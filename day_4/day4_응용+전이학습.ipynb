{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "WandB_pytorch_tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIFFEL-GN-2nd/TotochTeam1/blob/main/day_4/day4_%EC%9D%91%EC%9A%A9_%5B%EC%9D%B4%EB%A6%84%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🚀 Install, Import, and Log In"
      ],
      "metadata": {
        "id": "Cg1vp_Fe2nFJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import datasets\r\n",
        "from torch.utils.data import DataLoader, Subset\r\n",
        "from torchvision import models, transforms\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "outputs": [],
      "metadata": {
        "id": "bcFEvH5vhlYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0️⃣ Step 0: W&B 설치하기\n",
        "colab에서 WandB를 사용하려면 wandb modul을 install 해야합니다."
      ],
      "metadata": {
        "id": "ysRzZ5lGh7t5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "%%capture\r\n",
        "!pip install wandb --upgrade"
      ],
      "outputs": [],
      "metadata": {
        "id": "8mVVE8w1h8Jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ Step 1: W&B 로그인\n",
        "\n",
        "WandB의 web 서비스를 이용하기 위해선 log in이 필요합니다."
      ],
      "metadata": {
        "id": "ipp9aA2piG-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import wandb\r\n",
        "\r\n",
        "wandb.login()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpebpung\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {
        "id": "ovzfhTdSiJLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2️⃣ Step 2: config 설정 후 `wandb.init` 정의\n",
        "이제 본격적으로 모델을 학습 시키기 전에 몇가지 준비를 하려고 합니다.  \n",
        "1. hyper-parameter config 설정\n",
        "2. model 학습을 위한 pipeline 정의\n",
        "3. wandb.init()으로 wandb 서버와 연결\n",
        "4. dataloader 정의\n",
        "5. model 정의"
      ],
      "metadata": {
        "id": "fstctcwBiSlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) config 설정"
      ],
      "metadata": {
        "id": "GyjENuDR5I0J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "config  = {\r\n",
        "    'epochs': 5,\r\n",
        "    'classes':10,\r\n",
        "    'batch_size': 128,\r\n",
        "    'kernels': [16, 32],\r\n",
        "    'weight_decay': 0.0005,\r\n",
        "    'learning_rate': 1e-3,\r\n",
        "    'dataset': 'MNIST',\r\n",
        "    'architecture': 'CNN',\r\n",
        "    'seed': 42\r\n",
        "    }"
      ],
      "outputs": [],
      "metadata": {
        "id": "1lGXXFCXiTBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) model pipeline 정의"
      ],
      "metadata": {
        "id": "D1lrxavp5Nz3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def model_pipeline(hyperparameters):\r\n",
        "    wandb.init(project='test-pytorch', entity='pebpung', config=hyperparameters)\r\n",
        "      \r\n",
        "    config = wandb.config\r\n",
        "\r\n",
        "    model, train_loader, test_loader, criterion, optimizer = make(config)\r\n",
        "\r\n",
        "    train(model, train_loader, criterion, optimizer, config)\r\n",
        "    test(model, test_loader)\r\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "q8Zjs1lji-uQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def make(config):\r\n",
        "    train, test = get_data(train=True), get_data(train=False)\r\n",
        "    train_loader = make_loader(train, batch_size=config.batch_size)\r\n",
        "    test_loader = make_loader(test, batch_size=config.batch_size)\r\n",
        "\r\n",
        "    model = models.resnet18(pretrained=True)\r\n",
        "    num_ftrs = model.fc.in_features\r\n",
        "    model._fc = nn.Linear(num_ftrs, 2)\r\n",
        "    model.to(device)\r\n",
        "\r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\r\n",
        "    \r\n",
        "    return model, train_loader, test_loader, criterion, optimizer"
      ],
      "outputs": [],
      "metadata": {
        "id": "btjji_u27J81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) dataloader 정의"
      ],
      "metadata": {
        "id": "qgsDGEMY5VHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_data(slice=5, train=True):\r\n",
        "    full_dataset = datasets.MNIST(root='./data/MNIST', train=train, \r\n",
        "                                    download=True,  transform=transforms.ToTensor())\r\n",
        "    \r\n",
        "    #  equiv to slicing with [::slice] \r\n",
        "    sub_dataset = Subset(full_dataset, indices=range(0, len(full_dataset), slice))\r\n",
        "    return sub_dataset\r\n",
        "\r\n",
        "\r\n",
        "def make_loader(dataset, batch_size):\r\n",
        "    loader = DataLoader(dataset=dataset,\r\n",
        "                        batch_size=batch_size, \r\n",
        "                        shuffle=True,\r\n",
        "                        pin_memory=True, num_workers=2)\r\n",
        "    return loader"
      ],
      "outputs": [],
      "metadata": {
        "id": "Dt1AWh2fxN48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) 모델 정의"
      ],
      "metadata": {
        "id": "E13Qs4Xc5ZGe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Conventional and convolutional neural network\r\n",
        "\r\n",
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self, kernels, classes=10):\r\n",
        "        super(ConvNet, self).__init__()\r\n",
        "        \r\n",
        "        self.layer1 = nn.Sequential(\r\n",
        "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "        self.layer2 = nn.Sequential(\r\n",
        "            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        out = self.layer1(x)\r\n",
        "        out = self.layer2(out)\r\n",
        "        out = out.reshape(out.size(0), -1)\r\n",
        "        out = self.fc(out)\r\n",
        "        return out"
      ],
      "outputs": [],
      "metadata": {
        "id": "VI1Q0VoQxSUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3️⃣ Step 3. `wandb.watch`와 `wandb.log`를 사용해서 gradients 추적하기\n",
        "- **wandb.watch**는 gradient, topology와 관련된 정보를 visualization 하기 위한 코드입니다.\n",
        "- **wandb.log**는 visualization 하고 싶은 정보를 넘겨줄 수 있습니다.\n",
        "\n",
        "이 두가지 코드를 활용해서 gradient와 parameter를 시각화할 수 있습니다.   \n",
        "wandb.watch는 학습하기 전 train의 앞부분에 위치 시켜줍니다.  \n",
        "wandb.log는 학습 log를 출력하기 바로 전에 metric과 epoch을 입력합니다."
      ],
      "metadata": {
        "id": "iB4v24cn2d8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train(model, loader, criterion, optimizer, config):\r\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\r\n",
        "\r\n",
        "    # Run training and track with wandb\r\n",
        "    total_batches = len(loader) * config.epochs\r\n",
        "    example_ct = 0  # number of examples seen\r\n",
        "    batch_ct = 0\r\n",
        "    for epoch in tqdm(range(config.epochs)):\r\n",
        "        for batch_idx, (images, labels) in enumerate(loader):\r\n",
        "\r\n",
        "            images, labels = images.to(device), labels.to(device)\r\n",
        "    \r\n",
        "            # Forward pass ➡\r\n",
        "            outputs = model(images)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "            \r\n",
        "            # Backward pass ⬅\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            # Step with optimizer\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            example_ct +=  len(images)\r\n",
        "\r\n",
        "            # Report metrics every 25th batch\r\n",
        "            if ((batch_idx + 1) % 25) == 0:\r\n",
        "                train_log(loss, example_ct, epoch)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9Fz9rw8ExUez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train_log(loss, example_ct, epoch):\r\n",
        "    loss = float(loss)\r\n",
        "\r\n",
        "    # where the magic happens\r\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\r\n",
        "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZkSbJ9pLxV4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4️⃣ Optional Step 4:  `wandb.save`로 저장하기"
      ],
      "metadata": {
        "id": "4wCbKrfA2hv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def test(model, test_loader):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        correct, total = 0, 0\r\n",
        "        for images, labels in test_loader:\r\n",
        "            images, labels = images.to(device), labels.to(device)\r\n",
        "\r\n",
        "            outputs = model(images)\r\n",
        "            pred = outputs.max(1, keepdim = True)[1]                                       \r\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item() \r\n",
        "\r\n",
        "            total = len(test_loader.dataset)\r\n",
        "\r\n",
        "        print(f\"Accuracy of the model on the {total} \" +\r\n",
        "              f\"test images: {100 * correct / total}%\")\r\n",
        "        \r\n",
        "        wandb.log({\"test_accuracy\": correct / total})\r\n",
        "\r\n",
        "    # Save the model in the exchangeable ONNX format\r\n",
        "    torch.onnx.export(model, images, \"model.onnx\")\r\n",
        "    wandb.save(\"model.onnx\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "qk-YIDjlxXWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏃‍♀️ Run training and watch your metrics live on [wandb.ai](https://wandb.ai)!"
      ],
      "metadata": {
        "id": "76MuW0uc50QA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = model_pipeline(config)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kOSFlQBd5vJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "fS58qzKL8ar_"
      }
    }
  ]
}