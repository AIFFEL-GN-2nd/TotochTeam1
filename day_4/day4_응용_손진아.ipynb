{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day4_응용_손진아",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg1vp_Fe2nFJ"
      },
      "source": [
        "# 🚀 Install, Import, and Log In"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcFEvH5vhlYw"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysRzZ5lGh7t5"
      },
      "source": [
        "### 0️⃣ Step 0: W&B 설치하기\n",
        "colab에서 WandB를 사용하려면 wandb modul을 install 해야합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mVVE8w1h8Jc"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipp9aA2piG-g"
      },
      "source": [
        "### 1️⃣ Step 1: W&B 로그인\n",
        "\n",
        "WandB의 web 서비스를 이용하기 위해선 log in이 필요합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovzfhTdSiJLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bb33f954-784c-422d-f945-1f1f6b61a41d"
      },
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fstctcwBiSlH"
      },
      "source": [
        "### 2️⃣ Step 2: config 설정 후 `wandb.init` 정의\n",
        "이제 본격적으로 모델을 학습 시키기 전에 몇가지 준비를 하려고 합니다.  \n",
        "1. hyper-parameter config 설정\n",
        "2. model 학습을 위한 pipeline 정의\n",
        "3. wandb.init()으로 wandb 서버와 연결\n",
        "4. dataloader 정의\n",
        "5. model 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyjENuDR5I0J"
      },
      "source": [
        "### 1) config 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lGXXFCXiTBN"
      },
      "source": [
        "config  = {\n",
        "    'epochs': 5,\n",
        "    'classes':10,\n",
        "    'batch_size': 128,\n",
        "    'kernels': [16, 32],\n",
        "    'weight_decay': 0.0005,\n",
        "    'learning_rate': 1e-3,\n",
        "    'dataset': 'MNIST',\n",
        "    'architecture': 'CNN',\n",
        "    'seed': 42\n",
        "    }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1lrxavp5Nz3"
      },
      "source": [
        "### 2) model pipeline 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Zjs1lji-uQ"
      },
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "    wandb.init(project='test-pytorch', entity='jeena', config=hyperparameters)\n",
        "      \n",
        "    config = wandb.config\n",
        "\n",
        "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "\n",
        "    train(model, train_loader, criterion, optimizer, config)\n",
        "    test(model, test_loader)\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btjji_u27J81"
      },
      "source": [
        "def make(config):\n",
        "    train, test = get_data(train=True), get_data(train=False)\n",
        "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
        "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
        "\n",
        "    model = ConvNet(config.kernels, config.classes).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=config.learning_rate)\n",
        "    \n",
        "    return model, train_loader, test_loader, criterion, optimizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgsDGEMY5VHi"
      },
      "source": [
        "### 3) dataloader 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt1AWh2fxN48"
      },
      "source": [
        "def get_data(slice=5, train=True):\n",
        "    full_dataset = datasets.MNIST(root='./data/MNIST', train=train, \n",
        "                                    download=True,  transform=transforms.ToTensor())\n",
        "    \n",
        "    #  equiv to slicing with [::slice] \n",
        "    sub_dataset = torch.utils.data.Subset(full_dataset, \n",
        "                                          indices=range(0, len(full_dataset), slice))\n",
        "    return sub_dataset\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size):\n",
        "    loader = DataLoader(dataset=dataset,\n",
        "                        batch_size=batch_size, \n",
        "                        shuffle=True,\n",
        "                        pin_memory=True, num_workers=2)\n",
        "    return loader"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E13Qs4Xc5ZGe"
      },
      "source": [
        "### 4) 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI1Q0VoQxSUn"
      },
      "source": [
        "# Conventional and convolutional neural network\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, kernels, classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB4v24cn2d8o"
      },
      "source": [
        "### 3️⃣ Step 3. `wandb.watch`와 `wandb.log`를 사용해서 gradients 추적하기\n",
        "- **wandb.watch**는 gradient, topology와 관련된 정보를 visualization 하기 위한 코드입니다.\n",
        "- **wandb.log**는 visualization 하고 싶은 정보를 넘겨줄 수 있습니다.\n",
        "\n",
        "이 두가지 코드를 활용해서 gradient와 parameter를 시각화할 수 있습니다.   \n",
        "wandb.watch는 학습하기 전 train의 앞부분에 위치 시켜줍니다.  \n",
        "wandb.log는 학습 log를 출력하기 바로 전에 metric과 epoch을 입력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fz9rw8ExUez"
      },
      "source": [
        "def train(model, loader, criterion, optimizer, config):\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    total_batches = len(loader) * config.epochs\n",
        "    example_ct = 0  # number of examples seen\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        for batch_idx, (images, labels) in enumerate(loader):\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "            # Forward pass ➡\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Backward pass ⬅\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Step with optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "            example_ct +=  len(images)\n",
        "\n",
        "            # Report metrics every 25th batch\n",
        "            if ((batch_idx + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkSbJ9pLxV4R"
      },
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    loss = float(loss)\n",
        "\n",
        "    # where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wCbKrfA2hv4"
      },
      "source": [
        "### 4️⃣ Optional Step 4:  `wandb.save`로 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk-YIDjlxXWK"
      },
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            pred = outputs.max(1, keepdim = True)[1]                                       \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item() \n",
        "\n",
        "            total = len(test_loader.dataset)\n",
        "\n",
        "        print(f\"Accuracy of the model on the {total} \" +\n",
        "              f\"test images: {100 * correct / total}%\")\n",
        "        \n",
        "        wandb.log({\"test_accuracy\": correct / total})\n",
        "\n",
        "    # Save the model in the exchangeable ONNX format\n",
        "    torch.onnx.export(model, images, \"model.onnx\")\n",
        "    wandb.save(\"model.onnx\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76MuW0uc50QA"
      },
      "source": [
        "## 🏃‍♀️ Run training and watch your metrics live on [wandb.ai](https://wandb.ai)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOSFlQBd5vJN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "outputId": "1a1a2ecc-3bd3-4687-de97-ffdb605f733f"
      },
      "source": [
        "model = model_pipeline(config)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/jeena/test-pytorch/runs/25g4khs8\" target=\"_blank\">serene-pine-1</a></strong> to <a href=\"https://wandb.ai/jeena/test-pytorch\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "546ce2f6e45a4440adfadc52bc2ee7d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "509ef0416c6f4c92bcddc44f5494fd08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad1eb403820949d88a9eb19f0a5ec525",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c62ee08055e54e849c847b7ec1c65a13",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ec6c4e9a8be4c4084e7863ab7f1d4bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 03200 examples: 0.720\n",
            "Loss after 06400 examples: 0.395\n",
            "Loss after 09600 examples: 0.272\n",
            "Loss after 15200 examples: 0.238\n",
            "Loss after 18400 examples: 0.196\n",
            "Loss after 21600 examples: 0.290\n",
            "Loss after 27200 examples: 0.118\n",
            "Loss after 30400 examples: 0.168\n",
            "Loss after 33600 examples: 0.144\n",
            "Loss after 39200 examples: 0.106\n",
            "Loss after 42400 examples: 0.080\n",
            "Loss after 45600 examples: 0.080\n",
            "Loss after 51200 examples: 0.057\n",
            "Loss after 54400 examples: 0.090\n",
            "Loss after 57600 examples: 0.059\n",
            "Accuracy of the model on the 2000 test images: 96.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS58qzKL8ar_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}