{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/AIFFEL-GN-2nd/TotochTeam1/blob/main/day_4/day4_%EC%8B%A4%EC%8A%B5_%5B%EC%9D%B4%EB%A6%84%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\r\n",
    "\r\n",
    "# 이웃집 토토치 파이토치 : Day 4\r\n",
    "\r\n",
    "📢 해당 게시물은 파이토치 공식 튜토리얼 중 \r\n",
    "[컴퓨터 비전(VISION)을 위한 전이학습](https://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html)를 읽고 직접 작성해보는 실습 노트북입니다.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import Image\r\n",
    "Image(\"./img/image.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "🔎 Transfer learning은 무엇이고 pre-trained과 다른점이 무엇일까요?   \r\n",
    "👉 (괄호를 지우고 적어주세요!)  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Image(\"./img/gpu.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "시작하기 전에 런타임을 GPU로 바꿔주세요!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import print_function, division\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import numpy as np\r\n",
    "import torchvision\r\n",
    "from torchvision import models, transforms\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import time\r\n",
    "import copy\r\n",
    "\r\n",
    "from torchvision import transforms, datasets\r\n",
    "from torch.utils.data import DataLoader, Subset\r\n",
    "\r\n",
    "plt.ion()   # 대화형 모드"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "EPOCH = 10\r\n",
    "BATCH_SIZE = 8\r\n",
    "FC_LAYER_SIZE = 128\r\n",
    "LR = 0.01\r\n",
    "DROOUT = 0.5\r\n",
    "OPTIMIZER = 'sgd'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Dataset 준비"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transfer Leaning을 준비하기 위해서는 (1)내가 원하는 Dataset 과 (2) pre-trained model 이 필요합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\r\n",
    "                                    transforms.RandomHorizontalFlip(),\r\n",
    "                                    transforms.ToTensor(),\r\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
    "                                ])\r\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\r\n",
    "                                    transforms.CenterCrop(224),\r\n",
    "                                    transforms.ToTensor(),\r\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
    "                                ])\r\n",
    "\r\n",
    "train_dataset = datasets.CIFAR10(root = '../CIFAR10', train = True, \r\n",
    "                               download = True, transform = train_transform) \r\n",
    "\r\n",
    "test_dataset = datasets.CIFAR10(root = '../CIFAR10', train = False,\r\n",
    "                               download = True, transform = test_transform)\r\n",
    "\r\n",
    "# Subset을 사용하면 Dataset의 부분 집합만 가져올 수 있음.\r\n",
    "train_sub_dataset = Subset(train_dataset, indices=range(0, len(train_dataset), 5))\r\n",
    "test_sub_dataset = Subset(test_dataset, indices=range(0, len(test_dataset), 5))\r\n",
    "\r\n",
    "train_loader = DataLoader(dataset = train_sub_dataset, batch_size = BATCH_SIZE,\r\n",
    "                         shuffle = True, num_workers=2)\r\n",
    "\r\n",
    "test_loader = DataLoader(dataset = test_sub_dataset,\r\n",
    "                         batch_size = BATCH_SIZE)\r\n",
    "\r\n",
    "dataloaders = {\r\n",
    "    'train':train_loader,\r\n",
    "    'test':test_loader\r\n",
    "}\r\n",
    "\r\n",
    "classes = ('plane', 'car', 'bird', 'cat',\r\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A. 데이터 시각화"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def imshow(img):\r\n",
    "    img = img / 2 + 0.5    \r\n",
    "    npimg = img.numpy()\r\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "dataiter = iter(train_loader)\r\n",
    "images, labels = dataiter.next()\r\n",
    "\r\n",
    "imshow(torchvision.utils.make_grid(images))\r\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(BATCH_SIZE)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\r\n",
    "        self.fc2 = nn.Linear(120, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(F.relu(self.conv1(x)))\r\n",
    "        x = self.pool(F.relu(self.conv2(x)))\r\n",
    "        x = torch.flatten(x, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "model = Net()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Fine-tuning 모델"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "finetun_model = models.resnet18(pretrained=True)\r\n",
    "num_ftrs = finetun_model.fc.in_features\r\n",
    "finetun_model._fc = nn.Linear(num_ftrs, 2)\r\n",
    "\r\n",
    "finetun_model.to(DEVICE)\r\n",
    "\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.SGD(finetun_model.parameters(), lr=LR, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) 학습 진행하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = finetun_model\r\n",
    "\r\n",
    "train_acc_list =[]\r\n",
    "train_loss_list = []\r\n",
    "test_acc_list = []\r\n",
    "test_loss_list = []\r\n",
    "\r\n",
    "since = time.time()\r\n",
    "\r\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\r\n",
    "best_acc = 0.0\r\n",
    "\r\n",
    "for epoch in tqdm(range(EPOCH)):\r\n",
    "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\r\n",
    "    print('-' * 20)\r\n",
    "\r\n",
    "    # Each epoch has a training and validation phase\r\n",
    "    for phase in ['train', 'test']:\r\n",
    "        \r\n",
    "        if phase == 'train':\r\n",
    "            model.train()  # Set model to training mode\r\n",
    "        else:\r\n",
    "            model.eval()   # Set model to evaluate mode\r\n",
    "\r\n",
    "        running_loss = 0.0\r\n",
    "        running_corrects = 0\r\n",
    "\r\n",
    "        # Iterate over data.\r\n",
    "        for inputs, labels in dataloaders[phase]:\r\n",
    "            inputs = inputs.to(DEVICE)\r\n",
    "            labels = labels.to(DEVICE)\r\n",
    "            # print(labels)\r\n",
    "            # print(labels.shape)\r\n",
    "            # break\r\n",
    "            # zero the parameter gradients\r\n",
    "            optimizer.zero_grad()\r\n",
    "\r\n",
    "            # forward\r\n",
    "            # track history if only in train\r\n",
    "            with torch.set_grad_enabled(phase == 'train'):\r\n",
    "                outputs = model(inputs)\r\n",
    "                _, preds = torch.max(outputs, 1)\r\n",
    "                loss = criterion(outputs, labels)\r\n",
    "\r\n",
    "                # backward + optimize only if in training phase\r\n",
    "                if phase == 'train':\r\n",
    "                    loss.backward()\r\n",
    "                    optimizer.step()\r\n",
    "\r\n",
    "            # statistics\r\n",
    "            running_loss += loss.item() * inputs.size(0)\r\n",
    "            running_corrects += torch.sum(preds == labels.data)\r\n",
    "\r\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\r\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\r\n",
    "        \r\n",
    "        print('>> Phase: ', phase)\r\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\r\n",
    "            phase, epoch_loss, epoch_acc))\r\n",
    "\r\n",
    "        if phase == 'train':\r\n",
    "            train_acc_list.append(epoch_acc)\r\n",
    "            train_loss_list.append(epoch_loss)\r\n",
    "        else:\r\n",
    "            test_acc_list.append(epoch_acc)\r\n",
    "            test_loss_list.append(epoch_loss)\r\n",
    "            \r\n",
    "        # deep copy the model\r\n",
    "        if phase == 'test' and epoch_acc > best_acc:\r\n",
    "            best_acc = epoch_acc\r\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\r\n",
    "\r\n",
    "\r\n",
    "time_elapsed = time.time() - since\r\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\r\n",
    "    time_elapsed // 60, time_elapsed % 60))\r\n",
    "print('Best test Acc: {:4f}'.format(best_acc))\r\n",
    "\r\n",
    "# load best model weights\r\n",
    "# model.load_state_dict(best_model_wts)\r\n",
    "\r\n",
    "torch.save(best_model_wts , './pretrained_vgg_orignal_cifar10.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5) 학습 결과 시각화"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(train_loss_list)\r\n",
    "plt.plot(test_loss_list)\r\n",
    "plt.title('model loss')\r\n",
    "plt.ylabel('loss')\r\n",
    "plt.xlabel('epoch')\r\n",
    "plt.legend(['train', 'val'], loc='upper left')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(train_acc_list)\r\n",
    "plt.plot(test_acc_list)\r\n",
    "plt.title('model accuracy')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.xlabel('epoch')\r\n",
    "plt.legend(['train', 'val'], loc='upper left')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}