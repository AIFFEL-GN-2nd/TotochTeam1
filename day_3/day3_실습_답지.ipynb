{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 이웃집 토토치 파이토치 : Day 3\n",
        "\n",
        "📢 해당 게시물은 파이토치 공식 튜토리얼 중 \n",
        "[DATASET과 DATALOADER](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html)와 \n",
        "[분류기(CLASSIFIER) 학습하기](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)\n",
        "[모델 저장하고 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)\n",
        "를 읽고 직접 작성해보는 실습 노트북입니다.  \n",
        "\n",
        "#### 목차\n",
        "1. DATASET과 DATALOADER\n",
        "    1. 필요 모듈 준비\n",
        "    2. Configration 설정\n",
        "    3. 데이터 준비\n",
        "2. Pytorch로 구현하는 MNIST 손글씨 분류기\n",
        "    1. 도우미 함수 정의\n",
        "    2. 모델 정의하기\n",
        "    3. 학습 진행하기\n",
        "    4. Batch Norm 적용하고 학습하기\n",
        "3. 모델 저장하고 불러오기\n",
        "    1. 모델 전제 저장\n",
        "    2. 모델의 state_dict만 저장\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. DATASET과 DATALOADER\n",
        "---\n",
        "\n",
        "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\n",
        "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
        "\n",
        "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\n",
        "\n",
        "여기에서 데이터셋들을 찾아볼 수 있습니다:\n",
        "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \n",
        "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\n",
        "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) 필요 모듈 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vbhzwyVwIRaq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn    \n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Configration 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iLTqzrd0LJik"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 128\n",
        "FC_LAYER_SIZE = 128\n",
        "LR = 0.01\n",
        "DROOUT = 0.5\n",
        "OPTIMIZER = 'sgd'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-1) 기존 TorchVision Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "euieV7xAMGpE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pebpung\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.RandomRotation(degrees=45),\n",
        "                                      transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "                                      transforms.Normalize([0.5,],[0.5,])])\n",
        "test_transform = transforms.Compose([ transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5,],[0.5])])\n",
        "\n",
        "train_dataset = datasets.MNIST(root = '../MNIST', # 데이터 저장될장소 \n",
        "                               train = True, # train인지 test인지 \n",
        "                               download = True,# 인터넷에서 다운로드해 이용할건지 \n",
        "                               transform = train_transform) \n",
        "\n",
        "test_dataset = datasets.MNIST(root = '../MNIST', train = False,\n",
        "                               download = True, transform = test_transform)\n",
        "\n",
        "# Subset을 사용하면 Dataset의 부분 집합만 가져올 수 있음.\n",
        "train_sub_dataset = Subset(train_dataset, indices=range(0, len(train_dataset), 5))\n",
        "test_sub_dataset = Subset(test_dataset, indices=range(0, len(test_dataset), 5))\n",
        "\n",
        "train_loader = DataLoader(dataset = train_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Subset은 Dataset의 부분 집합을 가져오는 함수입니다.  \n",
        "Dataset 원본으로 학습을 시켰을 경우 16~17분 정도가 걸리지만, Subset으로 학습을 할 경우 3~4분 정도가 걸립니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "ih1u4er1cruk",
        "outputId": "7ce5c11b-770a-4074-be58-100a2633ad50"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_train, y_train = next(iter(train_loader))\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize = (10 * pltsize ,pltsize))\n",
        "for i in range(10):\n",
        "  plt.subplot(1, 10 , i + 1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(X_train[i, : , :, :].numpy().reshape(28,28), cmap = 'gray_r')\n",
        "  plt.title('class:' + str(y_train[i].item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-2) 다양한 transforms 적용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🔎 다양한 transforms 추가해서 Mnist 데이터셋을 변형해봅시다!   \n",
        "👉 (3-1에서 train_transform, test_transform를 바꿔보시길 바랍니다.)  \n",
        "🔔 [Hint](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-3) 더 빠른 augmentation, albumentations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🔎 Albumentations의 장점과 특징은 어떤게 있을까요?  \n",
        "👉 (괄호를 지우고 적어주세요!)   \n",
        "🔔 [Hint](https://hoya012.github.io/blog/albumentation_tutorial/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Pytorch로 구현하는 MNIST 손글씨 분류기\n",
        "---\n",
        "우리는 위에서 DATASET과 DATALOADER를 살펴보았습니다.  \n",
        "이번에는 Pytorch로 MNIST를 학습하는 코드를 적용해보겠습니다.  \n",
        "마찬가지로 중간중간에 있는 문제를 푸시면 됩니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) 도우미 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(network, loader, optimizer, criterion):\n",
        "    cumu_loss = 0\n",
        "    cumu_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    for _, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(network(data), target)\n",
        "        cumu_loss += loss.item()\n",
        "        _, predicted = torch.max(network(data).data, 1)\n",
        "        total += target.size(0)\n",
        "        cumu_acc += (predicted == target).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        network.eval() \n",
        "    return cumu_loss / len(loader), 100 * cumu_acc / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nY7vlD-8BBCC"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader, criterion):\n",
        "  model.eval() # 모델을 평가상태(test 상태)로 지정 \n",
        "  test_loss = 0 # test_loss 초기값 \n",
        "  correct = 0 # 올바른 class로 분류한 카운트를 세기위해 0으로 설정 \n",
        "\n",
        "  with torch.no_grad(): # 평가시에는 gradiant를 통해 패러미터 업데이트를 하지않음 \n",
        "    for image, label in test_loader: # mini_batch 단위로 꺼내기 \n",
        "      image = image.to(DEVICE) # DEVICE 할당\n",
        "      label = label.to(DEVICE) # DEVICE에 할당\n",
        "      output = model(image)    # 모델에 input을 넣어 output 계산 \n",
        "      test_loss += criterion(output, label).item() # output과 label의 loss 계산 \n",
        "      prediction = output.max(1, keepdim = True)[1] # output은 길이가 10인 벡터값 \n",
        "                                                    # 그중에서 가장 큰값인 위치의 라벨로\n",
        "                                                    # 예측햇다고 판단 \n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item() # eq() 메서드는 라벨과 예측이 같으면(equal) 1\n",
        "                                                                        # 다르면 0. 그 값들을더해서 correct에 더해주기 \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) 모델 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation 정의\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) 학습 진행하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OD4YKjG-tkc",
        "outputId": "53640226-1aaf-4122-9a78-6a82b2a87bae"
      },
      "outputs": [],
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**🔎 torch.optim에는 어떤 optimizer들을 구현할 수 있나요? ([공식 document](https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim)를 참조하여 2개 이상 적어주세요.)**  \n",
        "👉 대표적으로 ADAM, RMSprop등 다양한 optimizer가 있습니다. 또한 scheduler를 사용해서 학습 효율을 높일 수 있습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**🔎 nn.Module에서 활용할 수 있는 Loss function에는 어떤 것들이 있나요? ([공식 document-Loss function](https://pytorch.org/docs/stable/nn.html?highlight=loss#loss-functions)를 참조하여 2개 이상 적어주세요.)**  \n",
        "👉 NLLLoss: null loss라고 읽었는데 알고보니 negative log likelihood loss이다.  \n",
        "KLDivLoss: Kullback-Leibler divergence loss 이다. GAN에서 중요한 개념으로 사용된다.  \n",
        "SmoothL1Loss: YOLOv1과 YOLOv2에서 활용된다. L1 loss와 L2 loss를 적절하게 혼합함.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-1) 기본 augmentation을 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.9152 | Epoch ACC 41.38% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.3931 | Epoch ACC 87.54% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.2097 | Epoch ACC 93.58% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1493 | Epoch ACC 95.37% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.1046 | Epoch ACC 96.83% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0897 | Epoch ACC 97.32% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0689 | Epoch ACC 98.03% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0607 | Epoch ACC 98.11% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0527 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0454 | Epoch ACC 98.70% \n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test LOSS 0.0006 | Test ACC 97.90% \n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-2) RandomRotation, RandomAffine을 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pebpung\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 2.2399 | Epoch ACC 19.51% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 1.7524 | Epoch ACC 38.83% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 1.2340 | Epoch ACC 58.13% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.7992 | Epoch ACC 73.77% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.6238 | Epoch ACC 80.41% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.5233 | Epoch ACC 83.28% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.4151 | Epoch ACC 86.98% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.3697 | Epoch ACC 88.33% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.3327 | Epoch ACC 89.96% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.2974 | Epoch ACC 90.70% \n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test LOSS 0.0022 | Test ACC 91.55% \n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train 학습 시에는 기본 augmentation을 적용한 것 보다 ACC가 낮아지지만, evaluate 시에는 더 좋아집니다.  \n",
        "왜 이런 결과가 생겼을까요?  \n",
        "데이터 증강은 train 학습 시에 성능 향상을 목적으로 하는 것이 아니기 때문입니다.  \n",
        "더 다양한 모습의 데이터로 학습하여 새로 들어오는 test data에 대해서 robust 한 모델을 만드는 것이 목적이기 때문입니다.  \n",
        "그래서 train acc 뿐만 아니라, valid acc를 추가해서 비교하는 것이 옳습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) train, valid 함수 재정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(loader):\n",
        "            percent = 100. * (batch_idx + 1) / len(loader)\n",
        "            print(f'| {\"■\" * int(percent // 10) + \"□\" * int(10 - percent // 10)} | [{(batch_idx + 1) * len(loader)} / {len(loader.dataset)}', end='') \n",
        "            print(f'({percent:.0f}%)] | Loss: {loss.data.item():.4f}')\n",
        "                \n",
        "    loss /= len(loader.dataset)\n",
        "    acc = (100.0 * float(correct) / len(loader.dataset))\n",
        "    print(f\"\\nTRAIN EPOCH: {epoch + 1:02d} / {EPOCH:02d} | TRAIN LOSS {loss:.4f} | TRAIN ACC {acc:.2f}% \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, val_loader,criterion):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for _, (data, target) in enumerate(val_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        \n",
        "        output = model(data)\n",
        "        loss += criterion(output, target).data.item()\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    loss /= len(val_loader.dataset)\n",
        "    acc = (100.0 * float(correct) / len(val_loader.dataset))\n",
        "        \n",
        "    print(f\"VALID EPOCH: {epoch + 1:02d} / {EPOCH:02d} | VALID LOSS {loss:.4f} | VALID ACC {acc:.2f}% \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) BATCH Normalization적용하고 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.BatchNorm1d(fc_layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.BatchNorm1d(84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation 정의\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EPOCH: 01 / 10\n",
            "| ■□□□□□□□□□ | [940 / 12000(11%)] | Loss: 2.2394\n",
            "| ■■□□□□□□□□ | [1880 / 12000(21%)] | Loss: 1.9763\n",
            "| ■■■□□□□□□□ | [2820 / 12000(32%)] | Loss: 2.0110\n",
            "| ■■■■□□□□□□ | [3760 / 12000(43%)] | Loss: 1.8856\n",
            "| ■■■■■□□□□□ | [4700 / 12000(53%)] | Loss: 1.8185\n",
            "| ■■■■■■□□□□ | [5640 / 12000(64%)] | Loss: 1.7025\n",
            "| ■■■■■■■□□□ | [6580 / 12000(74%)] | Loss: 1.6714\n",
            "| ■■■■■■■■□□ | [7520 / 12000(85%)] | Loss: 1.6470\n",
            "| ■■■■■■■■■□ | [8460 / 12000(96%)] | Loss: 1.5269\n",
            "| ■■■■■■■■■■ | [8836 / 12000(100%)] | Loss: 1.2414\n",
            "\n",
            "TRAIN EPOCH: 01 / 10 | TRAIN LOSS 0.0001 | TRAIN ACC 36.96% \n",
            "VALID EPOCH: 01 / 10 | VALID LOSS 0.0125 | VALID ACC 45.90% \n",
            "\n",
            "EPOCH: 02 / 10\n",
            "| ■□□□□□□□□□ | [940 / 12000(11%)] | Loss: 1.2068\n",
            "| ■■□□□□□□□□ | [1880 / 12000(21%)] | Loss: 1.3196\n",
            "| ■■■□□□□□□□ | [2820 / 12000(32%)] | Loss: 1.1198\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-27-27554cd4de81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\nEPOCH: {epoch + 1:02d} / {EPOCH:02d}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-23-11cfc0c069e6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCH):\n",
        "    print(f'\\nEPOCH: {epoch + 1:02d} / {EPOCH:02d}')\n",
        "    train(model, train_loader, optimizer, criterion)\n",
        "    validate(model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Batch norm과 augmentation을 적용하여 성능 향상이 되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 모델 저장하고 불러오기\n",
        "---\n",
        "이번에는 저장하기나 불러오기를 통해 모델의 상태를 유지(persist)하고 모델의 예측을 실행하는 방법을 알아보겠습니다.  \n",
        "모델을 저장할 때는 두 가지 방법 중 한 방법을 선택할 수 있는데, 모델 전체를 저장하는 방법과 모델의 state_dict만 저장하는 방법이 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) 모델 전체 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Case 1\n",
        "torch.save(model, 'ConvNet.pt')\n",
        "# Load model\n",
        "model = torch.load('ConvNet.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) 모델의 state_dict만 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Case 1\n",
        "torch.save(model.state_dict(), 'ConvNet_dict.pt')\n",
        "# Load model\n",
        "model.load_state_dict(torch.load('ConvNet_dict.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🔎 model 전체를 저장하는 것과 state_dict만 저장하는 것은 무슨 차이가 있을까요? ([모델 저장하기 & 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)를 참조하세요.)  \n",
        "👉 모델 전체를 저장한다는 것의 의미는 모델 파라미터 뿐만 아니라, 옵티마이저(Optimizer), Epoch, 스코어 등 모든 상태를 저장한다는 것입니다. 만약 나중에 이어서 학습을 한다던지, 코드에 접근할 권한이 없는 사용자에게 사용할 수 있도록 합니다. 모델 전체를 저장하는 만큼, 상대적으로 더 큰 용량을 가지게 됩니다.  \n",
        "Pytorch에서 모델의 state_dict은 학습가능한 매개변수가 담겨있는 Dictionary입니다. Weight와 bias가 이에 해당합니다. 그러나 매개변수 이외에는 정보가 담겨있지 않기 때문에, 코드 상으로 모델이 구현되어 있는 경우에만 로드를 할 수 있습니다. state_dict만 저장하면 파일의 용량이 가벼워진다는 장점이 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2-1) 체크포인트(checkpoint) 저장하기 & 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, \n",
        "           'ConvNet_dict.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "\n",
        "checkpoint = torch.load('ConvNet_dict.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.01\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "10\n",
            "CrossEntropyLoss()\n"
          ]
        }
      ],
      "source": [
        "print(optimizer)\n",
        "print(epoch)\n",
        "print(loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "파이토치 코드_0929",
      "provenance": []
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit ('torch': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
