{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "파이토치 코드_0929",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 이웃집 토토치 파이토치 : Day 3\r\n",
        "\r\n",
        "📢 해당 게시물은 파이토치 공식 튜토리얼 중 \r\n",
        "[DATASET과 DATALOADER](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html)와 \r\n",
        "[분류기(CLASSIFIER) 학습하기](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)\r\n",
        "[모델 저장하고 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)\r\n",
        "를 읽고 직접 작성해보는 실습 노트북입니다.  \r\n",
        "\r\n",
        "#### 목차\r\n",
        "1. DATASET과 DATALOADER\r\n",
        "    1. 필요 모듈 준비\r\n",
        "    2. Configration 설정\r\n",
        "    3. 데이터 준비\r\n",
        "2. Pytorch로 구현하는 MNIST 손글씨 분류기\r\n",
        "    1. 도우미 함수 정의\r\n",
        "    2. 모델 정의하기\r\n",
        "    3. 학습 진행하기\r\n",
        "    4. Batch Norm 적용하고 학습하기\r\n",
        "3. 모델 저장하고 불러오기\r\n",
        "    1. 모델 전제 저장\r\n",
        "    2. 모델의 state_dict만 저장\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. DATASET과 DATALOADER\r\n",
        "---\r\n",
        "\r\n",
        "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\r\n",
        "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\r\n",
        "\r\n",
        "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\r\n",
        "\r\n",
        "여기에서 데이터셋들을 찾아볼 수 있습니다:\r\n",
        "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \r\n",
        "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\r\n",
        "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 필요 모듈 준비"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torch.nn as nn    \r\n",
        "from torchvision import transforms, datasets\r\n",
        "from torch.utils.data import DataLoader, Subset\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "vbhzwyVwIRaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Configration 설정"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "EPOCH = 10\r\n",
        "BATCH_SIZE = 128\r\n",
        "FC_LAYER_SIZE = 128\r\n",
        "LR = 0.01\r\n",
        "DROOUT = 0.5\r\n",
        "OPTIMIZER = 'sgd'"
      ],
      "outputs": [],
      "metadata": {
        "id": "iLTqzrd0LJik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 데이터 준비"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1) 기존 TorchVision Data Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                      transforms.RandomRotation(degrees=45),\r\n",
        "                                      transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2)),\r\n",
        "                                      transforms.Normalize([0.5,],[0.5,])])\r\n",
        "test_transform = transforms.Compose([ transforms.ToTensor(),\r\n",
        "                                      transforms.Normalize([0.5,],[0.5])])\r\n",
        "\r\n",
        "train_dataset = datasets.MNIST(root = '../MNIST', # 데이터 저장될장소 \r\n",
        "                               train = True, # train인지 test인지 \r\n",
        "                               download = True,# 인터넷에서 다운로드해 이용할건지 \r\n",
        "                               transform = train_transform) \r\n",
        "\r\n",
        "test_dataset = datasets.MNIST(root = '../MNIST', train = False,\r\n",
        "                               download = True, transform = test_transform)\r\n",
        "\r\n",
        "# Subset을 사용하면 Dataset의 부분 집합만 가져올 수 있음.\r\n",
        "train_sub_dataset = Subset(train_dataset, indices=range(0, len(train_dataset), 5))\r\n",
        "test_sub_dataset = Subset(test_dataset, indices=range(0, len(test_dataset), 5))\r\n",
        "\r\n",
        "train_loader = DataLoader(dataset = train_sub_dataset,\r\n",
        "                         batch_size = BATCH_SIZE,\r\n",
        "                         shuffle = True)\r\n",
        "\r\n",
        "test_loader = DataLoader(dataset = test_sub_dataset,\r\n",
        "                         batch_size = BATCH_SIZE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\pebpung\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ],
      "metadata": {
        "id": "euieV7xAMGpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subset은 Dataset의 부분 집합을 가져오는 함수입니다.  \r\n",
        "Dataset 원본으로 학습을 시켰을 경우 16~17분 정도가 걸리지만, Subset으로 학습을 할 경우 3~4분 정도가 걸립니다. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "X_train, y_train = next(iter(train_loader))\r\n",
        "\r\n",
        "pltsize = 1\r\n",
        "plt.figure(figsize = (10 * pltsize ,pltsize))\r\n",
        "for i in range(10):\r\n",
        "  plt.subplot(1, 10 , i + 1)\r\n",
        "  plt.axis('off')\r\n",
        "  plt.imshow(X_train[i, : , :, :].numpy().reshape(28,28), cmap = 'gray_r')\r\n",
        "  plt.title('class:' + str(y_train[i].item()))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "ih1u4er1cruk",
        "outputId": "7ce5c11b-770a-4074-be58-100a2633ad50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2) 다양한 transforms 적용해보기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎 다양한 transforms 추가해서 Mnist 데이터셋을 변형해봅시다!   \r\n",
        "👉 (3-1에서 train_transform, test_transform를 바꿔보시길 바랍니다.)  \r\n",
        "🔔 [Hint](https://pytorch.org/vision/stable/transforms.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-3) 더 빠른 augmentation, albumentations "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎 Albumentations의 장점과 특징은 어떤게 있을까요?  \r\n",
        "👉 (괄호를 지우고 적어주세요!)   \r\n",
        "🔔 [Hint](https://hoya012.github.io/blog/albumentation_tutorial/) "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pytorch로 구현하는 MNIST 손글씨 분류기\r\n",
        "---\r\n",
        "우리는 위에서 DATASET과 DATALOADER를 살펴보았습니다.  \r\n",
        "이번에는 Pytorch로 MNIST를 학습하는 코드를 적용해보겠습니다.  \r\n",
        "마찬가지로 중간중간에 있는 문제를 푸시면 됩니다!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 도우미 함수 정의"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "def train_epoch(network, loader, optimizer, criterion):\r\n",
        "    cumu_loss = 0\r\n",
        "    cumu_acc = 0\r\n",
        "    total = 0\r\n",
        "\r\n",
        "    for _, (data, target) in enumerate(loader):\r\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        loss = criterion(network(data), target)\r\n",
        "        cumu_loss += loss.item()\r\n",
        "        _, predicted = torch.max(network(data).data, 1)\r\n",
        "        total += target.size(0)\r\n",
        "        cumu_acc += (predicted == target).sum().item()\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        network.eval() \r\n",
        "    return cumu_loss / len(loader), 100 * cumu_acc / total"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def evaluate(model, test_loader, criterion):\r\n",
        "  model.eval() # 모델을 평가상태(test 상태)로 지정 \r\n",
        "  test_loss = 0 # test_loss 초기값 \r\n",
        "  correct = 0 # 올바른 class로 분류한 카운트를 세기위해 0으로 설정 \r\n",
        "\r\n",
        "  with torch.no_grad(): # 평가시에는 gradiant를 통해 패러미터 업데이트를 하지않음 \r\n",
        "    for image, label in test_loader: # mini_batch 단위로 꺼내기 \r\n",
        "      image = image.to(DEVICE) # DEVICE 할당\r\n",
        "      label = label.to(DEVICE) # DEVICE에 할당\r\n",
        "      output = model(image)    # 모델에 input을 넣어 output 계산 \r\n",
        "      test_loss += criterion(output, label).item() # output과 label의 loss 계산 \r\n",
        "      prediction = output.max(1, keepdim = True)[1] # output은 길이가 10인 벡터값 \r\n",
        "                                                    # 그중에서 가장 큰값인 위치의 라벨로\r\n",
        "                                                    # 예측햇다고 판단 \r\n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item() # eq() 메서드는 라벨과 예측이 같으면(equal) 1\r\n",
        "                                                                        # 다르면 0. 그 값들을더해서 correct에 더해주기 \r\n",
        "  test_loss /= len(test_loader.dataset)\r\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\r\n",
        "  return test_loss, test_accuracy"
      ],
      "outputs": [],
      "metadata": {
        "id": "nY7vlD-8BBCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 모델 정의하기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self, fc_layer_size, dropout):\r\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\r\n",
        "        self.layer1 = nn.Sequential(\r\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer2 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer3 = nn.Sequential(\r\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout))\r\n",
        "        self.layer4 = nn.Sequential(\r\n",
        "            nn.Linear(fc_layer_size, 84),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout))\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    # Forward Propagation 정의\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = x.view(x.size(0),-1) \r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 학습 진행하기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "if OPTIMIZER == \"sgd\":\r\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\r\n",
        "elif OPTIMIZER == \"adam\":\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\r\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OD4YKjG-tkc",
        "outputId": "53640226-1aaf-4122-9a78-6a82b2a87bae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🔎 torch.optim에는 어떤 optimizer들을 구현할 수 있나요? ([공식 document](https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim)를 참조하여 2개 이상 적어주세요.)**  \r\n",
        "👉 대표적으로 ADAM, RMSprop등 다양한 optimizer가 있습니다. 또한 scheduler를 사용해서 학습 효율을 높일 수 있습니다"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🔎 nn.Module에서 활용할 수 있는 Loss function에는 어떤 것들이 있나요? ([공식 document-Loss function](https://pytorch.org/docs/stable/nn.html?highlight=loss#loss-functions)를 참조하여 2개 이상 적어주세요.)**  \r\n",
        "👉 NLLLoss: null loss라고 읽었는데 알고보니 negative log likelihood loss이다.  \r\n",
        "KLDivLoss: Kullback-Leibler divergence loss 이다. GAN에서 중요한 개념으로 사용된다.  \r\n",
        "SmoothL1Loss: YOLOv1과 YOLOv2에서 활용된다. L1 loss와 L2 loss를 적절하게 혼합함.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1) 기본 augmentation을 적용"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "source": [
        "for epoch in range(EPOCH):\r\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\r\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.9152 | Epoch ACC 41.38% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.3931 | Epoch ACC 87.54% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.2097 | Epoch ACC 93.58% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1493 | Epoch ACC 95.37% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.1046 | Epoch ACC 96.83% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0897 | Epoch ACC 97.32% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0689 | Epoch ACC 98.03% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0607 | Epoch ACC 98.11% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0527 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0454 | Epoch ACC 98.70% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\r\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0006 | Test ACC 97.90% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2) RandomRotation, RandomAffine을 추가"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "for epoch in range(EPOCH):\r\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\r\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\pebpung\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 2.2399 | Epoch ACC 19.51% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 1.7524 | Epoch ACC 38.83% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 1.2340 | Epoch ACC 58.13% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.7992 | Epoch ACC 73.77% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.6238 | Epoch ACC 80.41% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.5233 | Epoch ACC 83.28% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.4151 | Epoch ACC 86.98% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.3697 | Epoch ACC 88.33% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.3327 | Epoch ACC 89.96% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.2974 | Epoch ACC 90.70% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\r\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0022 | Test ACC 91.55% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 학습 시에는 기본 augmentation을 적용한 것 보다 ACC가 낮아지지만, evaluate 시에는 더 좋아집니다.  \r\n",
        "왜 이런 결과가 생겼을까요?  \r\n",
        "데이터 증강은 train 학습 시에 성능 향상을 목적으로 하는 것이 아니기 때문입니다.  \r\n",
        "더 다양한 모습의 데이터로 학습하여 새로 들어오는 test data에 대해서 robust 한 모델을 만드는 것이 목적이기 때문입니다.  \r\n",
        "그래서 train acc 뿐만 아니라, valid acc를 추가해서 비교하는 것이 옳습니다.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) train, valid 함수 재정의"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "len(train_loader.dataset)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "def train(model, loader, optimizer, criterion):\r\n",
        "    model.train()\r\n",
        "    loss = 0\r\n",
        "    correct = 0\r\n",
        "\r\n",
        "    for batch_idx, (data, target) in enumerate(loader):\r\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\r\n",
        "\r\n",
        "        output = model(data)\r\n",
        "        loss = criterion(output, target)\r\n",
        "\r\n",
        "        pred = output.data.max(1, keepdim=True)[1]\r\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if (batch_idx + 1)% 10 == 0:\r\n",
        "            print(f'TRAIN EPOCH: {epoch + 1:04d} [{(batch_idx + 1) * len(data)} / {len(train_loader.dataset)}', end='') \r\n",
        "            print(f'({100. * (batch_idx + 1) / len(train_loader):.0f}%)] | Loss: {loss.data.item():.4f}')\r\n",
        "                \r\n",
        "    loss /= len(loader.dataset)\r\n",
        "    acc = (100.0 * float(correct) / len(loader.dataset))\r\n",
        "    print(f\"\\nTRAIN EPOCH: {epoch + 1:02d} / {EPOCH:02d} | TRAIN LOSS {loss:.4f} | TRAIN ACC {acc:.2f}% \")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "def validate(model, val_loader,criterion):\r\n",
        "    model.eval()\r\n",
        "    loss = 0\r\n",
        "    correct = 0\r\n",
        "    \r\n",
        "    for _, (data, target) in enumerate(val_loader):\r\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\r\n",
        "        \r\n",
        "        output = model(data)\r\n",
        "        loss += criterion(output, target).data.item()\r\n",
        "\r\n",
        "        pred = output.data.max(1, keepdim=True)[1]\r\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\r\n",
        "        \r\n",
        "    loss /= len(val_loader.dataset)\r\n",
        "    acc = (100.0 * float(correct) / len(val_loader.dataset))\r\n",
        "        \r\n",
        "    print(f\"VALID EPOCH: {epoch + 1:02d} / {EPOCH:02d} | VALID LOSS {loss:.4f} | VALID ACC {acc:.2f}% \")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) BATCH Normalization적용하고 학습하기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self, fc_layer_size, dropout):\r\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\r\n",
        "        self.layer1 = nn.Sequential(\r\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer2 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer3 = nn.Sequential(\r\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\r\n",
        "            nn.BatchNorm1d(fc_layer_size),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout),)\r\n",
        "        self.layer4 = nn.Sequential(\r\n",
        "            nn.Linear(fc_layer_size, 84),\r\n",
        "            nn.BatchNorm1d(84),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout),)\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    # Forward Propagation 정의\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = x.view(x.size(0),-1) \r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "if OPTIMIZER == \"sgd\":\r\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\r\n",
        "elif OPTIMIZER == \"adam\":\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\r\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "for epoch in range(EPOCH):\r\n",
        "    print(f'\\nEPOCH: {epoch + 1:02d} / {EPOCH:02d}')\r\n",
        "    train(model, train_loader, optimizer, criterion)\r\n",
        "    validate(model, test_loader, criterion)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN EPOCH: 0001 [1280/12000(11%)] | Loss: 2.2922\n",
            "TRAIN EPOCH: 0001 [2560/12000(21%)] | Loss: 2.1039\n",
            "TRAIN EPOCH: 0001 [3840/12000(32%)] | Loss: 1.9311\n",
            "TRAIN EPOCH: 0001 [5120/12000(43%)] | Loss: 1.8069\n",
            "TRAIN EPOCH: 0001 [6400/12000(53%)] | Loss: 1.6952\n",
            "TRAIN EPOCH: 0001 [7680/12000(64%)] | Loss: 1.8289\n",
            "TRAIN EPOCH: 0001 [8960/12000(74%)] | Loss: 1.5761\n",
            "TRAIN EPOCH: 0001 [10240/12000(85%)] | Loss: 1.4745\n",
            "TRAIN EPOCH: 0001 [11520/12000(96%)] | Loss: 1.4170\n",
            "\n",
            "TRAIN EPOCH: 0001 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 38.39% \n",
            "VALID EPOCH: 0001 / 0010 | VALID LOSS 0.0100 | VALID ACC 62.65% \n",
            "TRAIN EPOCH: 0002 [1280/12000(11%)] | Loss: 1.3130\n",
            "TRAIN EPOCH: 0002 [2560/12000(21%)] | Loss: 1.2054\n",
            "TRAIN EPOCH: 0002 [3840/12000(32%)] | Loss: 1.2104\n",
            "TRAIN EPOCH: 0002 [5120/12000(43%)] | Loss: 1.2261\n",
            "TRAIN EPOCH: 0002 [6400/12000(53%)] | Loss: 1.1391\n",
            "TRAIN EPOCH: 0002 [7680/12000(64%)] | Loss: 1.0530\n",
            "TRAIN EPOCH: 0002 [8960/12000(74%)] | Loss: 1.0968\n",
            "TRAIN EPOCH: 0002 [10240/12000(85%)] | Loss: 1.0075\n",
            "TRAIN EPOCH: 0002 [11520/12000(96%)] | Loss: 1.0325\n",
            "\n",
            "TRAIN EPOCH: 0002 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 62.44% \n",
            "VALID EPOCH: 0002 / 0010 | VALID LOSS 0.0066 | VALID ACC 73.60% \n",
            "TRAIN EPOCH: 0003 [1280/12000(11%)] | Loss: 1.0370\n",
            "TRAIN EPOCH: 0003 [2560/12000(21%)] | Loss: 1.0339\n",
            "TRAIN EPOCH: 0003 [3840/12000(32%)] | Loss: 1.0791\n",
            "TRAIN EPOCH: 0003 [5120/12000(43%)] | Loss: 0.9214\n",
            "TRAIN EPOCH: 0003 [6400/12000(53%)] | Loss: 0.7877\n",
            "TRAIN EPOCH: 0003 [7680/12000(64%)] | Loss: 0.9437\n",
            "TRAIN EPOCH: 0003 [8960/12000(74%)] | Loss: 0.9149\n",
            "TRAIN EPOCH: 0003 [10240/12000(85%)] | Loss: 0.8759\n",
            "TRAIN EPOCH: 0003 [11520/12000(96%)] | Loss: 0.8622\n",
            "\n",
            "TRAIN EPOCH: 0003 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 70.28% \n",
            "VALID EPOCH: 0003 / 0010 | VALID LOSS 0.0051 | VALID ACC 81.70% \n",
            "TRAIN EPOCH: 0004 [1280/12000(11%)] | Loss: 0.9290\n",
            "TRAIN EPOCH: 0004 [2560/12000(21%)] | Loss: 0.7201\n",
            "TRAIN EPOCH: 0004 [3840/12000(32%)] | Loss: 0.8242\n",
            "TRAIN EPOCH: 0004 [5120/12000(43%)] | Loss: 0.8344\n",
            "TRAIN EPOCH: 0004 [6400/12000(53%)] | Loss: 0.7920\n",
            "TRAIN EPOCH: 0004 [7680/12000(64%)] | Loss: 0.9243\n",
            "TRAIN EPOCH: 0004 [8960/12000(74%)] | Loss: 0.9740\n",
            "TRAIN EPOCH: 0004 [10240/12000(85%)] | Loss: 0.6974\n",
            "TRAIN EPOCH: 0004 [11520/12000(96%)] | Loss: 0.6900\n",
            "\n",
            "TRAIN EPOCH: 0004 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 75.08% \n",
            "VALID EPOCH: 0004 / 0010 | VALID LOSS 0.0041 | VALID ACC 84.10% \n",
            "TRAIN EPOCH: 0005 [1280/12000(11%)] | Loss: 0.7658\n",
            "TRAIN EPOCH: 0005 [2560/12000(21%)] | Loss: 0.7633\n",
            "TRAIN EPOCH: 0005 [3840/12000(32%)] | Loss: 0.7725\n",
            "TRAIN EPOCH: 0005 [5120/12000(43%)] | Loss: 0.5933\n",
            "TRAIN EPOCH: 0005 [6400/12000(53%)] | Loss: 0.6765\n",
            "TRAIN EPOCH: 0005 [7680/12000(64%)] | Loss: 0.6057\n",
            "TRAIN EPOCH: 0005 [8960/12000(74%)] | Loss: 0.8646\n",
            "TRAIN EPOCH: 0005 [10240/12000(85%)] | Loss: 0.6608\n",
            "TRAIN EPOCH: 0005 [11520/12000(96%)] | Loss: 0.6354\n",
            "\n",
            "TRAIN EPOCH: 0005 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 78.47% \n",
            "VALID EPOCH: 0005 / 0010 | VALID LOSS 0.0033 | VALID ACC 88.00% \n",
            "TRAIN EPOCH: 0006 [1280/12000(11%)] | Loss: 0.6313\n",
            "TRAIN EPOCH: 0006 [2560/12000(21%)] | Loss: 0.7827\n",
            "TRAIN EPOCH: 0006 [3840/12000(32%)] | Loss: 0.6062\n",
            "TRAIN EPOCH: 0006 [5120/12000(43%)] | Loss: 0.5552\n",
            "TRAIN EPOCH: 0006 [6400/12000(53%)] | Loss: 0.7004\n",
            "TRAIN EPOCH: 0006 [7680/12000(64%)] | Loss: 0.6521\n",
            "TRAIN EPOCH: 0006 [8960/12000(74%)] | Loss: 0.5414\n",
            "TRAIN EPOCH: 0006 [10240/12000(85%)] | Loss: 0.6098\n",
            "TRAIN EPOCH: 0006 [11520/12000(96%)] | Loss: 0.7290\n",
            "\n",
            "TRAIN EPOCH: 0006 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 81.07% \n",
            "VALID EPOCH: 0006 / 0010 | VALID LOSS 0.0032 | VALID ACC 87.55% \n",
            "TRAIN EPOCH: 0007 [1280/12000(11%)] | Loss: 0.5307\n",
            "TRAIN EPOCH: 0007 [2560/12000(21%)] | Loss: 0.6189\n",
            "TRAIN EPOCH: 0007 [3840/12000(32%)] | Loss: 0.5580\n",
            "TRAIN EPOCH: 0007 [5120/12000(43%)] | Loss: 0.4371\n",
            "TRAIN EPOCH: 0007 [6400/12000(53%)] | Loss: 0.5992\n",
            "TRAIN EPOCH: 0007 [7680/12000(64%)] | Loss: 0.5787\n",
            "TRAIN EPOCH: 0007 [8960/12000(74%)] | Loss: 0.4306\n",
            "TRAIN EPOCH: 0007 [10240/12000(85%)] | Loss: 0.4795\n",
            "TRAIN EPOCH: 0007 [11520/12000(96%)] | Loss: 0.5153\n",
            "\n",
            "TRAIN EPOCH: 0007 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 82.62% \n",
            "VALID EPOCH: 0007 / 0010 | VALID LOSS 0.0029 | VALID ACC 89.20% \n",
            "TRAIN EPOCH: 0008 [1280/12000(11%)] | Loss: 0.5870\n",
            "TRAIN EPOCH: 0008 [2560/12000(21%)] | Loss: 0.5757\n",
            "TRAIN EPOCH: 0008 [3840/12000(32%)] | Loss: 0.6502\n",
            "TRAIN EPOCH: 0008 [5120/12000(43%)] | Loss: 0.6270\n",
            "TRAIN EPOCH: 0008 [6400/12000(53%)] | Loss: 0.5869\n",
            "TRAIN EPOCH: 0008 [7680/12000(64%)] | Loss: 0.4543\n",
            "TRAIN EPOCH: 0008 [8960/12000(74%)] | Loss: 0.5817\n",
            "TRAIN EPOCH: 0008 [10240/12000(85%)] | Loss: 0.5025\n",
            "TRAIN EPOCH: 0008 [11520/12000(96%)] | Loss: 0.5280\n",
            "\n",
            "TRAIN EPOCH: 0008 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 83.22% \n",
            "VALID EPOCH: 0008 / 0010 | VALID LOSS 0.0025 | VALID ACC 90.45% \n",
            "TRAIN EPOCH: 0009 [1280/12000(11%)] | Loss: 0.5005\n",
            "TRAIN EPOCH: 0009 [2560/12000(21%)] | Loss: 0.6395\n",
            "TRAIN EPOCH: 0009 [3840/12000(32%)] | Loss: 0.5154\n",
            "TRAIN EPOCH: 0009 [5120/12000(43%)] | Loss: 0.5235\n",
            "TRAIN EPOCH: 0009 [6400/12000(53%)] | Loss: 0.5968\n",
            "TRAIN EPOCH: 0009 [7680/12000(64%)] | Loss: 0.5765\n",
            "TRAIN EPOCH: 0009 [8960/12000(74%)] | Loss: 0.4745\n",
            "TRAIN EPOCH: 0009 [10240/12000(85%)] | Loss: 0.4164\n",
            "TRAIN EPOCH: 0009 [11520/12000(96%)] | Loss: 0.3548\n",
            "\n",
            "TRAIN EPOCH: 0009 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 84.82% \n",
            "VALID EPOCH: 0009 / 0010 | VALID LOSS 0.0027 | VALID ACC 89.80% \n",
            "TRAIN EPOCH: 0010 [1280/12000(11%)] | Loss: 0.4713\n",
            "TRAIN EPOCH: 0010 [2560/12000(21%)] | Loss: 0.4130\n",
            "TRAIN EPOCH: 0010 [3840/12000(32%)] | Loss: 0.5276\n",
            "TRAIN EPOCH: 0010 [5120/12000(43%)] | Loss: 0.3827\n",
            "TRAIN EPOCH: 0010 [6400/12000(53%)] | Loss: 0.5620\n",
            "TRAIN EPOCH: 0010 [7680/12000(64%)] | Loss: 0.5514\n",
            "TRAIN EPOCH: 0010 [8960/12000(74%)] | Loss: 0.3399\n",
            "TRAIN EPOCH: 0010 [10240/12000(85%)] | Loss: 0.4672\n",
            "TRAIN EPOCH: 0010 [11520/12000(96%)] | Loss: 0.3131\n",
            "\n",
            "TRAIN EPOCH: 0010 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 85.72% \n",
            "VALID EPOCH: 0010 / 0010 | VALID LOSS 0.0021 | VALID ACC 92.40% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch norm과 augmentation을 적용하여 성능 향상이 되었습니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 모델 저장하고 불러오기\r\n",
        "---\r\n",
        "이번에는 저장하기나 불러오기를 통해 모델의 상태를 유지(persist)하고 모델의 예측을 실행하는 방법을 알아보겠습니다.  \r\n",
        "모델을 저장할 때는 두 가지 방법 중 한 방법을 선택할 수 있는데, 모델 전체를 저장하는 방법과 모델의 state_dict만 저장하는 방법이 있습니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 모델 전체 저장"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Case 1\r\n",
        "torch.save(model, 'ConvNet.pt')\r\n",
        "# Load model\r\n",
        "model = torch.load('ConvNet.pt')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 모델의 state_dict만 저장"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "# Case 1\r\n",
        "torch.save(model.state_dict(), 'ConvNet_dict.pt')\r\n",
        "# Load model\r\n",
        "model.load_state_dict(torch.load('ConvNet_dict.pt'))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔎 model 전체를 저장하는 것과 state_dict만 저장하는 것은 무슨 차이가 있을까요? ([모델 저장하기 & 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)를 참조하세요.)  \r\n",
        "👉 모델 전체를 저장한다는 것의 의미는 모델 파라미터 뿐만 아니라, 옵티마이저(Optimizer), Epoch, 스코어 등 모든 상태를 저장한다는 것입니다. 만약 나중에 이어서 학습을 한다던지, 코드에 접근할 권한이 없는 사용자에게 사용할 수 있도록 합니다. 모델 전체를 저장하는 만큼, 상대적으로 더 큰 용량을 가지게 됩니다.  \r\n",
        "Pytorch에서 모델의 state_dict은 학습가능한 매개변수가 담겨있는 Dictionary입니다. Weight와 bias가 이에 해당합니다. 그러나 매개변수 이외에는 정보가 담겨있지 않기 때문에, 코드 상으로 모델이 구현되어 있는 경우에만 로드를 할 수 있습니다. state_dict만 저장하면 파일의 용량이 가벼워진다는 장점이 있습니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1) 체크포인트(checkpoint) 저장하기 & 불러오기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "torch.save({\r\n",
        "            'epoch': EPOCH,\r\n",
        "            'model_state_dict': model.state_dict(),\r\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "            'loss': criterion,\r\n",
        "            }, \r\n",
        "           'ConvNet_dict.pt')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) \r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\r\n",
        "\r\n",
        "checkpoint = torch.load('ConvNet_dict.pt')\r\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "epoch = checkpoint['epoch']\r\n",
        "loss = checkpoint['loss']"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "print(optimizer)\r\n",
        "print(epoch)\r\n",
        "print(loss)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.01\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "10\n",
            "CrossEntropyLoss()\n"
          ]
        }
      ],
      "metadata": {}
    }
  ]
}