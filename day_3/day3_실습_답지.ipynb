{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "ÌååÏù¥ÌÜ†Ïπò ÏΩîÎìú_0929",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ïù¥ÏõÉÏßë ÌÜ†ÌÜ†Ïπò ÌååÏù¥ÌÜ†Ïπò : Day 3\r\n",
        "\r\n",
        "üì¢ Ìï¥Îãπ Í≤åÏãúÎ¨ºÏùÄ ÌååÏù¥ÌÜ†Ïπò Í≥µÏãù ÌäúÌÜ†Î¶¨Ïñº Ï§ë \r\n",
        "[DATASETÍ≥º DATALOADER](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html)ÏôÄ \r\n",
        "[Î∂ÑÎ•òÍ∏∞(CLASSIFIER) ÌïôÏäµÌïòÍ∏∞](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)\r\n",
        "[Î™®Îç∏ Ï†ÄÏû•ÌïòÍ≥† Î∂àÎü¨Ïò§Í∏∞](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)\r\n",
        "Î•º ÏùΩÍ≥† ÏßÅÏ†ë ÏûëÏÑ±Ìï¥Î≥¥Îäî Ïã§Ïäµ ÎÖ∏Ìä∏Î∂ÅÏûÖÎãàÎã§.  \r\n",
        "\r\n",
        "#### Î™©Ï∞®\r\n",
        "1. DATASETÍ≥º DATALOADER\r\n",
        "    1. ÌïÑÏöî Î™®Îìà Ï§ÄÎπÑ\r\n",
        "    2. Configration ÏÑ§Ï†ï\r\n",
        "    3. Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\r\n",
        "2. PytorchÎ°ú Íµ¨ÌòÑÌïòÎäî MNIST ÏÜêÍ∏ÄÏî® Î∂ÑÎ•òÍ∏∞\r\n",
        "    1. ÎèÑÏö∞ÎØ∏ Ìï®Ïàò Ï†ïÏùò\r\n",
        "    2. Î™®Îç∏ Ï†ïÏùòÌïòÍ∏∞\r\n",
        "    3. ÌïôÏäµ ÏßÑÌñâÌïòÍ∏∞\r\n",
        "    4. Batch Norm Ï†ÅÏö©ÌïòÍ≥† ÌïôÏäµÌïòÍ∏∞\r\n",
        "3. Î™®Îç∏ Ï†ÄÏû•ÌïòÍ≥† Î∂àÎü¨Ïò§Í∏∞\r\n",
        "    1. Î™®Îç∏ Ï†ÑÏ†ú Ï†ÄÏû•\r\n",
        "    2. Î™®Îç∏Ïùò state_dictÎßå Ï†ÄÏû•\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. DATASETÍ≥º DATALOADER\r\n",
        "---\r\n",
        "\r\n",
        "Îç∞Ïù¥ÌÑ∞ ÏÉòÌîåÏùÑ Ï≤òÎ¶¨ÌïòÎäî ÏΩîÎìúÎäî ÏßÄÏ†ÄÎ∂Ñ(messy)ÌïòÍ≥† Ïú†ÏßÄÎ≥¥ÏàòÍ∞Ä Ïñ¥Î†§Ïö∏ Ïàò ÏûàÏäµÎãàÎã§. Îçî ÎÇòÏùÄ Í∞ÄÎèÖÏÑ±(readability)Í≥º Î™®ÎìàÏÑ±(modularity)ÏùÑ ÏúÑÌï¥ Îç∞Ïù¥ÌÑ∞ÏÖã ÏΩîÎìúÎ•º Î™®Îç∏ ÌïôÏäµ ÏΩîÎìúÎ°úÎ∂ÄÌÑ∞ Î∂ÑÎ¶¨ÌïòÎäî Í≤ÉÏù¥ Ïù¥ÏÉÅÏ†ÅÏûÖÎãàÎã§. PyTorchÎäî ``torch.utils.data.DataLoader``ÏôÄ ``torch.utils.data.Dataset`` Ïùò Îëê Í∞ÄÏßÄ Îç∞Ïù¥ÌÑ∞ Í∏∞Î≥∏ ÏöîÏÜåÎ•º Ï†úÍ≥µÌïòÏó¨ ÎØ∏Î¶¨ Ï§ÄÎπÑÌï¥Îêú(pre-loaded) Îç∞Ïù¥ÌÑ∞ÏÖã ÎøêÎßå ÏïÑÎãàÎùº Í∞ÄÏßÄÍ≥† ÏûàÎäî Îç∞Ïù¥ÌÑ∞Î•º ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù Ìï©ÎãàÎã§.\r\n",
        "``Dataset`` ÏùÄ ÏÉòÌîåÍ≥º Ï†ïÎãµ(label)ÏùÑ Ï†ÄÏû•ÌïòÍ≥†, ``DataLoader`` Îäî ``Dataset`` ÏùÑ ÏÉòÌîåÏóê ÏâΩÍ≤å Ï†ëÍ∑ºÌï† Ïàò ÏûàÎèÑÎ°ù ÏàúÌöå Í∞ÄÎä•Ìïú Í∞ùÏ≤¥(iterable)Î°ú Í∞êÏåâÎãàÎã§.\r\n",
        "\r\n",
        "PyTorchÏùò ÎèÑÎ©îÏù∏ ÌäπÌôî ÎùºÏù¥Î∏åÎü¨Î¶¨Îì§ÏùÄ (FashionMNISTÏôÄ Í∞ôÏùÄ) Îã§ÏñëÌïú ÎØ∏Î¶¨ Ï§ÄÎπÑÌï¥Îëî(pre-loaded) Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§. Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ ``torch.utils.data.Dataset`` Ïùò ÌïòÏúÑ ÌÅ¥ÎûòÏä§Î°ú Í∞úÎ≥Ñ Îç∞Ïù¥ÌÑ∞Î•º ÌäπÏ†ïÌïòÎäî Ìï®ÏàòÍ∞Ä Íµ¨ÌòÑÎêòÏñ¥ ÏûàÏäµÎãàÎã§. Ïù¥Îü¨Ìïú Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ Î™®Îç∏ÏùÑ ÎßåÎì§Ïñ¥Î≥¥Í≥†(prototype) ÏÑ±Îä•ÏùÑ Ï∏°Ï†ï(benchmark)ÌïòÎäîÎç∞ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏäµÎãàÎã§.\r\n",
        "\r\n",
        "Ïó¨Í∏∞ÏóêÏÑú Îç∞Ïù¥ÌÑ∞ÏÖãÎì§ÏùÑ Ï∞æÏïÑÎ≥º Ïàò ÏûàÏäµÎãàÎã§:\r\n",
        "[Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ÏÖã](https://pytorch.org/vision/stable/datasets.html), \r\n",
        "[ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã](https://pytorch.org/text/stable/datasets.html) Î∞è\r\n",
        "[Ïò§ÎîîÏò§ Îç∞Ïù¥ÌÑ∞ÏÖã](https://pytorch.org/audio/stable/datasets.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) ÌïÑÏöî Î™®Îìà Ï§ÄÎπÑ"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torch.nn as nn    \r\n",
        "from torchvision import transforms, datasets\r\n",
        "from torch.utils.data import DataLoader, Subset\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "vbhzwyVwIRaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Configration ÏÑ§Ï†ï"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "EPOCH = 10\r\n",
        "BATCH_SIZE = 128\r\n",
        "FC_LAYER_SIZE = 128\r\n",
        "LR = 0.01\r\n",
        "DROOUT = 0.5\r\n",
        "OPTIMIZER = 'sgd'"
      ],
      "outputs": [],
      "metadata": {
        "id": "iLTqzrd0LJik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1) Í∏∞Ï°¥ TorchVision Data Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "train_transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                      transforms.RandomRotation(degrees=45),\r\n",
        "                                      transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2)),\r\n",
        "                                      transforms.Normalize([0.5,],[0.5,])])\r\n",
        "test_transform = transforms.Compose([ transforms.ToTensor(),\r\n",
        "                                      transforms.Normalize([0.5,],[0.5])])\r\n",
        "\r\n",
        "train_dataset = datasets.MNIST(root = '../MNIST', # Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•Îê†Ïû•ÏÜå \r\n",
        "                               train = True, # trainÏù∏ÏßÄ testÏù∏ÏßÄ \r\n",
        "                               download = True,# Ïù∏ÌÑ∞ÎÑ∑ÏóêÏÑú Îã§Ïö¥Î°úÎìúÌï¥ Ïù¥Ïö©Ìï†Í±¥ÏßÄ \r\n",
        "                               transform = train_transform) \r\n",
        "\r\n",
        "test_dataset = datasets.MNIST(root = '../MNIST', train = False,\r\n",
        "                               download = True, transform = test_transform)\r\n",
        "\r\n",
        "# SubsetÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ DatasetÏùò Î∂ÄÎ∂Ñ ÏßëÌï©Îßå Í∞ÄÏ†∏Ïò¨ Ïàò ÏûàÏùå.\r\n",
        "train_sub_dataset = Subset(train_dataset, indices=range(0, len(train_dataset), 5))\r\n",
        "test_sub_dataset = Subset(test_dataset, indices=range(0, len(test_dataset), 5))\r\n",
        "\r\n",
        "train_loader = DataLoader(dataset = train_sub_dataset,\r\n",
        "                         batch_size = BATCH_SIZE,\r\n",
        "                         shuffle = True)\r\n",
        "\r\n",
        "test_loader = DataLoader(dataset = test_sub_dataset,\r\n",
        "                         batch_size = BATCH_SIZE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\pebpung\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ],
      "metadata": {
        "id": "euieV7xAMGpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SubsetÏùÄ DatasetÏùò Î∂ÄÎ∂Ñ ÏßëÌï©ÏùÑ Í∞ÄÏ†∏Ïò§Îäî Ìï®ÏàòÏûÖÎãàÎã§.  \r\n",
        "Dataset ÏõêÎ≥∏ÏúºÎ°ú ÌïôÏäµÏùÑ ÏãúÏº∞ÏùÑ Í≤ΩÏö∞ 16~17Î∂Ñ Ï†ïÎèÑÍ∞Ä Í±∏Î¶¨ÏßÄÎßå, SubsetÏúºÎ°ú ÌïôÏäµÏùÑ Ìï† Í≤ΩÏö∞ 3~4Î∂Ñ Ï†ïÎèÑÍ∞Ä Í±∏Î¶ΩÎãàÎã§. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "X_train, y_train = next(iter(train_loader))\r\n",
        "\r\n",
        "pltsize = 1\r\n",
        "plt.figure(figsize = (10 * pltsize ,pltsize))\r\n",
        "for i in range(10):\r\n",
        "  plt.subplot(1, 10 , i + 1)\r\n",
        "  plt.axis('off')\r\n",
        "  plt.imshow(X_train[i, : , :, :].numpy().reshape(28,28), cmap = 'gray_r')\r\n",
        "  plt.title('class:' + str(y_train[i].item()))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "ih1u4er1cruk",
        "outputId": "7ce5c11b-770a-4074-be58-100a2633ad50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2) Îã§ÏñëÌïú transforms Ï†ÅÏö©Ìï¥Î≥¥Í∏∞"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé Îã§ÏñëÌïú transforms Ï∂îÍ∞ÄÌï¥ÏÑú Mnist Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Î≥ÄÌòïÌï¥Î¥ÖÏãúÎã§!   \r\n",
        "üëâ (3-1ÏóêÏÑú train_transform, test_transformÎ•º Î∞îÍøîÎ≥¥ÏãúÍ∏∏ Î∞îÎûçÎãàÎã§.)  \r\n",
        "üîî [Hint](https://pytorch.org/vision/stable/transforms.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-3) Îçî Îπ†Î•∏ augmentation, albumentations "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé AlbumentationsÏùò Ïû•Ï†êÍ≥º ÌäπÏßïÏùÄ Ïñ¥Îñ§Í≤å ÏûàÏùÑÍπåÏöî?  \r\n",
        "üëâ (Í¥ÑÌò∏Î•º ÏßÄÏö∞Í≥† Ï†ÅÏñ¥Ï£ºÏÑ∏Ïöî!)   \r\n",
        "üîî [Hint](https://hoya012.github.io/blog/albumentation_tutorial/) "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. PytorchÎ°ú Íµ¨ÌòÑÌïòÎäî MNIST ÏÜêÍ∏ÄÏî® Î∂ÑÎ•òÍ∏∞\r\n",
        "---\r\n",
        "Ïö∞Î¶¨Îäî ÏúÑÏóêÏÑú DATASETÍ≥º DATALOADERÎ•º ÏÇ¥Ìé¥Î≥¥ÏïòÏäµÎãàÎã§.  \r\n",
        "Ïù¥Î≤àÏóêÎäî PytorchÎ°ú MNISTÎ•º ÌïôÏäµÌïòÎäî ÏΩîÎìúÎ•º Ï†ÅÏö©Ìï¥Î≥¥Í≤†ÏäµÎãàÎã§.  \r\n",
        "ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú Ï§ëÍ∞ÑÏ§ëÍ∞ÑÏóê ÏûàÎäî Î¨∏Ï†úÎ•º Ìë∏ÏãúÎ©¥ Îê©ÎãàÎã§!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) ÎèÑÏö∞ÎØ∏ Ìï®Ïàò Ï†ïÏùò"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "def train_epoch(network, loader, optimizer, criterion):\r\n",
        "    cumu_loss = 0\r\n",
        "    cumu_acc = 0\r\n",
        "    total = 0\r\n",
        "\r\n",
        "    for _, (data, target) in enumerate(loader):\r\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        loss = criterion(network(data), target)\r\n",
        "        cumu_loss += loss.item()\r\n",
        "        _, predicted = torch.max(network(data).data, 1)\r\n",
        "        total += target.size(0)\r\n",
        "        cumu_acc += (predicted == target).sum().item()\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        network.eval() \r\n",
        "    return cumu_loss / len(loader), 100 * cumu_acc / total"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def evaluate(model, test_loader, criterion):\r\n",
        "  model.eval() # Î™®Îç∏ÏùÑ ÌèâÍ∞ÄÏÉÅÌÉú(test ÏÉÅÌÉú)Î°ú ÏßÄÏ†ï \r\n",
        "  test_loss = 0 # test_loss Ï¥àÍ∏∞Í∞í \r\n",
        "  correct = 0 # Ïò¨Î∞îÎ•∏ classÎ°ú Î∂ÑÎ•òÌïú Ïπ¥Ïö¥Ìä∏Î•º ÏÑ∏Í∏∞ÏúÑÌï¥ 0ÏúºÎ°ú ÏÑ§Ï†ï \r\n",
        "\r\n",
        "  with torch.no_grad(): # ÌèâÍ∞ÄÏãúÏóêÎäî gradiantÎ•º ÌÜµÌï¥ Ìå®Îü¨ÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏Î•º ÌïòÏßÄÏïäÏùå \r\n",
        "    for image, label in test_loader: # mini_batch Îã®ÏúÑÎ°ú Í∫ºÎÇ¥Í∏∞ \r\n",
        "      image = image.to(DEVICE) # DEVICE Ìï†Îãπ\r\n",
        "      label = label.to(DEVICE) # DEVICEÏóê Ìï†Îãπ\r\n",
        "      output = model(image)    # Î™®Îç∏Ïóê inputÏùÑ ÎÑ£Ïñ¥ output Í≥ÑÏÇ∞ \r\n",
        "      test_loss += criterion(output, label).item() # outputÍ≥º labelÏùò loss Í≥ÑÏÇ∞ \r\n",
        "      prediction = output.max(1, keepdim = True)[1] # outputÏùÄ Í∏∏Ïù¥Í∞Ä 10Ïù∏ Î≤°ÌÑ∞Í∞í \r\n",
        "                                                    # Í∑∏Ï§ëÏóêÏÑú Í∞ÄÏû• ÌÅ∞Í∞íÏù∏ ÏúÑÏπòÏùò ÎùºÎ≤®Î°ú\r\n",
        "                                                    # ÏòàÏ∏°ÌñáÎã§Í≥† ÌåêÎã® \r\n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item() # eq() Î©îÏÑúÎìúÎäî ÎùºÎ≤®Í≥º ÏòàÏ∏°Ïù¥ Í∞ôÏúºÎ©¥(equal) 1\r\n",
        "                                                                        # Îã§Î•¥Î©¥ 0. Í∑∏ Í∞íÎì§ÏùÑÎçîÌï¥ÏÑú correctÏóê ÎçîÌï¥Ï£ºÍ∏∞ \r\n",
        "  test_loss /= len(test_loader.dataset)\r\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\r\n",
        "  return test_loss, test_accuracy"
      ],
      "outputs": [],
      "metadata": {
        "id": "nY7vlD-8BBCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Î™®Îç∏ Ï†ïÏùòÌïòÍ∏∞"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self, fc_layer_size, dropout):\r\n",
        "        super(ConvNet, self).__init__() # nn.Module Ïùò init ÏÉÅÏÜç\r\n",
        "        self.layer1 = nn.Sequential(\r\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer2 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer3 = nn.Sequential(\r\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout))\r\n",
        "        self.layer4 = nn.Sequential(\r\n",
        "            nn.Linear(fc_layer_size, 84),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout))\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    # Forward Propagation Ï†ïÏùò\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = x.view(x.size(0),-1) \r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) ÌïôÏäµ ÏßÑÌñâÌïòÍ∏∞"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "if OPTIMIZER == \"sgd\":\r\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\r\n",
        "elif OPTIMIZER == \"adam\":\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\r\n",
        "criterion = nn.CrossEntropyLoss() # Loss Í∏∞Ï§ÄÏùÄ CrossEntropyLossÎ°ú"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OD4YKjG-tkc",
        "outputId": "53640226-1aaf-4122-9a78-6a82b2a87bae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîé torch.optimÏóêÎäî Ïñ¥Îñ§ optimizerÎì§ÏùÑ Íµ¨ÌòÑÌï† Ïàò ÏûàÎÇòÏöî? ([Í≥µÏãù document](https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim)Î•º Ï∞∏Ï°∞ÌïòÏó¨ 2Í∞ú Ïù¥ÏÉÅ Ï†ÅÏñ¥Ï£ºÏÑ∏Ïöî.)**  \r\n",
        "üëâ ÎåÄÌëúÏ†ÅÏúºÎ°ú ADAM, RMSpropÎì± Îã§ÏñëÌïú optimizerÍ∞Ä ÏûàÏäµÎãàÎã§. ÎòêÌïú schedulerÎ•º ÏÇ¨Ïö©Ìï¥ÏÑú ÌïôÏäµ Ìö®Ïú®ÏùÑ ÎÜíÏùº Ïàò ÏûàÏäµÎãàÎã§"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîé nn.ModuleÏóêÏÑú ÌôúÏö©Ìï† Ïàò ÏûàÎäî Loss functionÏóêÎäî Ïñ¥Îñ§ Í≤ÉÎì§Ïù¥ ÏûàÎÇòÏöî? ([Í≥µÏãù document-Loss function](https://pytorch.org/docs/stable/nn.html?highlight=loss#loss-functions)Î•º Ï∞∏Ï°∞ÌïòÏó¨ 2Í∞ú Ïù¥ÏÉÅ Ï†ÅÏñ¥Ï£ºÏÑ∏Ïöî.)**  \r\n",
        "üëâ NLLLoss: null lossÎùºÍ≥† ÏùΩÏóàÎäîÎç∞ ÏïåÍ≥†Î≥¥Îãà negative log likelihood lossÏù¥Îã§.  \r\n",
        "KLDivLoss: Kullback-Leibler divergence loss Ïù¥Îã§. GANÏóêÏÑú Ï§ëÏöîÌïú Í∞úÎÖêÏúºÎ°ú ÏÇ¨Ïö©ÎêúÎã§.  \r\n",
        "SmoothL1Loss: YOLOv1Í≥º YOLOv2ÏóêÏÑú ÌôúÏö©ÎêúÎã§. L1 lossÏôÄ L2 lossÎ•º Ï†ÅÏ†àÌïòÍ≤å ÌòºÌï©Ìï®.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1) Í∏∞Î≥∏ augmentationÏùÑ Ï†ÅÏö©"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "source": [
        "for epoch in range(EPOCH):\r\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\r\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.9152 | Epoch ACC 41.38% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.3931 | Epoch ACC 87.54% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.2097 | Epoch ACC 93.58% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1493 | Epoch ACC 95.37% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.1046 | Epoch ACC 96.83% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0897 | Epoch ACC 97.32% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0689 | Epoch ACC 98.03% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0607 | Epoch ACC 98.11% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0527 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0454 | Epoch ACC 98.70% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\r\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0006 | Test ACC 97.90% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2) RandomRotation, RandomAffineÏùÑ Ï∂îÍ∞Ä"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "for epoch in range(EPOCH):\r\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\r\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\pebpung\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 2.2399 | Epoch ACC 19.51% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 1.7524 | Epoch ACC 38.83% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 1.2340 | Epoch ACC 58.13% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.7992 | Epoch ACC 73.77% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.6238 | Epoch ACC 80.41% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.5233 | Epoch ACC 83.28% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.4151 | Epoch ACC 86.98% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.3697 | Epoch ACC 88.33% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.3327 | Epoch ACC 89.96% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.2974 | Epoch ACC 90.70% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\r\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0022 | Test ACC 91.55% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "train ÌïôÏäµ ÏãúÏóêÎäî Í∏∞Î≥∏ augmentationÏùÑ Ï†ÅÏö©Ìïú Í≤É Î≥¥Îã§ ACCÍ∞Ä ÎÇÆÏïÑÏßÄÏßÄÎßå, evaluate ÏãúÏóêÎäî Îçî Ï¢ãÏïÑÏßëÎãàÎã§.  \r\n",
        "Ïôú Ïù¥Îü∞ Í≤∞Í≥ºÍ∞Ä ÏÉùÍ≤ºÏùÑÍπåÏöî?  \r\n",
        "Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ïÏùÄ train ÌïôÏäµ ÏãúÏóê ÏÑ±Îä• Ìñ•ÏÉÅÏùÑ Î™©Ï†ÅÏúºÎ°ú ÌïòÎäî Í≤ÉÏù¥ ÏïÑÎãàÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§.  \r\n",
        "Îçî Îã§ÏñëÌïú Î™®ÏäµÏùò Îç∞Ïù¥ÌÑ∞Î°ú ÌïôÏäµÌïòÏó¨ ÏÉàÎ°ú Îì§Ïñ¥Ïò§Îäî test dataÏóê ÎåÄÌï¥ÏÑú robust Ìïú Î™®Îç∏ÏùÑ ÎßåÎìúÎäî Í≤ÉÏù¥ Î™©Ï†ÅÏù¥Í∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§.  \r\n",
        "Í∑∏ÎûòÏÑú train acc ÎøêÎßå ÏïÑÎãàÎùº, valid accÎ•º Ï∂îÍ∞ÄÌï¥ÏÑú ÎπÑÍµêÌïòÎäî Í≤ÉÏù¥ Ïò≥ÏäµÎãàÎã§.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) train, valid Ìï®Ïàò Ïû¨Ï†ïÏùò"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "len(train_loader.dataset)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "def train(model, loader, optimizer, criterion):\r\n",
        "    model.train()\r\n",
        "    loss = 0\r\n",
        "    correct = 0\r\n",
        "\r\n",
        "    for batch_idx, (data, target) in enumerate(loader):\r\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\r\n",
        "\r\n",
        "        output = model(data)\r\n",
        "        loss = criterion(output, target)\r\n",
        "\r\n",
        "        pred = output.data.max(1, keepdim=True)[1]\r\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if (batch_idx + 1)% 10 == 0:\r\n",
        "            print(f'TRAIN EPOCH: {epoch + 1:04d} [{(batch_idx + 1) * len(data)} / {len(train_loader.dataset)}', end='') \r\n",
        "            print(f'({100. * (batch_idx + 1) / len(train_loader):.0f}%)] | Loss: {loss.data.item():.4f}')\r\n",
        "                \r\n",
        "    loss /= len(loader.dataset)\r\n",
        "    acc = (100.0 * float(correct) / len(loader.dataset))\r\n",
        "    print(f\"\\nTRAIN EPOCH: {epoch + 1:02d} / {EPOCH:02d} | TRAIN LOSS {loss:.4f} | TRAIN ACC {acc:.2f}% \")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "def validate(model, val_loader,criterion):\r\n",
        "    model.eval()\r\n",
        "    loss = 0\r\n",
        "    correct = 0\r\n",
        "    \r\n",
        "    for _, (data, target) in enumerate(val_loader):\r\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\r\n",
        "        \r\n",
        "        output = model(data)\r\n",
        "        loss += criterion(output, target).data.item()\r\n",
        "\r\n",
        "        pred = output.data.max(1, keepdim=True)[1]\r\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\r\n",
        "        \r\n",
        "    loss /= len(val_loader.dataset)\r\n",
        "    acc = (100.0 * float(correct) / len(val_loader.dataset))\r\n",
        "        \r\n",
        "    print(f\"VALID EPOCH: {epoch + 1:02d} / {EPOCH:02d} | VALID LOSS {loss:.4f} | VALID ACC {acc:.2f}% \")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) BATCH NormalizationÏ†ÅÏö©ÌïòÍ≥† ÌïôÏäµÌïòÍ∏∞"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self, fc_layer_size, dropout):\r\n",
        "        super(ConvNet, self).__init__() # nn.Module Ïùò init ÏÉÅÏÜç\r\n",
        "        self.layer1 = nn.Sequential(\r\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer2 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2, 2))\r\n",
        "        self.layer3 = nn.Sequential(\r\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\r\n",
        "            nn.BatchNorm1d(fc_layer_size),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout),)\r\n",
        "        self.layer4 = nn.Sequential(\r\n",
        "            nn.Linear(fc_layer_size, 84),\r\n",
        "            nn.BatchNorm1d(84),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout2d(p=dropout),)\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    # Forward Propagation Ï†ïÏùò\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = x.view(x.size(0),-1) \r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "if OPTIMIZER == \"sgd\":\r\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\r\n",
        "elif OPTIMIZER == \"adam\":\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\r\n",
        "criterion = nn.CrossEntropyLoss() # Loss Í∏∞Ï§ÄÏùÄ CrossEntropyLossÎ°ú"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "for epoch in range(EPOCH):\r\n",
        "    print(f'\\nEPOCH: {epoch + 1:02d} / {EPOCH:02d}')\r\n",
        "    train(model, train_loader, optimizer, criterion)\r\n",
        "    validate(model, test_loader, criterion)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN EPOCH: 0001 [1280/12000(11%)] | Loss: 2.2922\n",
            "TRAIN EPOCH: 0001 [2560/12000(21%)] | Loss: 2.1039\n",
            "TRAIN EPOCH: 0001 [3840/12000(32%)] | Loss: 1.9311\n",
            "TRAIN EPOCH: 0001 [5120/12000(43%)] | Loss: 1.8069\n",
            "TRAIN EPOCH: 0001 [6400/12000(53%)] | Loss: 1.6952\n",
            "TRAIN EPOCH: 0001 [7680/12000(64%)] | Loss: 1.8289\n",
            "TRAIN EPOCH: 0001 [8960/12000(74%)] | Loss: 1.5761\n",
            "TRAIN EPOCH: 0001 [10240/12000(85%)] | Loss: 1.4745\n",
            "TRAIN EPOCH: 0001 [11520/12000(96%)] | Loss: 1.4170\n",
            "\n",
            "TRAIN EPOCH: 0001 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 38.39% \n",
            "VALID EPOCH: 0001 / 0010 | VALID LOSS 0.0100 | VALID ACC 62.65% \n",
            "TRAIN EPOCH: 0002 [1280/12000(11%)] | Loss: 1.3130\n",
            "TRAIN EPOCH: 0002 [2560/12000(21%)] | Loss: 1.2054\n",
            "TRAIN EPOCH: 0002 [3840/12000(32%)] | Loss: 1.2104\n",
            "TRAIN EPOCH: 0002 [5120/12000(43%)] | Loss: 1.2261\n",
            "TRAIN EPOCH: 0002 [6400/12000(53%)] | Loss: 1.1391\n",
            "TRAIN EPOCH: 0002 [7680/12000(64%)] | Loss: 1.0530\n",
            "TRAIN EPOCH: 0002 [8960/12000(74%)] | Loss: 1.0968\n",
            "TRAIN EPOCH: 0002 [10240/12000(85%)] | Loss: 1.0075\n",
            "TRAIN EPOCH: 0002 [11520/12000(96%)] | Loss: 1.0325\n",
            "\n",
            "TRAIN EPOCH: 0002 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 62.44% \n",
            "VALID EPOCH: 0002 / 0010 | VALID LOSS 0.0066 | VALID ACC 73.60% \n",
            "TRAIN EPOCH: 0003 [1280/12000(11%)] | Loss: 1.0370\n",
            "TRAIN EPOCH: 0003 [2560/12000(21%)] | Loss: 1.0339\n",
            "TRAIN EPOCH: 0003 [3840/12000(32%)] | Loss: 1.0791\n",
            "TRAIN EPOCH: 0003 [5120/12000(43%)] | Loss: 0.9214\n",
            "TRAIN EPOCH: 0003 [6400/12000(53%)] | Loss: 0.7877\n",
            "TRAIN EPOCH: 0003 [7680/12000(64%)] | Loss: 0.9437\n",
            "TRAIN EPOCH: 0003 [8960/12000(74%)] | Loss: 0.9149\n",
            "TRAIN EPOCH: 0003 [10240/12000(85%)] | Loss: 0.8759\n",
            "TRAIN EPOCH: 0003 [11520/12000(96%)] | Loss: 0.8622\n",
            "\n",
            "TRAIN EPOCH: 0003 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 70.28% \n",
            "VALID EPOCH: 0003 / 0010 | VALID LOSS 0.0051 | VALID ACC 81.70% \n",
            "TRAIN EPOCH: 0004 [1280/12000(11%)] | Loss: 0.9290\n",
            "TRAIN EPOCH: 0004 [2560/12000(21%)] | Loss: 0.7201\n",
            "TRAIN EPOCH: 0004 [3840/12000(32%)] | Loss: 0.8242\n",
            "TRAIN EPOCH: 0004 [5120/12000(43%)] | Loss: 0.8344\n",
            "TRAIN EPOCH: 0004 [6400/12000(53%)] | Loss: 0.7920\n",
            "TRAIN EPOCH: 0004 [7680/12000(64%)] | Loss: 0.9243\n",
            "TRAIN EPOCH: 0004 [8960/12000(74%)] | Loss: 0.9740\n",
            "TRAIN EPOCH: 0004 [10240/12000(85%)] | Loss: 0.6974\n",
            "TRAIN EPOCH: 0004 [11520/12000(96%)] | Loss: 0.6900\n",
            "\n",
            "TRAIN EPOCH: 0004 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 75.08% \n",
            "VALID EPOCH: 0004 / 0010 | VALID LOSS 0.0041 | VALID ACC 84.10% \n",
            "TRAIN EPOCH: 0005 [1280/12000(11%)] | Loss: 0.7658\n",
            "TRAIN EPOCH: 0005 [2560/12000(21%)] | Loss: 0.7633\n",
            "TRAIN EPOCH: 0005 [3840/12000(32%)] | Loss: 0.7725\n",
            "TRAIN EPOCH: 0005 [5120/12000(43%)] | Loss: 0.5933\n",
            "TRAIN EPOCH: 0005 [6400/12000(53%)] | Loss: 0.6765\n",
            "TRAIN EPOCH: 0005 [7680/12000(64%)] | Loss: 0.6057\n",
            "TRAIN EPOCH: 0005 [8960/12000(74%)] | Loss: 0.8646\n",
            "TRAIN EPOCH: 0005 [10240/12000(85%)] | Loss: 0.6608\n",
            "TRAIN EPOCH: 0005 [11520/12000(96%)] | Loss: 0.6354\n",
            "\n",
            "TRAIN EPOCH: 0005 / 0010 | TRAIN LOSS 0.0001 | TRAIN ACC 78.47% \n",
            "VALID EPOCH: 0005 / 0010 | VALID LOSS 0.0033 | VALID ACC 88.00% \n",
            "TRAIN EPOCH: 0006 [1280/12000(11%)] | Loss: 0.6313\n",
            "TRAIN EPOCH: 0006 [2560/12000(21%)] | Loss: 0.7827\n",
            "TRAIN EPOCH: 0006 [3840/12000(32%)] | Loss: 0.6062\n",
            "TRAIN EPOCH: 0006 [5120/12000(43%)] | Loss: 0.5552\n",
            "TRAIN EPOCH: 0006 [6400/12000(53%)] | Loss: 0.7004\n",
            "TRAIN EPOCH: 0006 [7680/12000(64%)] | Loss: 0.6521\n",
            "TRAIN EPOCH: 0006 [8960/12000(74%)] | Loss: 0.5414\n",
            "TRAIN EPOCH: 0006 [10240/12000(85%)] | Loss: 0.6098\n",
            "TRAIN EPOCH: 0006 [11520/12000(96%)] | Loss: 0.7290\n",
            "\n",
            "TRAIN EPOCH: 0006 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 81.07% \n",
            "VALID EPOCH: 0006 / 0010 | VALID LOSS 0.0032 | VALID ACC 87.55% \n",
            "TRAIN EPOCH: 0007 [1280/12000(11%)] | Loss: 0.5307\n",
            "TRAIN EPOCH: 0007 [2560/12000(21%)] | Loss: 0.6189\n",
            "TRAIN EPOCH: 0007 [3840/12000(32%)] | Loss: 0.5580\n",
            "TRAIN EPOCH: 0007 [5120/12000(43%)] | Loss: 0.4371\n",
            "TRAIN EPOCH: 0007 [6400/12000(53%)] | Loss: 0.5992\n",
            "TRAIN EPOCH: 0007 [7680/12000(64%)] | Loss: 0.5787\n",
            "TRAIN EPOCH: 0007 [8960/12000(74%)] | Loss: 0.4306\n",
            "TRAIN EPOCH: 0007 [10240/12000(85%)] | Loss: 0.4795\n",
            "TRAIN EPOCH: 0007 [11520/12000(96%)] | Loss: 0.5153\n",
            "\n",
            "TRAIN EPOCH: 0007 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 82.62% \n",
            "VALID EPOCH: 0007 / 0010 | VALID LOSS 0.0029 | VALID ACC 89.20% \n",
            "TRAIN EPOCH: 0008 [1280/12000(11%)] | Loss: 0.5870\n",
            "TRAIN EPOCH: 0008 [2560/12000(21%)] | Loss: 0.5757\n",
            "TRAIN EPOCH: 0008 [3840/12000(32%)] | Loss: 0.6502\n",
            "TRAIN EPOCH: 0008 [5120/12000(43%)] | Loss: 0.6270\n",
            "TRAIN EPOCH: 0008 [6400/12000(53%)] | Loss: 0.5869\n",
            "TRAIN EPOCH: 0008 [7680/12000(64%)] | Loss: 0.4543\n",
            "TRAIN EPOCH: 0008 [8960/12000(74%)] | Loss: 0.5817\n",
            "TRAIN EPOCH: 0008 [10240/12000(85%)] | Loss: 0.5025\n",
            "TRAIN EPOCH: 0008 [11520/12000(96%)] | Loss: 0.5280\n",
            "\n",
            "TRAIN EPOCH: 0008 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 83.22% \n",
            "VALID EPOCH: 0008 / 0010 | VALID LOSS 0.0025 | VALID ACC 90.45% \n",
            "TRAIN EPOCH: 0009 [1280/12000(11%)] | Loss: 0.5005\n",
            "TRAIN EPOCH: 0009 [2560/12000(21%)] | Loss: 0.6395\n",
            "TRAIN EPOCH: 0009 [3840/12000(32%)] | Loss: 0.5154\n",
            "TRAIN EPOCH: 0009 [5120/12000(43%)] | Loss: 0.5235\n",
            "TRAIN EPOCH: 0009 [6400/12000(53%)] | Loss: 0.5968\n",
            "TRAIN EPOCH: 0009 [7680/12000(64%)] | Loss: 0.5765\n",
            "TRAIN EPOCH: 0009 [8960/12000(74%)] | Loss: 0.4745\n",
            "TRAIN EPOCH: 0009 [10240/12000(85%)] | Loss: 0.4164\n",
            "TRAIN EPOCH: 0009 [11520/12000(96%)] | Loss: 0.3548\n",
            "\n",
            "TRAIN EPOCH: 0009 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 84.82% \n",
            "VALID EPOCH: 0009 / 0010 | VALID LOSS 0.0027 | VALID ACC 89.80% \n",
            "TRAIN EPOCH: 0010 [1280/12000(11%)] | Loss: 0.4713\n",
            "TRAIN EPOCH: 0010 [2560/12000(21%)] | Loss: 0.4130\n",
            "TRAIN EPOCH: 0010 [3840/12000(32%)] | Loss: 0.5276\n",
            "TRAIN EPOCH: 0010 [5120/12000(43%)] | Loss: 0.3827\n",
            "TRAIN EPOCH: 0010 [6400/12000(53%)] | Loss: 0.5620\n",
            "TRAIN EPOCH: 0010 [7680/12000(64%)] | Loss: 0.5514\n",
            "TRAIN EPOCH: 0010 [8960/12000(74%)] | Loss: 0.3399\n",
            "TRAIN EPOCH: 0010 [10240/12000(85%)] | Loss: 0.4672\n",
            "TRAIN EPOCH: 0010 [11520/12000(96%)] | Loss: 0.3131\n",
            "\n",
            "TRAIN EPOCH: 0010 / 0010 | TRAIN LOSS 0.0000 | TRAIN ACC 85.72% \n",
            "VALID EPOCH: 0010 / 0010 | VALID LOSS 0.0021 | VALID ACC 92.40% \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch normÍ≥º augmentationÏùÑ Ï†ÅÏö©ÌïòÏó¨ ÏÑ±Îä• Ìñ•ÏÉÅÏù¥ ÎêòÏóàÏäµÎãàÎã§."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Î™®Îç∏ Ï†ÄÏû•ÌïòÍ≥† Î∂àÎü¨Ïò§Í∏∞\r\n",
        "---\r\n",
        "Ïù¥Î≤àÏóêÎäî Ï†ÄÏû•ÌïòÍ∏∞ÎÇò Î∂àÎü¨Ïò§Í∏∞Î•º ÌÜµÌï¥ Î™®Îç∏Ïùò ÏÉÅÌÉúÎ•º Ïú†ÏßÄ(persist)ÌïòÍ≥† Î™®Îç∏Ïùò ÏòàÏ∏°ÏùÑ Ïã§ÌñâÌïòÎäî Î∞©Î≤ïÏùÑ ÏïåÏïÑÎ≥¥Í≤†ÏäµÎãàÎã§.  \r\n",
        "Î™®Îç∏ÏùÑ Ï†ÄÏû•Ìï† ÎïåÎäî Îëê Í∞ÄÏßÄ Î∞©Î≤ï Ï§ë Ìïú Î∞©Î≤ïÏùÑ ÏÑ†ÌÉùÌï† Ïàò ÏûàÎäîÎç∞, Î™®Îç∏ Ï†ÑÏ≤¥Î•º Ï†ÄÏû•ÌïòÎäî Î∞©Î≤ïÍ≥º Î™®Îç∏Ïùò state_dictÎßå Ï†ÄÏû•ÌïòÎäî Î∞©Î≤ïÏù¥ ÏûàÏäµÎãàÎã§."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Î™®Îç∏ Ï†ÑÏ≤¥ Ï†ÄÏû•"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Case 1\r\n",
        "torch.save(model, 'ConvNet.pt')\r\n",
        "# Load model\r\n",
        "model = torch.load('ConvNet.pt')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Î™®Îç∏Ïùò state_dictÎßå Ï†ÄÏû•"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "# Case 1\r\n",
        "torch.save(model.state_dict(), 'ConvNet_dict.pt')\r\n",
        "# Load model\r\n",
        "model.load_state_dict(torch.load('ConvNet_dict.pt'))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé model Ï†ÑÏ≤¥Î•º Ï†ÄÏû•ÌïòÎäî Í≤ÉÍ≥º state_dictÎßå Ï†ÄÏû•ÌïòÎäî Í≤ÉÏùÄ Î¨¥Ïä® Ï∞®Ïù¥Í∞Ä ÏûàÏùÑÍπåÏöî? ([Î™®Îç∏ Ï†ÄÏû•ÌïòÍ∏∞ & Î∂àÎü¨Ïò§Í∏∞](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)Î•º Ï∞∏Ï°∞ÌïòÏÑ∏Ïöî.)  \r\n",
        "üëâ Î™®Îç∏ Ï†ÑÏ≤¥Î•º Ï†ÄÏû•ÌïúÎã§Îäî Í≤ÉÏùò ÏùòÎØ∏Îäî Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ ÎøêÎßå ÏïÑÎãàÎùº, ÏòµÌã∞ÎßàÏù¥Ï†Ä(Optimizer), Epoch, Ïä§ÏΩîÏñ¥ Îì± Î™®Îì† ÏÉÅÌÉúÎ•º Ï†ÄÏû•ÌïúÎã§Îäî Í≤ÉÏûÖÎãàÎã§. ÎßåÏïΩ ÎÇòÏ§ëÏóê Ïù¥Ïñ¥ÏÑú ÌïôÏäµÏùÑ ÌïúÎã§ÎçòÏßÄ, ÏΩîÎìúÏóê Ï†ëÍ∑ºÌï† Í∂åÌïúÏù¥ ÏóÜÎäî ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù Ìï©ÎãàÎã§. Î™®Îç∏ Ï†ÑÏ≤¥Î•º Ï†ÄÏû•ÌïòÎäî ÎßåÌÅº, ÏÉÅÎåÄÏ†ÅÏúºÎ°ú Îçî ÌÅ∞ Ïö©ÎüâÏùÑ Í∞ÄÏßÄÍ≤å Îê©ÎãàÎã§.  \r\n",
        "PytorchÏóêÏÑú Î™®Îç∏Ïùò state_dictÏùÄ ÌïôÏäµÍ∞ÄÎä•Ìïú Îß§Í∞úÎ≥ÄÏàòÍ∞Ä Îã¥Í≤®ÏûàÎäî DictionaryÏûÖÎãàÎã§. WeightÏôÄ biasÍ∞Ä Ïù¥Ïóê Ìï¥ÎãπÌï©ÎãàÎã§. Í∑∏Îü¨ÎÇò Îß§Í∞úÎ≥ÄÏàò Ïù¥Ïô∏ÏóêÎäî Ï†ïÎ≥¥Í∞Ä Îã¥Í≤®ÏûàÏßÄ ÏïäÍ∏∞ ÎïåÎ¨∏Ïóê, ÏΩîÎìú ÏÉÅÏúºÎ°ú Î™®Îç∏Ïù¥ Íµ¨ÌòÑÎêòÏñ¥ ÏûàÎäî Í≤ΩÏö∞ÏóêÎßå Î°úÎìúÎ•º Ìï† Ïàò ÏûàÏäµÎãàÎã§. state_dictÎßå Ï†ÄÏû•ÌïòÎ©¥ ÌååÏùºÏùò Ïö©ÎüâÏù¥ Í∞ÄÎ≤ºÏõåÏßÑÎã§Îäî Ïû•Ï†êÏù¥ ÏûàÏäµÎãàÎã§."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1) Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏(checkpoint) Ï†ÄÏû•ÌïòÍ∏∞ & Î∂àÎü¨Ïò§Í∏∞"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "torch.save({\r\n",
        "            'epoch': EPOCH,\r\n",
        "            'model_state_dict': model.state_dict(),\r\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "            'loss': criterion,\r\n",
        "            }, \r\n",
        "           'ConvNet_dict.pt')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) \r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\r\n",
        "\r\n",
        "checkpoint = torch.load('ConvNet_dict.pt')\r\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "epoch = checkpoint['epoch']\r\n",
        "loss = checkpoint['loss']"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "print(optimizer)\r\n",
        "print(epoch)\r\n",
        "print(loss)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.01\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "10\n",
            "CrossEntropyLoss()\n"
          ]
        }
      ],
      "metadata": {}
    }
  ]
}