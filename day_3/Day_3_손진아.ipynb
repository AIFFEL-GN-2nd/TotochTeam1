{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_3_손진아",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjeena0722/TotochTeam1/blob/main/day_3/Day_3_%EC%86%90%EC%A7%84%EC%95%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qutt2gWe721X"
      },
      "source": [
        "# 이웃집 토토치 파이토치 : Day 3\n",
        "\n",
        "📢 해당 게시물은 파이토치 공식 튜토리얼 중 \n",
        "[DATASET과 DATALOADER](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html)와 \n",
        "[분류기(CLASSIFIER) 학습하기](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)\n",
        "[모델 저장하고 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)\n",
        "를 읽고 직접 작성해보는 실습 노트북입니다.  \n",
        "\n",
        "#### 목차\n",
        "1. DATASET과 DATALOADER\n",
        "    1. 필요 모듈 준비\n",
        "    2. Configration 설정\n",
        "    3. 데이터 준비\n",
        "2. Pytorch로 구현하는 MNIST 손글씨 분류기\n",
        "    1. 도우미 함수 정의\n",
        "    2. 모델 정의하기\n",
        "    3. 학습 진행하기\n",
        "    4. Batch Norm 적용하고 학습하기\n",
        "3. 모델 저장하고 불러오기\n",
        "    1. 모델 전제 저장\n",
        "    2. 모델의 state_dict만 저장\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMlvZ7se721h"
      },
      "source": [
        "# 1. DATASET과 DATALOADER\n",
        "---\n",
        "\n",
        "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\n",
        "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
        "\n",
        "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\n",
        "\n",
        "여기에서 데이터셋들을 찾아볼 수 있습니다:\n",
        "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \n",
        "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\n",
        "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s56hF2u6721m"
      },
      "source": [
        "## 1) 필요 모듈 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbhzwyVwIRaq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn    \n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpHqxBV8721q"
      },
      "source": [
        "## 2) Configration 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLTqzrd0LJik"
      },
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 128\n",
        "FC_LAYER_SIZE = 128\n",
        "LR = 0.01\n",
        "DROOUT = 0.5\n",
        "OPTIMIZER = 'sgd'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjQHHjX1721r"
      },
      "source": [
        "## 3) 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpNEi2F721s"
      },
      "source": [
        "### 3-1) 기존 TorchVision Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euieV7xAMGpE"
      },
      "source": [
        "\n",
        "train_transform = transforms.Compose([#transforms.CenterCrop(10),\n",
        "                                      transforms.Pad(padding=30),\n",
        "                                      transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "                                      #transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5,],[0.5,])])\n",
        "test_transform = transforms.Compose([#transforms.CenterCrop(10),\n",
        "                                     transforms.Pad(padding=30),\n",
        "                                     transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "                                     #transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5,],[0.5])])\n",
        "\n",
        "\n",
        "train_dataset = datasets.MNIST(root = '../MNIST', # 데이터 저장될장소 \n",
        "                               train = True, # train인지 test인지 \n",
        "                               download = True,# 인터넷에서 다운로드해 이용할건지 \n",
        "                               transform = train_transform) \n",
        "\n",
        "test_dataset = datasets.MNIST(root = '../MNIST', train = False,\n",
        "                               download = True, transform = test_transform)\n",
        "\n",
        "# Subset을 사용하면 Dataset의 부분 집합만 가져올 수 있음.\n",
        "train_sub_dataset = Subset(train_dataset, indices=range(0, len(train_dataset), 5))\n",
        "test_sub_dataset = Subset(test_dataset, indices=range(0, len(test_dataset), 5))\n",
        "\n",
        "train_loader = DataLoader(dataset = train_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he-GrRD0721v"
      },
      "source": [
        "Subset은 Dataset의 부분 집합을 가져오는 함수입니다.  \n",
        "Dataset 원본으로 학습을 시켰을 경우 16~17분 정도가 걸리지만, Subset으로 학습을 할 경우 3~4분 정도가 걸립니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "ih1u4er1cruk",
        "outputId": "44df5c4b-a73d-4190-a7f9-5313976d77f9"
      },
      "source": [
        "X_train, y_train = next(iter(train_loader))\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize = (10 * pltsize ,pltsize))\n",
        "for i in range(10):\n",
        "  plt.subplot(1, 10 , i + 1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(X_train[i, : , :, :].numpy().reshape(88,88), cmap = 'gray_r')\n",
        "  plt.title('class:' + str(y_train[i].item()))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBn758Nq721y"
      },
      "source": [
        "### 3-2) 다양한 transforms 적용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_AKbbCa721z"
      },
      "source": [
        "🔎 다양한 transforms 추가해서 Mnist 데이터셋을 변형해봅시다!   \n",
        "👉 (3-1에서 train_transform, test_transform를 바꿔보시길 바랍니다.)  \n",
        "🔔 [Hint](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOiGrudY7210"
      },
      "source": [
        "### 3-3) 더 빠른 augmentation, albumentations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95GvR8397214"
      },
      "source": [
        "🔎 Albumentations의 장점과 특징은 어떤게 있을까요?  \n",
        "👉  처리속도가 빠름, 기능이 다양 <br>\n",
        "🔔 [Hint](https://hoya012.github.io/blog/albumentation_tutorial/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QOapvUn7214"
      },
      "source": [
        "# 2. Pytorch로 구현하는 MNIST 손글씨 분류기\n",
        "---\n",
        "우리는 위에서 DATASET과 DATALOADER를 살펴보았습니다.  \n",
        "이번에는 Pytorch로 MNIST를 학습하는 코드를 적용해보겠습니다.  \n",
        "마찬가지로 중간중간에 있는 문제를 푸시면 됩니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-wb6koj7215"
      },
      "source": [
        "## 1) 도우미 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uoU8juA7215"
      },
      "source": [
        "def train_epoch(network, loader, optimizer, criterion):\n",
        "    cumu_loss = 0\n",
        "    cumu_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    for _, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(network(data), target)\n",
        "        cumu_loss += loss.item()\n",
        "        _, predicted = torch.max(network(data).data, 1)\n",
        "        total += target.size(0)\n",
        "        cumu_acc += (predicted == target).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        network.eval() \n",
        "    return cumu_loss / len(loader), 100 * cumu_acc / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY7vlD-8BBCC"
      },
      "source": [
        "def evaluate(model, test_loader, criterion):\n",
        "  model.eval() # 모델을 평가상태(test 상태)로 지정 \n",
        "  test_loss = 0 # test_loss 초기값 \n",
        "  correct = 0 # 올바른 class로 분류한 카운트를 세기위해 0으로 설정 \n",
        "\n",
        "  with torch.no_grad(): # 평가시에는 gradiant를 통해 패러미터 업데이트를 하지않음 \n",
        "    for image, label in test_loader: # mini_batch 단위로 꺼내기 \n",
        "      image = image.to(DEVICE) # DEVICE 할당\n",
        "      label = label.to(DEVICE) # DEVICE에 할당\n",
        "      output = model(image)    # 모델에 input을 넣어 output 계산 \n",
        "      test_loss += criterion(output, label).item() # output과 label의 loss 계산 \n",
        "      prediction = output.max(1, keepdim = True)[1] # output은 길이가 10인 벡터값 \n",
        "                                                    # 그중에서 가장 큰값인 위치의 라벨로\n",
        "                                                    # 예측햇다고 판단 \n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item() # eq() 메서드는 라벨과 예측이 같으면(equal) 1\n",
        "                                                                        # 다르면 0. 그 값들을더해서 correct에 더해주기 \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt0_dIHx7217"
      },
      "source": [
        "## 2) 모델 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkaFqWLH7218"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation 정의\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCSb_1JW7218"
      },
      "source": [
        "## 3) 학습 진행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OD4YKjG-tkc"
      },
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8gefTlA7219"
      },
      "source": [
        "**🔎 torch.optim에는 어떤 optimizer들을 구현할 수 있나요? ([공식 document](https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim)를 참조하여 2개 이상 적어주세요.)**  \n",
        "👉 (괄호를 지우고 적어주세요!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaBnS50X721-"
      },
      "source": [
        "**🔎 nn.Module에서 활용할 수 있는 Loss function에는 어떤 것들이 구현할 수 있나요? ([공식 document-Loss function](https://pytorch.org/docs/stable/nn.html?highlight=loss#loss-functions)를 참조하여 2개 이상 적어주세요.)**  \n",
        "👉 (괄호를 지우고 적어주세요!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2YcbudY721-",
        "outputId": "3aa53cac-361e-4d7f-b4a4-b8ce3a980eaf"
      },
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.9152 | Epoch ACC 41.38% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.3931 | Epoch ACC 87.54% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.2097 | Epoch ACC 93.58% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1493 | Epoch ACC 95.37% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.1046 | Epoch ACC 96.83% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0897 | Epoch ACC 97.32% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0689 | Epoch ACC 98.03% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0607 | Epoch ACC 98.11% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0527 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0454 | Epoch ACC 98.70% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHReDHJk721_",
        "outputId": "6ce1394a-d2e0-4fab-ca8d-41f9e5447590"
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0006 | Test ACC 97.90% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdcO0JMa722A"
      },
      "source": [
        "## 4) BATCH Normalization적용하고 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYQCip9c722B"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.BatchNorm1d(fc_layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.BatchNorm1d(84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation 정의\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikTC3VLw722B"
      },
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LElnrcIL722C",
        "outputId": "e1472387-8ca3-40f7-90fd-d7190c067c8b"
      },
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.4639 | Epoch ACC 54.67% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.2883 | Epoch ACC 91.31% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.1608 | Epoch ACC 95.20% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1063 | Epoch ACC 96.72% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.0878 | Epoch ACC 97.37% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0694 | Epoch ACC 97.98% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0551 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0433 | Epoch ACC 98.72% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0386 | Epoch ACC 98.94% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0369 | Epoch ACC 98.93% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr-ChCOl722D",
        "outputId": "7de6068f-6f07-4dda-e94f-cb90b3ad0e6e"
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0004 | Test ACC 98.15% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB-zIHI5722D"
      },
      "source": [
        "Batch norm을 적용하여서 성능 향상이 되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDC6OgbF722D"
      },
      "source": [
        "# 3. 모델 저장하고 불러오기\n",
        "---\n",
        "이번에는 저장하기나 불러오기를 통해 모델의 상태를 유지(persist)하고 모델의 예측을 실행하는 방법을 알아보겠습니다.  \n",
        "모델을 저장할 때는 두 가지 방법 중 한 방법을 선택할 수 있는데, 모델 전체를 저장하는 방법과 모델의 state_dict만 저장하는 방법이 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc_7dPNa722E"
      },
      "source": [
        "## 1) 모델 전체 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfwnJuTk722E"
      },
      "source": [
        "# Case 1\n",
        "torch.save(model, 'ConvNet.pt')\n",
        "# Load model\n",
        "model = torch.load('ConvNet.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjUawCYF722E"
      },
      "source": [
        "## 2) 모델의 state_dict만 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpNZSBGS722E"
      },
      "source": [
        "# Case 1\n",
        "torch.save(model.state_dict(), 'ConvNet_dict.pt')\n",
        "# Load model\n",
        "model.load_state_dict(torch.load('ConvNet_dict.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efBuTodV722E"
      },
      "source": [
        "🔎 model 전체를 저장하는 것과 state_dict만 저장하는 것은 무슨 차이가 있을까요? ([모델 저장하기 & 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)를 참조하세요.)  \n",
        "👉 (괄호를 지우고 적어주세요!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEjSnsE_722G"
      },
      "source": [
        "### 2-1) 체크포인트(checkpoint) 저장하기 & 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq975jKm722H"
      },
      "source": [
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, \n",
        "           'ConvNet_dict.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eXJFLwZ722H"
      },
      "source": [
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "\n",
        "checkpoint = torch.load('ConvNet_dict.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YumkYOX722I"
      },
      "source": [
        "print(optimizer)\n",
        "print(epoch)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}