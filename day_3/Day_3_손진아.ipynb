{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_3_ì†ì§„ì•„",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjeena0722/TotochTeam1/blob/main/day_3/Day_3_%EC%86%90%EC%A7%84%EC%95%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qutt2gWe721X"
      },
      "source": [
        "# ì´ì›ƒì§‘ í† í† ì¹˜ íŒŒì´í† ì¹˜ : Day 3\n",
        "\n",
        "ğŸ“¢ í•´ë‹¹ ê²Œì‹œë¬¼ì€ íŒŒì´í† ì¹˜ ê³µì‹ íŠœí† ë¦¬ì–¼ ì¤‘ \n",
        "[DATASETê³¼ DATALOADER](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html)ì™€ \n",
        "[ë¶„ë¥˜ê¸°(CLASSIFIER) í•™ìŠµí•˜ê¸°](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)\n",
        "[ëª¨ë¸ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ê¸°](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)\n",
        "ë¥¼ ì½ê³  ì§ì ‘ ì‘ì„±í•´ë³´ëŠ” ì‹¤ìŠµ ë…¸íŠ¸ë¶ì…ë‹ˆë‹¤.  \n",
        "\n",
        "#### ëª©ì°¨\n",
        "1. DATASETê³¼ DATALOADER\n",
        "    1. í•„ìš” ëª¨ë“ˆ ì¤€ë¹„\n",
        "    2. Configration ì„¤ì •\n",
        "    3. ë°ì´í„° ì¤€ë¹„\n",
        "2. Pytorchë¡œ êµ¬í˜„í•˜ëŠ” MNIST ì†ê¸€ì”¨ ë¶„ë¥˜ê¸°\n",
        "    1. ë„ìš°ë¯¸ í•¨ìˆ˜ ì •ì˜\n",
        "    2. ëª¨ë¸ ì •ì˜í•˜ê¸°\n",
        "    3. í•™ìŠµ ì§„í–‰í•˜ê¸°\n",
        "    4. Batch Norm ì ìš©í•˜ê³  í•™ìŠµí•˜ê¸°\n",
        "3. ëª¨ë¸ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    1. ëª¨ë¸ ì „ì œ ì €ì¥\n",
        "    2. ëª¨ë¸ì˜ state_dictë§Œ ì €ì¥\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMlvZ7se721h"
      },
      "source": [
        "# 1. DATASETê³¼ DATALOADER\n",
        "---\n",
        "\n",
        "ë°ì´í„° ìƒ˜í”Œì„ ì²˜ë¦¬í•˜ëŠ” ì½”ë“œëŠ” ì§€ì €ë¶„(messy)í•˜ê³  ìœ ì§€ë³´ìˆ˜ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ê°€ë…ì„±(readability)ê³¼ ëª¨ë“ˆì„±(modularity)ì„ ìœ„í•´ ë°ì´í„°ì…‹ ì½”ë“œë¥¼ ëª¨ë¸ í•™ìŠµ ì½”ë“œë¡œë¶€í„° ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì´ìƒì ì…ë‹ˆë‹¤. PyTorchëŠ” ``torch.utils.data.DataLoader``ì™€ ``torch.utils.data.Dataset`` ì˜ ë‘ ê°€ì§€ ë°ì´í„° ê¸°ë³¸ ìš”ì†Œë¥¼ ì œê³µí•˜ì—¬ ë¯¸ë¦¬ ì¤€ë¹„í•´ëœ(pre-loaded) ë°ì´í„°ì…‹ ë¿ë§Œ ì•„ë‹ˆë¼ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
        "``Dataset`` ì€ ìƒ˜í”Œê³¼ ì •ë‹µ(label)ì„ ì €ì¥í•˜ê³ , ``DataLoader`` ëŠ” ``Dataset`` ì„ ìƒ˜í”Œì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ìˆœíšŒ ê°€ëŠ¥í•œ ê°ì²´(iterable)ë¡œ ê°ìŒ‰ë‹ˆë‹¤.\n",
        "\n",
        "PyTorchì˜ ë„ë©”ì¸ íŠ¹í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ (FashionMNISTì™€ ê°™ì€) ë‹¤ì–‘í•œ ë¯¸ë¦¬ ì¤€ë¹„í•´ë‘”(pre-loaded) ë°ì´í„°ì…‹ì„ ì œê³µí•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ ``torch.utils.data.Dataset`` ì˜ í•˜ìœ„ í´ë˜ìŠ¤ë¡œ ê°œë³„ ë°ì´í„°ë¥¼ íŠ¹ì •í•˜ëŠ” í•¨ìˆ˜ê°€ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°ì´í„°ì…‹ì€ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ê³ (prototype) ì„±ëŠ¥ì„ ì¸¡ì •(benchmark)í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì—ì„œ ë°ì´í„°ì…‹ë“¤ì„ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
        "[ì´ë¯¸ì§€ ë°ì´í„°ì…‹](https://pytorch.org/vision/stable/datasets.html), \n",
        "[í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹](https://pytorch.org/text/stable/datasets.html) ë°\n",
        "[ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹](https://pytorch.org/audio/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s56hF2u6721m"
      },
      "source": [
        "## 1) í•„ìš” ëª¨ë“ˆ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbhzwyVwIRaq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn    \n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpHqxBV8721q"
      },
      "source": [
        "## 2) Configration ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLTqzrd0LJik"
      },
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 128\n",
        "FC_LAYER_SIZE = 128\n",
        "LR = 0.01\n",
        "DROOUT = 0.5\n",
        "OPTIMIZER = 'sgd'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjQHHjX1721r"
      },
      "source": [
        "## 3) ë°ì´í„° ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpNEi2F721s"
      },
      "source": [
        "### 3-1) ê¸°ì¡´ TorchVision Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euieV7xAMGpE"
      },
      "source": [
        "\n",
        "train_transform = transforms.Compose([#transforms.CenterCrop(10),\n",
        "                                      transforms.Pad(padding=30),\n",
        "                                      transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "                                      #transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5,],[0.5,])])\n",
        "test_transform = transforms.Compose([#transforms.CenterCrop(10),\n",
        "                                     transforms.Pad(padding=30),\n",
        "                                     transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "                                     #transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5,],[0.5])])\n",
        "\n",
        "\n",
        "train_dataset = datasets.MNIST(root = '../MNIST', # ë°ì´í„° ì €ì¥ë ì¥ì†Œ \n",
        "                               train = True, # trainì¸ì§€ testì¸ì§€ \n",
        "                               download = True,# ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œí•´ ì´ìš©í• ê±´ì§€ \n",
        "                               transform = train_transform) \n",
        "\n",
        "test_dataset = datasets.MNIST(root = '../MNIST', train = False,\n",
        "                               download = True, transform = test_transform)\n",
        "\n",
        "# Subsetì„ ì‚¬ìš©í•˜ë©´ Datasetì˜ ë¶€ë¶„ ì§‘í•©ë§Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ.\n",
        "train_sub_dataset = Subset(train_dataset, indices=range(0, len(train_dataset), 5))\n",
        "test_sub_dataset = Subset(test_dataset, indices=range(0, len(test_dataset), 5))\n",
        "\n",
        "train_loader = DataLoader(dataset = train_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he-GrRD0721v"
      },
      "source": [
        "Subsetì€ Datasetì˜ ë¶€ë¶„ ì§‘í•©ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.  \n",
        "Dataset ì›ë³¸ìœ¼ë¡œ í•™ìŠµì„ ì‹œì¼°ì„ ê²½ìš° 16~17ë¶„ ì •ë„ê°€ ê±¸ë¦¬ì§€ë§Œ, Subsetìœ¼ë¡œ í•™ìŠµì„ í•  ê²½ìš° 3~4ë¶„ ì •ë„ê°€ ê±¸ë¦½ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "ih1u4er1cruk",
        "outputId": "44df5c4b-a73d-4190-a7f9-5313976d77f9"
      },
      "source": [
        "X_train, y_train = next(iter(train_loader))\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize = (10 * pltsize ,pltsize))\n",
        "for i in range(10):\n",
        "  plt.subplot(1, 10 , i + 1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(X_train[i, : , :, :].numpy().reshape(88,88), cmap = 'gray_r')\n",
        "  plt.title('class:' + str(y_train[i].item()))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBn758Nq721y"
      },
      "source": [
        "### 3-2) ë‹¤ì–‘í•œ transforms ì ìš©í•´ë³´ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_AKbbCa721z"
      },
      "source": [
        "ğŸ” ë‹¤ì–‘í•œ transforms ì¶”ê°€í•´ì„œ Mnist ë°ì´í„°ì…‹ì„ ë³€í˜•í•´ë´…ì‹œë‹¤!   \n",
        "ğŸ‘‰ (3-1ì—ì„œ train_transform, test_transformë¥¼ ë°”ê¿”ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤.)  \n",
        "ğŸ”” [Hint](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOiGrudY7210"
      },
      "source": [
        "### 3-3) ë” ë¹ ë¥¸ augmentation, albumentations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95GvR8397214"
      },
      "source": [
        "ğŸ” Albumentationsì˜ ì¥ì ê³¼ íŠ¹ì§•ì€ ì–´ë–¤ê²Œ ìˆì„ê¹Œìš”?  \n",
        "ğŸ‘‰  ì²˜ë¦¬ì†ë„ê°€ ë¹ ë¦„, ê¸°ëŠ¥ì´ ë‹¤ì–‘ <br>\n",
        "ğŸ”” [Hint](https://hoya012.github.io/blog/albumentation_tutorial/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QOapvUn7214"
      },
      "source": [
        "# 2. Pytorchë¡œ êµ¬í˜„í•˜ëŠ” MNIST ì†ê¸€ì”¨ ë¶„ë¥˜ê¸°\n",
        "---\n",
        "ìš°ë¦¬ëŠ” ìœ„ì—ì„œ DATASETê³¼ DATALOADERë¥¼ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤.  \n",
        "ì´ë²ˆì—ëŠ” Pytorchë¡œ MNISTë¥¼ í•™ìŠµí•˜ëŠ” ì½”ë“œë¥¼ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.  \n",
        "ë§ˆì°¬ê°€ì§€ë¡œ ì¤‘ê°„ì¤‘ê°„ì— ìˆëŠ” ë¬¸ì œë¥¼ í‘¸ì‹œë©´ ë©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-wb6koj7215"
      },
      "source": [
        "## 1) ë„ìš°ë¯¸ í•¨ìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uoU8juA7215"
      },
      "source": [
        "def train_epoch(network, loader, optimizer, criterion):\n",
        "    cumu_loss = 0\n",
        "    cumu_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    for _, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(network(data), target)\n",
        "        cumu_loss += loss.item()\n",
        "        _, predicted = torch.max(network(data).data, 1)\n",
        "        total += target.size(0)\n",
        "        cumu_acc += (predicted == target).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        network.eval() \n",
        "    return cumu_loss / len(loader), 100 * cumu_acc / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY7vlD-8BBCC"
      },
      "source": [
        "def evaluate(model, test_loader, criterion):\n",
        "  model.eval() # ëª¨ë¸ì„ í‰ê°€ìƒíƒœ(test ìƒíƒœ)ë¡œ ì§€ì • \n",
        "  test_loss = 0 # test_loss ì´ˆê¸°ê°’ \n",
        "  correct = 0 # ì˜¬ë°”ë¥¸ classë¡œ ë¶„ë¥˜í•œ ì¹´ìš´íŠ¸ë¥¼ ì„¸ê¸°ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì • \n",
        "\n",
        "  with torch.no_grad(): # í‰ê°€ì‹œì—ëŠ” gradiantë¥¼ í†µí•´ íŒ¨ëŸ¬ë¯¸í„° ì—…ë°ì´íŠ¸ë¥¼ í•˜ì§€ì•ŠìŒ \n",
        "    for image, label in test_loader: # mini_batch ë‹¨ìœ„ë¡œ êº¼ë‚´ê¸° \n",
        "      image = image.to(DEVICE) # DEVICE í• ë‹¹\n",
        "      label = label.to(DEVICE) # DEVICEì— í• ë‹¹\n",
        "      output = model(image)    # ëª¨ë¸ì— inputì„ ë„£ì–´ output ê³„ì‚° \n",
        "      test_loss += criterion(output, label).item() # outputê³¼ labelì˜ loss ê³„ì‚° \n",
        "      prediction = output.max(1, keepdim = True)[1] # outputì€ ê¸¸ì´ê°€ 10ì¸ ë²¡í„°ê°’ \n",
        "                                                    # ê·¸ì¤‘ì—ì„œ ê°€ì¥ í°ê°’ì¸ ìœ„ì¹˜ì˜ ë¼ë²¨ë¡œ\n",
        "                                                    # ì˜ˆì¸¡í–‡ë‹¤ê³  íŒë‹¨ \n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item() # eq() ë©”ì„œë“œëŠ” ë¼ë²¨ê³¼ ì˜ˆì¸¡ì´ ê°™ìœ¼ë©´(equal) 1\n",
        "                                                                        # ë‹¤ë¥´ë©´ 0. ê·¸ ê°’ë“¤ì„ë”í•´ì„œ correctì— ë”í•´ì£¼ê¸° \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt0_dIHx7217"
      },
      "source": [
        "## 2) ëª¨ë¸ ì •ì˜í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkaFqWLH7218"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module ì˜ init ìƒì†\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation ì •ì˜\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCSb_1JW7218"
      },
      "source": [
        "## 3) í•™ìŠµ ì§„í–‰í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OD4YKjG-tkc"
      },
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss ê¸°ì¤€ì€ CrossEntropyLossë¡œ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8gefTlA7219"
      },
      "source": [
        "**ğŸ” torch.optimì—ëŠ” ì–´ë–¤ optimizerë“¤ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‚˜ìš”? ([ê³µì‹ document](https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim)ë¥¼ ì°¸ì¡°í•˜ì—¬ 2ê°œ ì´ìƒ ì ì–´ì£¼ì„¸ìš”.)**  \n",
        "ğŸ‘‰ (ê´„í˜¸ë¥¼ ì§€ìš°ê³  ì ì–´ì£¼ì„¸ìš”!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaBnS50X721-"
      },
      "source": [
        "**ğŸ” nn.Moduleì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” Loss functionì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ êµ¬í˜„í•  ìˆ˜ ìˆë‚˜ìš”? ([ê³µì‹ document-Loss function](https://pytorch.org/docs/stable/nn.html?highlight=loss#loss-functions)ë¥¼ ì°¸ì¡°í•˜ì—¬ 2ê°œ ì´ìƒ ì ì–´ì£¼ì„¸ìš”.)**  \n",
        "ğŸ‘‰ (ê´„í˜¸ë¥¼ ì§€ìš°ê³  ì ì–´ì£¼ì„¸ìš”!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2YcbudY721-",
        "outputId": "3aa53cac-361e-4d7f-b4a4-b8ce3a980eaf"
      },
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.9152 | Epoch ACC 41.38% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.3931 | Epoch ACC 87.54% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.2097 | Epoch ACC 93.58% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1493 | Epoch ACC 95.37% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.1046 | Epoch ACC 96.83% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0897 | Epoch ACC 97.32% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0689 | Epoch ACC 98.03% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0607 | Epoch ACC 98.11% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0527 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0454 | Epoch ACC 98.70% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHReDHJk721_",
        "outputId": "6ce1394a-d2e0-4fab-ca8d-41f9e5447590"
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0006 | Test ACC 97.90% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdcO0JMa722A"
      },
      "source": [
        "## 4) BATCH Normalizationì ìš©í•˜ê³  í•™ìŠµí•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYQCip9c722B"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module ì˜ init ìƒì†\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.BatchNorm1d(fc_layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.BatchNorm1d(84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation ì •ì˜\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikTC3VLw722B"
      },
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss ê¸°ì¤€ì€ CrossEntropyLossë¡œ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LElnrcIL722C",
        "outputId": "e1472387-8ca3-40f7-90fd-d7190c067c8b"
      },
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.4639 | Epoch ACC 54.67% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.2883 | Epoch ACC 91.31% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.1608 | Epoch ACC 95.20% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1063 | Epoch ACC 96.72% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.0878 | Epoch ACC 97.37% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0694 | Epoch ACC 97.98% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0551 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0433 | Epoch ACC 98.72% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0386 | Epoch ACC 98.94% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0369 | Epoch ACC 98.93% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr-ChCOl722D",
        "outputId": "7de6068f-6f07-4dda-e94f-cb90b3ad0e6e"
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0004 | Test ACC 98.15% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB-zIHI5722D"
      },
      "source": [
        "Batch normì„ ì ìš©í•˜ì—¬ì„œ ì„±ëŠ¥ í–¥ìƒì´ ë˜ì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDC6OgbF722D"
      },
      "source": [
        "# 3. ëª¨ë¸ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "---\n",
        "ì´ë²ˆì—ëŠ” ì €ì¥í•˜ê¸°ë‚˜ ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ í†µí•´ ëª¨ë¸ì˜ ìƒíƒœë¥¼ ìœ ì§€(persist)í•˜ê³  ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.  \n",
        "ëª¨ë¸ì„ ì €ì¥í•  ë•ŒëŠ” ë‘ ê°€ì§€ ë°©ë²• ì¤‘ í•œ ë°©ë²•ì„ ì„ íƒí•  ìˆ˜ ìˆëŠ”ë°, ëª¨ë¸ ì „ì²´ë¥¼ ì €ì¥í•˜ëŠ” ë°©ë²•ê³¼ ëª¨ë¸ì˜ state_dictë§Œ ì €ì¥í•˜ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc_7dPNa722E"
      },
      "source": [
        "## 1) ëª¨ë¸ ì „ì²´ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfwnJuTk722E"
      },
      "source": [
        "# Case 1\n",
        "torch.save(model, 'ConvNet.pt')\n",
        "# Load model\n",
        "model = torch.load('ConvNet.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjUawCYF722E"
      },
      "source": [
        "## 2) ëª¨ë¸ì˜ state_dictë§Œ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpNZSBGS722E"
      },
      "source": [
        "# Case 1\n",
        "torch.save(model.state_dict(), 'ConvNet_dict.pt')\n",
        "# Load model\n",
        "model.load_state_dict(torch.load('ConvNet_dict.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efBuTodV722E"
      },
      "source": [
        "ğŸ” model ì „ì²´ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒê³¼ state_dictë§Œ ì €ì¥í•˜ëŠ” ê²ƒì€ ë¬´ìŠ¨ ì°¨ì´ê°€ ìˆì„ê¹Œìš”? ([ëª¨ë¸ ì €ì¥í•˜ê¸° & ë¶ˆëŸ¬ì˜¤ê¸°](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.)  \n",
        "ğŸ‘‰ (ê´„í˜¸ë¥¼ ì§€ìš°ê³  ì ì–´ì£¼ì„¸ìš”!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEjSnsE_722G"
      },
      "source": [
        "### 2-1) ì²´í¬í¬ì¸íŠ¸(checkpoint) ì €ì¥í•˜ê¸° & ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq975jKm722H"
      },
      "source": [
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, \n",
        "           'ConvNet_dict.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eXJFLwZ722H"
      },
      "source": [
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "\n",
        "checkpoint = torch.load('ConvNet_dict.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YumkYOX722I"
      },
      "source": [
        "print(optimizer)\n",
        "print(epoch)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}