{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_3_손진아",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjeena0722/TotochTeam1/blob/main/day_3/Day_3_%EC%86%90%EC%A7%84%EC%95%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qutt2gWe721X"
      },
      "source": [
        "# 이웃집 토토치 파이토치 : Day 3\n",
        "\n",
        "📢 해당 게시물은 파이토치 공식 튜토리얼 중 \n",
        "[DATASET과 DATALOADER](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html)와 \n",
        "[분류기(CLASSIFIER) 학습하기](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)\n",
        "[모델 저장하고 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)\n",
        "를 읽고 직접 작성해보는 실습 노트북입니다.  \n",
        "\n",
        "#### 목차\n",
        "1. DATASET과 DATALOADER\n",
        "    1. 필요 모듈 준비\n",
        "    2. Configration 설정\n",
        "    3. 데이터 준비\n",
        "2. Pytorch로 구현하는 MNIST 손글씨 분류기\n",
        "    1. 도우미 함수 정의\n",
        "    2. 모델 정의하기\n",
        "    3. 학습 진행하기\n",
        "    4. Batch Norm 적용하고 학습하기\n",
        "3. 모델 저장하고 불러오기\n",
        "    1. 모델 전제 저장\n",
        "    2. 모델의 state_dict만 저장\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMlvZ7se721h"
      },
      "source": [
        "# 1. DATASET과 DATALOADER\n",
        "---\n",
        "\n",
        "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\n",
        "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
        "\n",
        "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\n",
        "\n",
        "여기에서 데이터셋들을 찾아볼 수 있습니다:\n",
        "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \n",
        "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\n",
        "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s56hF2u6721m"
      },
      "source": [
        "## 1) 필요 모듈 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbhzwyVwIRaq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn    \n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpHqxBV8721q"
      },
      "source": [
        "## 2) Configration 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLTqzrd0LJik"
      },
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 128\n",
        "FC_LAYER_SIZE = 128\n",
        "LR = 0.01\n",
        "DROOUT = 0.5\n",
        "OPTIMIZER = 'sgd'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjQHHjX1721r"
      },
      "source": [
        "## 3) 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpNEi2F721s"
      },
      "source": [
        "### 3-1) 기존 TorchVision Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euieV7xAMGpE"
      },
      "source": [
        "\n",
        "train_transform = transforms.Compose([transforms.CenterCrop(10),\n",
        "                                      transforms.Pad(padding=30),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5,],[0.5,])])\n",
        "test_transform = transforms.Compose([transforms.CenterCrop(10),\n",
        "                                     transforms.Pad(padding=30),\n",
        "                                     transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5,],[0.5])])\n",
        "\n",
        "\n",
        "train_dataset = datasets.MNIST(root = '../MNIST', # 데이터 저장될장소 \n",
        "                               train = True, # train인지 test인지 \n",
        "                               download = True,# 인터넷에서 다운로드해 이용할건지 \n",
        "                               transform = train_transform) \n",
        "\n",
        "test_dataset = datasets.MNIST(root = '../MNIST', train = False,\n",
        "                               download = True, transform = test_transform)\n",
        "\n",
        "# Subset을 사용하면 Dataset의 부분 집합만 가져올 수 있음.\n",
        "train_sub_dataset = Subset(train_dataset, indices=range(0, len(train_dataset), 5))\n",
        "test_sub_dataset = Subset(test_dataset, indices=range(0, len(test_dataset), 5))\n",
        "\n",
        "train_loader = DataLoader(dataset = train_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_sub_dataset,\n",
        "                         batch_size = BATCH_SIZE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he-GrRD0721v"
      },
      "source": [
        "Subset은 Dataset의 부분 집합을 가져오는 함수입니다.  \n",
        "Dataset 원본으로 학습을 시켰을 경우 16~17분 정도가 걸리지만, Subset으로 학습을 할 경우 3~4분 정도가 걸립니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "ih1u4er1cruk",
        "outputId": "795ae2f1-dbd7-490b-c98b-e183af9ab360"
      },
      "source": [
        "X_train, y_train = next(iter(train_loader))\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize = (10 * pltsize ,pltsize))\n",
        "for i in range(10):\n",
        "  plt.subplot(1, 10 , i + 1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(X_train[i, : , :, :].numpy().reshape(70,70), cmap = 'gray_r')\n",
        "  plt.title('class:' + str(y_train[i].item()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBn758Nq721y"
      },
      "source": [
        "### 3-2) 다양한 transforms 적용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_AKbbCa721z"
      },
      "source": [
        "🔎 다양한 transforms 추가해서 Mnist 데이터셋을 변형해봅시다!   \n",
        "👉 (3-1에서 train_transform, test_transform를 바꿔보시길 바랍니다.)  \n",
        "🔔 [Hint](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOiGrudY7210"
      },
      "source": [
        "### 3-3) 더 빠른 augmentation, albumentations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95GvR8397214"
      },
      "source": [
        "🔎 Albumentations의 장점과 특징은 어떤게 있을까요?  \n",
        "👉 (괄호를 지우고 적어주세요!)   \n",
        "🔔 [Hint](https://hoya012.github.io/blog/albumentation_tutorial/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QOapvUn7214"
      },
      "source": [
        "# 2. Pytorch로 구현하는 MNIST 손글씨 분류기\n",
        "---\n",
        "우리는 위에서 DATASET과 DATALOADER를 살펴보았습니다.  \n",
        "이번에는 Pytorch로 MNIST를 학습하는 코드를 적용해보겠습니다.  \n",
        "마찬가지로 중간중간에 있는 문제를 푸시면 됩니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-wb6koj7215"
      },
      "source": [
        "## 1) 도우미 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uoU8juA7215"
      },
      "source": [
        "def train_epoch(network, loader, optimizer, criterion):\n",
        "    cumu_loss = 0\n",
        "    cumu_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    for _, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(network(data), target)\n",
        "        cumu_loss += loss.item()\n",
        "        _, predicted = torch.max(network(data).data, 1)\n",
        "        total += target.size(0)\n",
        "        cumu_acc += (predicted == target).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        network.eval() \n",
        "    return cumu_loss / len(loader), 100 * cumu_acc / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY7vlD-8BBCC"
      },
      "source": [
        "def evaluate(model, test_loader, criterion):\n",
        "  model.eval() # 모델을 평가상태(test 상태)로 지정 \n",
        "  test_loss = 0 # test_loss 초기값 \n",
        "  correct = 0 # 올바른 class로 분류한 카운트를 세기위해 0으로 설정 \n",
        "\n",
        "  with torch.no_grad(): # 평가시에는 gradiant를 통해 패러미터 업데이트를 하지않음 \n",
        "    for image, label in test_loader: # mini_batch 단위로 꺼내기 \n",
        "      image = image.to(DEVICE) # DEVICE 할당\n",
        "      label = label.to(DEVICE) # DEVICE에 할당\n",
        "      output = model(image)    # 모델에 input을 넣어 output 계산 \n",
        "      test_loss += criterion(output, label).item() # output과 label의 loss 계산 \n",
        "      prediction = output.max(1, keepdim = True)[1] # output은 길이가 10인 벡터값 \n",
        "                                                    # 그중에서 가장 큰값인 위치의 라벨로\n",
        "                                                    # 예측햇다고 판단 \n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item() # eq() 메서드는 라벨과 예측이 같으면(equal) 1\n",
        "                                                                        # 다르면 0. 그 값들을더해서 correct에 더해주기 \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt0_dIHx7217"
      },
      "source": [
        "## 2) 모델 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkaFqWLH7218"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation 정의\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCSb_1JW7218"
      },
      "source": [
        "## 3) 학습 진행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OD4YKjG-tkc"
      },
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8gefTlA7219"
      },
      "source": [
        "**🔎 torch.optim에는 어떤 optimizer들을 구현할 수 있나요? ([공식 document](https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim)를 참조하여 2개 이상 적어주세요.)**  \n",
        "👉 (괄호를 지우고 적어주세요!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaBnS50X721-"
      },
      "source": [
        "**🔎 nn.Module에서 활용할 수 있는 Loss function에는 어떤 것들이 구현할 수 있나요? ([공식 document-Loss function](https://pytorch.org/docs/stable/nn.html?highlight=loss#loss-functions)를 참조하여 2개 이상 적어주세요.)**  \n",
        "👉 (괄호를 지우고 적어주세요!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2YcbudY721-",
        "outputId": "3aa53cac-361e-4d7f-b4a4-b8ce3a980eaf"
      },
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.9152 | Epoch ACC 41.38% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.3931 | Epoch ACC 87.54% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.2097 | Epoch ACC 93.58% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1493 | Epoch ACC 95.37% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.1046 | Epoch ACC 96.83% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0897 | Epoch ACC 97.32% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0689 | Epoch ACC 98.03% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0607 | Epoch ACC 98.11% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0527 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0454 | Epoch ACC 98.70% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHReDHJk721_",
        "outputId": "6ce1394a-d2e0-4fab-ca8d-41f9e5447590"
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0006 | Test ACC 97.90% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdcO0JMa722A"
      },
      "source": [
        "## 4) BATCH Normalization적용하고 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYQCip9c722B"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, fc_layer_size, dropout):\n",
        "        super(ConvNet, self).__init__() # nn.Module 의 init 상속\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, fc_layer_size, bias=True),\n",
        "            nn.BatchNorm1d(fc_layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(fc_layer_size, 84),\n",
        "            nn.BatchNorm1d(84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout),)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # Forward Propagation 정의\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikTC3VLw722B"
      },
      "source": [
        "if OPTIMIZER == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "elif OPTIMIZER == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() # Loss 기준은 CrossEntropyLoss로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LElnrcIL722C",
        "outputId": "e1472387-8ca3-40f7-90fd-d7190c067c8b"
      },
      "source": [
        "for epoch in range(EPOCH):\n",
        "    avg_loss, avg_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"TRAIN: EPOCH {epoch + 1:04d} / {EPOCH:04d} | Epoch LOSS {avg_loss:.4f} | Epoch ACC {avg_acc:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: EPOCH 0001 / 0010 | Epoch LOSS 1.4639 | Epoch ACC 54.67% \n",
            "TRAIN: EPOCH 0002 / 0010 | Epoch LOSS 0.2883 | Epoch ACC 91.31% \n",
            "TRAIN: EPOCH 0003 / 0010 | Epoch LOSS 0.1608 | Epoch ACC 95.20% \n",
            "TRAIN: EPOCH 0004 / 0010 | Epoch LOSS 0.1063 | Epoch ACC 96.72% \n",
            "TRAIN: EPOCH 0005 / 0010 | Epoch LOSS 0.0878 | Epoch ACC 97.37% \n",
            "TRAIN: EPOCH 0006 / 0010 | Epoch LOSS 0.0694 | Epoch ACC 97.98% \n",
            "TRAIN: EPOCH 0007 / 0010 | Epoch LOSS 0.0551 | Epoch ACC 98.42% \n",
            "TRAIN: EPOCH 0008 / 0010 | Epoch LOSS 0.0433 | Epoch ACC 98.72% \n",
            "TRAIN: EPOCH 0009 / 0010 | Epoch LOSS 0.0386 | Epoch ACC 98.94% \n",
            "TRAIN: EPOCH 0010 / 0010 | Epoch LOSS 0.0369 | Epoch ACC 98.93% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr-ChCOl722D",
        "outputId": "7de6068f-6f07-4dda-e94f-cb90b3ad0e6e"
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test LOSS {test_loss:.4f} | Test ACC {test_accuracy:.2f}% \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS 0.0004 | Test ACC 98.15% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB-zIHI5722D"
      },
      "source": [
        "Batch norm을 적용하여서 성능 향상이 되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDC6OgbF722D"
      },
      "source": [
        "# 3. 모델 저장하고 불러오기\n",
        "---\n",
        "이번에는 저장하기나 불러오기를 통해 모델의 상태를 유지(persist)하고 모델의 예측을 실행하는 방법을 알아보겠습니다.  \n",
        "모델을 저장할 때는 두 가지 방법 중 한 방법을 선택할 수 있는데, 모델 전체를 저장하는 방법과 모델의 state_dict만 저장하는 방법이 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc_7dPNa722E"
      },
      "source": [
        "## 1) 모델 전체 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfwnJuTk722E"
      },
      "source": [
        "# Case 1\n",
        "torch.save(model, 'ConvNet.pt')\n",
        "# Load model\n",
        "model = torch.load('ConvNet.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjUawCYF722E"
      },
      "source": [
        "## 2) 모델의 state_dict만 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpNZSBGS722E"
      },
      "source": [
        "# Case 1\n",
        "torch.save(model.state_dict(), 'ConvNet_dict.pt')\n",
        "# Load model\n",
        "model.load_state_dict(torch.load('ConvNet_dict.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efBuTodV722E"
      },
      "source": [
        "🔎 model 전체를 저장하는 것과 state_dict만 저장하는 것은 무슨 차이가 있을까요? ([모델 저장하기 & 불러오기](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)를 참조하세요.)  \n",
        "👉 (괄호를 지우고 적어주세요!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEjSnsE_722G"
      },
      "source": [
        "### 2-1) 체크포인트(checkpoint) 저장하기 & 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq975jKm722H"
      },
      "source": [
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            }, \n",
        "           'ConvNet_dict.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eXJFLwZ722H"
      },
      "source": [
        "model = ConvNet(FC_LAYER_SIZE, DROOUT).to(DEVICE) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "\n",
        "checkpoint = torch.load('ConvNet_dict.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YumkYOX722I"
      },
      "source": [
        "print(optimizer)\n",
        "print(epoch)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}