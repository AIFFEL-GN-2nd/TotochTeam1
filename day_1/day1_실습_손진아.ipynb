{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day1_실습_손진아.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PEBpung/TotochTeam1/blob/main/day1_%ED%85%90%EC%84%9C(Tensor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_FyQ99czaAS"
      },
      "source": [
        "# 이웃집 토토치 파이토치 : Day 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIEtaQ_Czdkp"
      },
      "source": [
        "📢 해당 게시물은 파이토치 공식 튜토리얼 중 파이토치(PyTorch) 시작하기를 읽고 직접 작성해보는 실습 노트북입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZV548lFG_ll"
      },
      "source": [
        "#### 목차\n",
        "1. 탠서(TENSOR)\n",
        "    1. 텐서(tensor) 초기화\n",
        "    2. 텐서의 속성(Attribute)\n",
        "    3. 텐서 연산(Operation)\n",
        "    4. NumPy 변환(Bridge)\n",
        "2. Autograd\n",
        "    1. 간단한 이미지 분류 학습\n",
        "    2. [실습] 연산 그래프 직접 구현하기\n",
        "3. DATASET과 DATALOADER\n",
        "    1. 데이터셋 불러오기\n",
        "    2. 데이터셋을 순회하고 시각화하기\n",
        "    3. 파일에서 사용자 정의 데이터셋 만들기\n",
        "    4. DataLoader로 학습용 데이터 준비하기\n",
        "    5. DataLoader를 통해 순회하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5CTkc4nirPn"
      },
      "source": [
        "## 1. 텐서 (Tensor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxpKzLnXimaU"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul7rdwiRi5zl"
      },
      "source": [
        "### 텐서(tensor) 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVcsUDhcjCrD"
      },
      "source": [
        "**데이터로부터 직접(directly) 생성하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10y9YFqZiopn"
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "x_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhK77YQwi6L1"
      },
      "source": [
        "**NumPy 배열로부터 생성하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvgWwsTUipiu"
      },
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "x_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF0gt5U6jR8V"
      },
      "source": [
        "**다른 텐서로부터 생성하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wikxshb9iqQ8"
      },
      "source": [
        "# x_data의 속성을 유지합니다.\n",
        "x_ones = torch.ones_like(x_data) \n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "# x_data의 속성을 덮어씁니다.\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) \n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sepex-_YjYkG"
      },
      "source": [
        "**무작위(random) 또는 상수(constant) 값을 사용하기:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmVb1QuTiqZb"
      },
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68cNHQmlG_mX"
      },
      "source": [
        "rand_tensor.add(ones_tensor)\n",
        "print(rand_tensor)\n",
        "rand_tensor.add_(ones_tensor)\n",
        "print(rand_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2blbrRdjgI2"
      },
      "source": [
        "### 텐서의 속성(Attribute)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HbUDrVljf_H"
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "############################\n",
        "# 밑줄 친 곳을 채워주세요! #\n",
        "############################\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdTMCC1KmPD-"
      },
      "source": [
        "### 텐서 연산(Operation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHEQDwzwG_mh"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. 텐서를 사용하면 어떤 점이 좋을까요??</b></p>\n",
        "    <p>👉 다양한 연산이 가능하다..? </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyM7zxmnjf3y"
      },
      "source": [
        "# GPU가 존재하면 텐서를 이동합니다\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV3e7QrZmdF8"
      },
      "source": [
        "NumPy식의 표준 인덱싱과 슬라이싱:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "522O3OXJjfuB"
      },
      "source": [
        "data = [[1, 2, 3],\n",
        "         [4, 5, 6],\n",
        "         [7, 8, 9]]\n",
        "t_data = torch.tensor(data)\n",
        "\n",
        "############################\n",
        "# 밑줄 친 곳을 채워주세요! #\n",
        "############################\n",
        "\n",
        "print('2번째 행 출력: ',t_data[1])\n",
        "print('t_data에서 5를 출력: ', t_data[1,1])\n",
        "print('마지막 column 출력:', t_data[...,-1])\n",
        "t_data[:,2] = 0\n",
        "print('3번째 column을 0으로 만들기:')\n",
        "print(t_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DbwAF-TpeBg"
      },
      "source": [
        "**텐서 합치기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWGBUa0ljfi6"
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCf2__l_ppjd"
      },
      "source": [
        "**산술 연산(Arithmetic operations)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAMnNAnurkDb"
      },
      "source": [
        "tensor = torch.rand(3,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rl2lXktjfEx"
      },
      "source": [
        "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "print(y1)\n",
        "print(y2)\n",
        "print(y3)\n",
        "\n",
        "print('-- '*15)\n",
        "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)\n",
        "print(z1)\n",
        "print(z2)\n",
        "print(z3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zIgkmn9G_m2"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. 행렬 곱(matrix multiplication)과 요소별 곱(element-wise product)의 차이점이 뭘까요??</b></p>\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS823HhDsI6Z"
      },
      "source": [
        "**단일-요소(single-element)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9_IWxvHsIqV"
      },
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6VGHAC4wWCi"
      },
      "source": [
        "**텐서차원 축소/확장(Squeeze/Unsqueeze) 연산**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYhTcpCor2wC"
      },
      "source": [
        "# Squeeze/Unsqueeze\n",
        "x = torch.rand((1,1,3,4))\n",
        "y = x.squeeze()\n",
        "print(y.size())\n",
        "print(y.unsqueeze(1).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKuDZQXDG_nD"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. Squeeze와 Unsqueeze는 어떤 경우에 사용 될까요? 자유롭게 생각해보죠!</b></p>\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaocZgDTG_nE"
      },
      "source": [
        "**스태킹(Stacking)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNRBWF-iG_nF"
      },
      "source": [
        "x = torch.FloatTensor([1, 4])\n",
        "y = torch.FloatTensor([2, 5])\n",
        "z = torch.FloatTensor([3, 6])\n",
        "\n",
        "print(torch.stack([x, y, z]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c289uXBJG_nH"
      },
      "source": [
        "### 넘파이(Numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17IUYsqNxUxp"
      },
      "source": [
        "**텐서를 NumPy 배열로 변환하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EuvEtoIxUl-"
      },
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDV_kHfJxYvM"
      },
      "source": [
        "텐서의 변경 사항이 NumPy 배열에 반영됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcKNnWvFxUhd"
      },
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D5LXTwDxcap"
      },
      "source": [
        "**NumPy 배열을 텐서로 변환하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GLooKX3xUfd"
      },
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0VP8MyOxfq_"
      },
      "source": [
        "NumPy 배열의 변경 사항이 텐서에 반영됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJL53PRxUZc"
      },
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oSFS6lfG_nS"
      },
      "source": [
        "# 2. Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwpLSARtG_nT"
      },
      "source": [
        "## 간단 이미지 분류 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtwEylGdG_nZ"
      },
      "source": [
        "random_seed = 99\n",
        "torch.manual_seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EsbqCNyG_na"
      },
      "source": [
        "동일한 출력을 얻기 위해서 random seed 값 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkCd6na7G_nb"
      },
      "source": [
        "### 1) 데이터 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DGY7lVbG_nd"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(6, 1),\n",
        "    torch.nn.Flatten()\n",
        ")\n",
        "data = torch.rand(2, 6)\n",
        "labels = torch.ones(2, 1)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi-rUIeWG_ni"
      },
      "source": [
        "랜덤으로 설정된 label 값은 ([1.], [1.])입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF1xDqHuG_ni"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. 각자 그림을 그리면서 이해하시는 것을 추천드립니다!</b></p>\n",
        "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zNQaM43G_nj"
      },
      "source": [
        "### 2) 순전파 (Forward Propagation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3Y8IMiMG_nj"
      },
      "source": [
        "prediction = model(data) # 순전파 단계(forward pass)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AXMCXbaG_nj"
      },
      "source": [
        "순전파 단계에서는 입력(input) 데이터를 모델의 각 층(layer)에 통과시켜 예측값(prediction)을 생성합니다.   \n",
        "모델의 output으로 나온 pred 값은 ([0.3425], [0.2512])입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbU5bqe_G_nk"
      },
      "source": [
        "layer = model[0]\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMiZf0r8G_nk"
      },
      "source": [
        "모델의 초기 weight와 bias를 확인 해보시길 바랍니다.  \n",
        "손실함수와 옵티마이저를 사용해서 이 값들을 변경할 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4CYYWODG_nl"
      },
      "source": [
        "### 3) 손실함수 (loss) 계산하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px8yBCY0G_nl"
      },
      "source": [
        "loss = (prediction - labels).sum() \n",
        "print(loss)\n",
        "loss.backward() # 역전파 단계(backward pass)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKiWF63SG_nm"
      },
      "source": [
        "- 모델의 예측값(prediction)과 그에 해당하는 정답(label)의 차이를 합하여 오차(error, 손실(loss) )를 계산하였습니다. 손실함수를 구하는 방법은 다양하지만 이번글에서는 간단하게 차이값으로만 구하도록 하겠습니다.\n",
        "\n",
        "-  오차 텐서(error tensor)에 .backward() 를 호출하면 역전파가 시작되며, 그 다음 Autograd가 매개변수(parameter)의 .grad 속성(attribute)에, 모델의 각 매개변수에 대한 변화도(gradient)를 계산하고 저장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY6XDWmZG_nm"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. loss의 결과는 -1.4063이 나왔습니다, 직접 labels 값과 pred 값을 비교해서 계산해봅시다!</b></p>\n",
        "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZW8_mmZG_nn"
      },
      "source": [
        "### 4) 옵티마이저 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZdMDG2rG_nn"
      },
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REvOF9j7G_no"
      },
      "source": [
        "- 학습율(learning rate) 0.01과 모멘텀(momentum) 0.9를 갖는 SGD로 옵티마이즈를 설정하였으며, 옵티마이저(optimizer)에 모델의 모든 매개변수(models.parameters())를 등록합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrYCqb8NG_np"
      },
      "source": [
        "### 5) 경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pxes5ynG_np"
      },
      "source": [
        "optim.step() # 경사하강법(gradient descent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0_M_ckG_nr"
      },
      "source": [
        "- step 을 호출하여 경사하강법(gradient descent)을 시작합니다. 옵티마이저는 .grad 에 저장된 기울기(gradient)에 따라 각 매개변수를 조정(adjust)합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLjJu6bxG_nr"
      },
      "source": [
        "layer = model[0]\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaLkFLsG_ns"
      },
      "source": [
        "prediction = model(data) # 순전파 단계(forward pass)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5iSj4IvG_ns"
      },
      "source": [
        "## 실습 문제\n",
        "다음과 같은 연산 그래프를 직접 구현하면서 Autograd를 이해해보는 시간을 갖겠습니다.   \n",
        "이번 실습에서는 backpop의 미분 값이 어떻게 계산되는 지 살펴볼 것입니다.  \n",
        "x는 초기 값으로 2x2의 1로 채워진 행렬을 사용할 것입니다.  \n",
        "\n",
        "<img src=\"./img/ex1.jpg\" width='600'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL457X64G_nt"
      },
      "source": [
        "x = torch.ones(2, 2)\n",
        "print(x)\n",
        "print(x.requires_grad)\n",
        "print('-'*10)\n",
        "\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "print(x.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtjmBrogG_nt"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. requires_grad는 어떤 역할을 하는 파라미터일까요?</b></p>\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oe8lEfIG_nt"
      },
      "source": [
        "############################\n",
        "# 밑줄 친 곳을 채워주세요! #\n",
        "############################\n",
        "\n",
        "y = ___\n",
        "print(y)\n",
        "print(y.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtlqpBygG_nu"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQSDNKvWG_nu"
      },
      "source": [
        "############################\n",
        "# 밑줄 친 곳을 채워주세요! #\n",
        "############################\n",
        "\n",
        "z = ___\n",
        "out = z.mean()\n",
        "print(z)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ45KyVRG_nv"
      },
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "\n",
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHsZtuSBG_nv"
      },
      "source": [
        "### Gradient, 경사/기울기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfRGtm8lG_nv"
      },
      "source": [
        "역전파를 해보겠습니다. out.backward()과 out.backward(torch.Tensor([1.0]))은 동일하게 동작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Y57ZzuG_nw"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0umG1PlG_ny"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edGD-yf2G_nz"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. requires_grad = True를 하면 무슨 일이 일어나길래, grad()를 호출하면 바로 미분값을 합산해줄까?</b></p>\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1zo1XjLG_n0"
      },
      "source": [
        "# 3. DATASET과 DATALOADER\n",
        "\n",
        "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\n",
        "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
        "\n",
        "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\n",
        "\n",
        "여기에서 데이터셋들을 찾아볼 수 있습니다:\n",
        "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \n",
        "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\n",
        "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHsWuiUrG_n1"
      },
      "source": [
        "### A. 데이터셋 불러오기\n",
        "\n",
        "`TorchVision` 에서 [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist) 데이터셋을\n",
        "불러오는 예제를 살펴보겠습니다. Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다. 각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성됩니다.\n",
        "\n",
        "다음 매개변수들을 사용하여 [FashionMNIST 데이터셋](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)을 불러옵니다:\n",
        " - ``root`` 는 학습/테스트 데이터가 저장되는 경로입니다.\n",
        " - ``train`` 은 학습용 또는 테스트용 데이터셋 여부를 지정합니다.\n",
        " - ``download=True`` 는 ``root`` 에 데이터가 없는 경우 인터넷에서 다운로드합니다.\n",
        " - ``transform`` 과 ``target_transform`` 은 특징(feature)과 정답(label) 변형(transform)을 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE6tOvlAG_n1"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNZacYNny2Nx"
      },
      "source": [
        "### B. 데이터셋을 순회하고 시각화하기\n",
        "\n",
        "Dataset 에 리스트(list)처럼 직접 접근(index)할 수 있습니다: training_data[index]. matplotlib 을 사용하여 학습 데이터의 일부를 시각화해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKrvKr4lG_n2"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMbZo78_G_n3"
      },
      "source": [
        "### C. 파일에서 사용자 정의 데이터셋 만들기\n",
        "\n",
        "사용자 정의 Dataset 클래스는 반드시 3개 함수를 구현해야 합니다: `__init__`, `__len__`, and `__getitem__`. 아래 구현을 살펴보면 FashionMNIST 이미지들은 img_dir 디렉토리에 저장되고, 정답은 `annotations_file csv` 파일에 별도로 저장됩니다.\n",
        "\n",
        "다음 장에서 각 함수들에서 일어나는 일들을 자세히 살펴보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkd4lfDqG_n4"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OZGjfa4G_n5"
      },
      "source": [
        "#### a. \\_\\_init\\_\\_\n",
        "\n",
        "`__init__` 함수는 Dataset 객체가 생성(instantiate)될 때 한 번만 실행됩니다. 여기서는 이미지와 주석 파일(annotation_file)이 포함된 디렉토리와 (다음 장에서 자세히 살펴볼) 두가지 변형(transform)을 초기화합니다. \n",
        "\n",
        "labels.csv 파일은 다음과 같습니다: \n",
        "```\n",
        "tshirt1.jpg, 0\n",
        "tshirt2.jpg, 0\n",
        "......\n",
        "ankleboot999.jpg, 9\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U9PV98BG_n7"
      },
      "source": [
        "#### b. \\_\\_len\\_\\_\n",
        "\n",
        "`__len__` 함수는 데이터셋의 샘플 개수를 반환합니다.\n",
        "\n",
        "예:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxpNJMDdG_n8"
      },
      "source": [
        "#### c. \\_\\_getitem\\_\\_\n",
        "\n",
        "`__getitem__` 함수는 주어진 인덱스 ``idx`` 에 해당하는 샘플을 데이터셋에서 불러오고 반환합니다.<br>\n",
        "인덱스를 기반으로, 디스크에서 이미지의 위치를 식별하고, ``read_image`` 를 사용하여 이미지를 텐서로 변환하고, ``self.img_labels`` 의 csv 데이터로부터 해당하는 정답(label)을 가져오고, (해당하는 경우) 변형(transform) 함수들을 호출한 뒤, 텐서 이미지와 라벨을 Python 사전(dict)형으로 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUyIaUFgG_n8"
      },
      "source": [
        "def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "    sample = {\"image\": image, \"label\": label}\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsVQ5hdtG_n8"
      },
      "source": [
        "### D. DataLoader로 학습용 데이터 준비하기\n",
        "\n",
        "`Dataset`은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다. 모델을 학습할 때, 일반적으로 샘플들을 “미니배치(minibatch)”로 전달하고, 매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고, Python의 multiprocessing 을 사용하여 데이터 검색 속도를 높이려고 합니다.\n",
        "\n",
        "`DataLoader`는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iteratable)입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMSvH4aKG_n9"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPBX0WIqG_n9"
      },
      "source": [
        "### E. DataLoader를 통해 순회하기(iterate)\n",
        "\n",
        "``DataLoader`` 에 데이터셋을 불러온 뒤에는 필요에 따라 데이터셋을 순회(iterate)할 수 있습니다.\n",
        "아래의 각 순회(iteration)는 (각각 ``batch_size=64`` 의 특징(feature)과 정답(label)을 포함하는) ``train_features`` 와\n",
        "``train_labels`` 의 묶음(batch)을 반환합니다. ``shuffle=True`` 로 지정했으므로, 모든 배치를 순회한 뒤 데이터가 섞입니다.\n",
        "(데이터 불러오기 순서를 보다 세밀하게(finer-grained) 제어하려면 [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)\n",
        "를 살펴보세요.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxj98xfoG_n-"
      },
      "source": [
        "# 이미지와 정답(label)을 표시합니다.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}