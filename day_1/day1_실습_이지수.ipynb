{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day1_실습_이지수.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PEBpung/TotochTeam1/blob/main/day1_%ED%85%90%EC%84%9C(Tensor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_FyQ99czaAS"
      },
      "source": [
        "# 이웃집 토토치 파이토치 : Day 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIEtaQ_Czdkp"
      },
      "source": [
        "📢 해당 게시물은 파이토치 공식 튜토리얼 중 파이토치(PyTorch) 시작하기를 읽고 직접 작성해보는 실습 노트북입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaiMk6Q6CVn8"
      },
      "source": [
        "#### 목차\n",
        "1. 탠서(TENSOR)\n",
        "    1. 텐서(tensor) 초기화\n",
        "    2. 텐서의 속성(Attribute)\n",
        "    3. 텐서 연산(Operation)\n",
        "    4. NumPy 변환(Bridge)\n",
        "2. Autograd\n",
        "    1. 간단한 이미지 분류 학습\n",
        "    2. [실습] 연산 그래프 직접 구현하기\n",
        "3. DATASET과 DATALOADER\n",
        "    1. 데이터셋 불러오기\n",
        "    2. 데이터셋을 순회하고 시각화하기\n",
        "    3. 파일에서 사용자 정의 데이터셋 만들기\n",
        "    4. DataLoader로 학습용 데이터 준비하기\n",
        "    5. DataLoader를 통해 순회하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5CTkc4nirPn"
      },
      "source": [
        "## 1. 텐서 (Tensor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxpKzLnXimaU"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul7rdwiRi5zl"
      },
      "source": [
        "### 텐서(tensor) 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVcsUDhcjCrD"
      },
      "source": [
        "**데이터로부터 직접(directly) 생성하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10y9YFqZiopn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f94c886-31e0-4421-afc5-71e60a34874f"
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "x_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhK77YQwi6L1"
      },
      "source": [
        "**NumPy 배열로부터 생성하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvgWwsTUipiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364e6914-8284-43b1-84f0-8ca5e325dca1"
      },
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "x_np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF0gt5U6jR8V"
      },
      "source": [
        "**다른 텐서로부터 생성하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wikxshb9iqQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487a1f14-ff7d-466e-fbe1-b0012cd2bb82"
      },
      "source": [
        "# x_data의 속성을 유지합니다.\n",
        "x_ones = torch.ones_like(x_data) \n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "# x_data의 속성을 덮어씁니다.\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) \n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5539, 0.2157],\n",
            "        [0.0180, 0.8247]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sepex-_YjYkG"
      },
      "source": [
        "**무작위(random) 또는 상수(constant) 값을 사용하기:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmVb1QuTiqZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187c23ee-ac15-45f3-8b81-ae16727ffe12"
      },
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.1403, 0.5211, 0.2082],\n",
            "        [0.2220, 0.5965, 0.1121]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVltQbTlCVoD"
      },
      "source": [
        "rand_tensor.add(ones_tensor)\n",
        "print(rand_tensor)\n",
        "rand_tensor.add_(ones_tensor)\n",
        "print(rand_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2blbrRdjgI2"
      },
      "source": [
        "### 텐서의 속성(Attribute)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HbUDrVljf_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc58bb33-6a52-4888-948f-21fe01f9d150"
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdTMCC1KmPD-"
      },
      "source": [
        "### 텐서 연산(Operation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_RWKZ82CVoE"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. 텐서를 사용하면 어떤 점이 좋을까요??</b></p>\n",
        "    <p>👉 1. tensor is a multidimensional array with a uniform data type as dtype <br> 2. gpu 사용에 원활 <br></p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyM7zxmnjf3y"
      },
      "source": [
        "# GPU가 존재하면 텐서를 이동합니다\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV3e7QrZmdF8"
      },
      "source": [
        "NumPy식의 표준 인덱싱과 슬라이싱:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "522O3OXJjfuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8827a691-75be-448f-8535-dcbf04a5989d"
      },
      "source": [
        "data = [[1, 2, 3],\n",
        "         [4, 5, 6],\n",
        "         [7, 8, 9]]\n",
        "t_data = torch.tensor(data)\n",
        "\n",
        "print('2번째 행 출력: ',t_data[1])\n",
        "print('t_data에서 5를 출력: ', t_data[1,1])\n",
        "print('마지막 column 출력:', t_data[:, -1])\n",
        "print('3번째 column을 0으로 만들기:')\n",
        "t_data[:, 2] = 0\n",
        "\n",
        "print(t_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2번째 행 출력:  tensor([4, 5, 6])\n",
            "t_data에서 5를 출력:  tensor(5)\n",
            "마지막 column 출력: tensor([3, 6, 9])\n",
            "3번째 column을 0으로 만들기:\n",
            "tensor([[1, 2, 0],\n",
            "        [4, 5, 0],\n",
            "        [7, 8, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DbwAF-TpeBg"
      },
      "source": [
        "**텐서 합치기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWGBUa0ljfi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff7aff2-d06c-41a1-c02f-80f011df6a86"
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2256, 0.5805, 0.3120, 0.7266, 0.2256, 0.5805, 0.3120, 0.7266, 0.2256,\n",
            "         0.5805, 0.3120, 0.7266],\n",
            "        [0.6534, 0.7825, 0.5527, 0.9068, 0.6534, 0.7825, 0.5527, 0.9068, 0.6534,\n",
            "         0.7825, 0.5527, 0.9068],\n",
            "        [0.8042, 0.7445, 0.4327, 0.1314, 0.8042, 0.7445, 0.4327, 0.1314, 0.8042,\n",
            "         0.7445, 0.4327, 0.1314]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCf2__l_ppjd"
      },
      "source": [
        "**산술 연산(Arithmetic operations)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAMnNAnurkDb"
      },
      "source": [
        "tensor = torch.rand(3,4)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zTjlfFmFA_g",
        "outputId": "72d277bc-9ba9-44a9-f042-430347eee9f4"
      },
      "source": [
        "torch.matmul(tensor, tensor.T, out=y3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7870, 1.5411, 1.6276],\n",
              "        [1.5411, 1.4101, 1.5690],\n",
              "        [1.6276, 1.5690, 2.2733]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rl2lXktjfEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbfe7ba-d7c8-44f3-dd62-c18fd2b09b94"
      },
      "source": [
        "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
        "y1 = tensor @ tensor.T # @가 matmul인가 보군 \n",
        "y2 = tensor.matmul(tensor.T)\n",
        "# torch.matmul(tensor, tensor.T, out=y3) # 같은 결과 \n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "\n",
        "print(y1)\n",
        "print(y2)\n",
        "print(y3)\n",
        "\n",
        "print('-- '*15)\n",
        "\n",
        "# mul은 일반적 곱셈, matmul은 matrix곱\n",
        "\n",
        "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)\n",
        "print(z1)\n",
        "print(z2)\n",
        "print(z3)\n",
        "\n",
        "# question. 그런데 왜 rand_like라서 shape만 같으면 되는데 값이 같게 나와? "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7870, 1.5411, 1.6276],\n",
            "        [1.5411, 1.4101, 1.5690],\n",
            "        [1.6276, 1.5690, 2.2733]])\n",
            "tensor([[1.7870, 1.5411, 1.6276],\n",
            "        [1.5411, 1.4101, 1.5690],\n",
            "        [1.6276, 1.5690, 2.2733]])\n",
            "tensor([[1.7870, 1.5411, 1.6276],\n",
            "        [1.5411, 1.4101, 1.5690],\n",
            "        [1.6276, 1.5690, 2.2733]])\n",
            "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
            "tensor([[8.7574e-01, 2.0804e-04, 4.5468e-01, 4.5636e-01],\n",
            "        [4.5053e-01, 1.3045e-02, 2.9391e-01, 6.5258e-01],\n",
            "        [7.2657e-01, 5.7258e-01, 6.8082e-02, 9.0604e-01]])\n",
            "tensor([[8.7574e-01, 2.0804e-04, 4.5468e-01, 4.5636e-01],\n",
            "        [4.5053e-01, 1.3045e-02, 2.9391e-01, 6.5258e-01],\n",
            "        [7.2657e-01, 5.7258e-01, 6.8082e-02, 9.0604e-01]])\n",
            "tensor([[8.7574e-01, 2.0804e-04, 4.5468e-01, 4.5636e-01],\n",
            "        [4.5053e-01, 1.3045e-02, 2.9391e-01, 6.5258e-01],\n",
            "        [7.2657e-01, 5.7258e-01, 6.8082e-02, 9.0604e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KJunc26CVoG"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. 행렬 곱(matrix multiplication)과 요소별 곱(element-wise product)의 차이점이 뭘까요??</b></p>\n",
        "    <p>👉 mul은 일반적 곱셈, matmul은 matrix곱</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS823HhDsI6Z"
      },
      "source": [
        "**단일-요소(single-element)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9_IWxvHsIqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195693e8-fc39-41f4-8aa5-9a8447e31862"
      },
      "source": [
        "print(tensor)\n",
        "# 모든 값들의 종합 \n",
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9358, 0.0144, 0.6743, 0.6755],\n",
            "        [0.6712, 0.1142, 0.5421, 0.8078],\n",
            "        [0.8524, 0.7567, 0.2609, 0.9519]])\n",
            "7.2573370933532715 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6VGHAC4wWCi"
      },
      "source": [
        "**텐서차원 축소/확장(Squeeze/Unsqueeze) 연산**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYhTcpCor2wC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ae26ca-500e-4375-82ab-facc7bb6c72f"
      },
      "source": [
        "# Squeeze/Unsqueeze\n",
        "x = torch.rand((1,1,3,4))\n",
        "print(x)\n",
        "y = x.squeeze()\n",
        "print(y)\n",
        "\n",
        "print(y.size())\n",
        "print(y.unsqueeze(1).size())\n",
        "print(y.unsqueeze(1))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.5156, 0.2884, 0.3448, 0.7284],\n",
            "          [0.4604, 0.7629, 0.1168, 0.2796],\n",
            "          [0.3170, 0.6365, 0.9293, 0.0282]]]])\n",
            "tensor([[0.5156, 0.2884, 0.3448, 0.7284],\n",
            "        [0.4604, 0.7629, 0.1168, 0.2796],\n",
            "        [0.3170, 0.6365, 0.9293, 0.0282]])\n",
            "torch.Size([3, 4])\n",
            "torch.Size([3, 1, 4])\n",
            "tensor([[[0.5156, 0.2884, 0.3448, 0.7284]],\n",
            "\n",
            "        [[0.4604, 0.7629, 0.1168, 0.2796]],\n",
            "\n",
            "        [[0.3170, 0.6365, 0.9293, 0.0282]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odrEcD_qCVoI"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. Squeeze와 Unsqueeze는 어떤 경우에 사용 될까요? 자유롭게 생각해보죠!</b></p>\n",
        "    <p>👉 nn 학습진행시 dimension change 필요할 때</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h58rooooCVoI"
      },
      "source": [
        "**스태킹(Stacking)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl5cJQ34CVoI",
        "outputId": "c8991f33-d016-48d9-b177-d51da0e5897b"
      },
      "source": [
        "x = torch.FloatTensor([1, 4])\n",
        "y = torch.FloatTensor([2, 5])\n",
        "z = torch.FloatTensor([3, 6])\n",
        "\n",
        "print(type(x[0]))\n",
        "print(torch.stack([x, y, z]))\n",
        "print(torch.stack([x, y, z]).size())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n",
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S46yib7CVoJ"
      },
      "source": [
        "### 넘파이(Numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17IUYsqNxUxp"
      },
      "source": [
        "**텐서를 NumPy 배열로 변환하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EuvEtoIxUl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd757028-b176-427d-e805-25ba93436da3"
      },
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy() # 반대는 from_numpy\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDV_kHfJxYvM"
      },
      "source": [
        "텐서의 변경 사항이 NumPy 배열에 반영됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcKNnWvFxUhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87239856-cc04-4eea-96d7-eedb7d7ec0b4"
      },
      "source": [
        "t.add_(1) # 공홈에서 해당 방식 권장하지는 않는다고 함 \n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D5LXTwDxcap"
      },
      "source": [
        "**NumPy 배열을 텐서로 변환하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GLooKX3xUfd"
      },
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0VP8MyOxfq_"
      },
      "source": [
        "NumPy 배열의 변경 사항이 텐서에 반영됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJL53PRxUZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85454251-fcff-453f-ff8e-1c902af344cc"
      },
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\") # tensor는 바꾸지도 않았는데 변화가 되네 \n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBHa6JzGCVoK"
      },
      "source": [
        "# 2. Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHePx4GICVoK"
      },
      "source": [
        "## 간단 이미지 분류 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89gkUIYfCVoK",
        "outputId": "9163c505-4d31-409e-f9f5-e3a2b0e17f8a"
      },
      "source": [
        "random_seed = 99\n",
        "torch.manual_seed(random_seed)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe914d61b30>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfO4haxlCVoL"
      },
      "source": [
        "동일한 출력을 얻기 위해서 random seed 값 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTdDjGZZCVoL"
      },
      "source": [
        "### 1) 데이터 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-F96q7jCVoL",
        "outputId": "d529e35a-a9b0-4dbb-ccfa-397ea0633841"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(6, 1),\n",
        "    torch.nn.Flatten()\n",
        ")\n",
        "print(model)\n",
        "\n",
        "data = torch.rand(2, 6)\n",
        "labels = torch.ones(2, 1)\n",
        "print(data)\n",
        "print(labels)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=6, out_features=1, bias=True)\n",
            "  (1): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n",
            "tensor([[0.5017, 0.2137, 0.8108, 0.7784, 0.2362, 0.2899],\n",
            "        [0.3328, 0.9092, 0.2502, 0.6224, 0.9650, 0.5300]])\n",
            "tensor([[1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeHZN3b5CVoL"
      },
      "source": [
        "label 값은 ([1.], [1.])입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymsqHu99CVoM"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. 각자 그림을 그리면서 이해하시는 것을 추천드립니다!</b></p>\n",
        "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmh51bURCVoM"
      },
      "source": [
        "### 2) 순전파 (Forward Propagation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds0pnb4FCVoM",
        "outputId": "b43deaa2-8b4b-402a-c05f-daab72c958f2"
      },
      "source": [
        "prediction = model(data) # 순전파 단계(forward pass)\n",
        "prediction"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5021],\n",
              "        [-0.2194]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eedYpT_kCVoM"
      },
      "source": [
        "순전파 단계에서는 입력(input) 데이터를 모델의 각 층(layer)에 통과시켜 예측값(prediction)을 생성합니다.   \n",
        "모델의 output으로 나온 pred 값은 ([0.3425], [0.2512])입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DkVPeFlCVoM",
        "outputId": "c6fc1c83-4323-41b2-90c5-34c9b9cc58ca"
      },
      "source": [
        "layer = model[0]\n",
        "print(layer)\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=6, out_features=1, bias=True)\n",
            "Result: y = -0.10972732305526733 + 0.04066823050379753 x + -0.35353073477745056 x^2 + -0.3128962814807892 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q35JQesXCVoN"
      },
      "source": [
        "모델의 초기 weight와 bias를 확인 해보시길 바랍니다.  \n",
        "손실함수와 옵티마이저를 사용해서 이 값들을 변경할 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-1HTXSxCVoN"
      },
      "source": [
        "### 3) 손실함수 (loss) 계산하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jELkCTJtCVoN",
        "outputId": "d9aa3c61-b807-4dd8-fc83-191646120335"
      },
      "source": [
        "loss = (prediction - labels).sum() \n",
        "print(prediction-labels)\n",
        "print(loss)\n",
        "loss.backward() # 역전파 단계(backward pass)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5021],\n",
            "        [-1.2194]], grad_fn=<SubBackward0>)\n",
            "tensor(-2.7215, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXm15y5aCVoN"
      },
      "source": [
        "- 모델의 예측값(prediction)과 그에 해당하는 정답(label)의 차이를 합하여 오차(error, 손실(loss) )를 계산하였습니다. 손실함수를 구하는 방법은 다양하지만 이번글에서는 간단하게 차이값으로만 구하도록 하겠습니다.\n",
        "\n",
        "-  오차 텐서(error tensor)에 .backward() 를 호출하면 역전파가 시작되며, 그 다음 Autograd가 매개변수(parameter)의 .grad 속성(attribute)에, 모델의 각 매개변수에 대한 변화도(gradient)를 계산하고 저장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d40Nkr_3CVoN"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. loss의 결과는 -1.4063이 나왔습니다, 직접 labels 값과 pred 값을 비교해서 계산해봅시다!</b></p>\n",
        "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8lBwpwTMtv2",
        "outputId": "534cd4cc-9969-409b-d010-5118dbdfbac0"
      },
      "source": [
        "# for checking the process\n",
        "\n",
        "print(data)\n",
        "print(labels)\n",
        "\n",
        "for i, d in enumerate(zip(data, labels)):\n",
        "  # print(d)\n",
        "  # print(d[0][0])\n",
        "  # print(d[0][1])\n",
        "  # print(d[1][0])\n",
        "  print(d[0].sum())\n",
        "  print(torch.sub(d[1], d[0]))\n",
        "  print(torch.sub(d[0], d[1]).sum())\n",
        "  print(torch.sub(d[0], d[1]).sum() / len(d[0]))\n",
        "  # tensor.add(d[1]) - tensor.add(d[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5017, 0.2137, 0.8108, 0.7784, 0.2362, 0.2899],\n",
            "        [0.3328, 0.9092, 0.2502, 0.6224, 0.9650, 0.5300]])\n",
            "tensor([[1.],\n",
            "        [1.]])\n",
            "tensor(2.8307)\n",
            "tensor([0.4983, 0.7863, 0.1892, 0.2216, 0.7638, 0.7101])\n",
            "tensor(-3.1693)\n",
            "tensor(-0.5282)\n",
            "tensor(3.6095)\n",
            "tensor([0.6672, 0.0908, 0.7498, 0.3776, 0.0350, 0.4700])\n",
            "tensor(-2.3905)\n",
            "tensor(-0.3984)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "motQm8bkCVoN"
      },
      "source": [
        "### 4) 옵티마이저 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqNE3LUCVoO"
      },
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux-G4UpkCVoO"
      },
      "source": [
        "- 학습율(learning rate) 0.01과 모멘텀(momentum) 0.9를 갖는 SGD로 옵티마이즈를 설정하였으며, 옵티마이저(optimizer)에 모델의 모든 매개변수(models.parameters())를 등록합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzKeepCiCVoO"
      },
      "source": [
        "### 5) 경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5iIUEQ1CVoO"
      },
      "source": [
        "optim.step() # 경사하강법(gradient descent)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLp6KdmXCVoO"
      },
      "source": [
        "- step 을 호출하여 경사하강법(gradient descent)을 시작합니다. 옵티마이저는 .grad 에 저장된 기울기(gradient)에 따라 각 매개변수를 조정(adjust)합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svkt46doCVoP",
        "outputId": "554f3b7a-c8da-4f60-c060-24818d290c93"
      },
      "source": [
        "layer = model[0]\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: y = -0.1297273188829422 + 0.032322634011507034 x + -0.36475998163223267 x^2 + -0.32350581884384155 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QteM3csCVoP",
        "outputId": "c19616e6-9e7b-4e02-92ab-61378e50471b"
      },
      "source": [
        "prediction = model(data) # 순전파 단계(forward pass)\n",
        "prediction"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5534],\n",
              "        [-0.2797]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appgsnciCVoP"
      },
      "source": [
        "## 실습 문제\n",
        "다음과 같은 연산 그래프를 직접 구현하면서 Autograd를 이해해보는 시간을 갖겠습니다.   \n",
        "이번 실습에서는 backpop의 미분 값이 어떻게 계산되는 지 살펴볼 것입니다.  \n",
        "x는 초기 값으로 2x2의 1로 채워진 행렬을 사용할 것입니다.  \n",
        "\n",
        "<img src=\"./img/ex1.jpg\" width='600'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5LoJC6fCVoP",
        "outputId": "71876943-216b-4acf-f290-def585afd0ef"
      },
      "source": [
        "x = torch.ones(2, 2)\n",
        "print(x)\n",
        "print(x.requires_grad) # True면 autograd 에 모든 연산(operation)들을 추적\n",
        "print('-'*10)\n",
        "\n",
        "x = torch.ones(2, 2, requires_grad=True) # default가 False\n",
        "print(x)\n",
        "print(x.requires_grad)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "False\n",
            "----------\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRO6g7B6CVoP"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. requires_grad는 어떤 역할을 하는 파라미터일까요?</b></p>\n",
        "    <p>👉 True면 autograd 에 모든 연산(operation)들을 추적</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXjpO9XBCVoP",
        "outputId": "9bd8ebc0-656f-4d7a-9275-818e08e2e981"
      },
      "source": [
        "y = x +2\n",
        "print(y)\n",
        "print(y.requires_grad)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEwr0o9yCVoQ",
        "outputId": "3a967892-b07d-4b51-ccc7-adfbda140401"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7fe90fb7fbd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5IPZyaDCVoQ",
        "outputId": "2d1c21d8-5172-4fe7-b731-dab51256ae01"
      },
      "source": [
        "z = 3 * y**2\n",
        "out = z.mean()\n",
        "print(z)\n",
        "print(out)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coZABm4MCVoQ",
        "outputId": "91576341-c152-4c80-a97f-91dd0a341d78"
      },
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "\n",
        "z = torch.matmul(x, w)+b\n",
        "print(z)\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smCMoZ59CVoQ"
      },
      "source": [
        "### Gradient, 경사/기울기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rrgrc7ZCVoQ"
      },
      "source": [
        "역전파를 해보겠습니다. out.backward()과 out.backward(torch.Tensor([1.0]))은 동일하게 동작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfQsfv0TCVoQ"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hZugx4vCVoR"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsmNDZnFCVoR"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. requires_grad = True를 하면 무슨 일이 일어나길래, grad()를 호출하면 바로 미분값을 합산해줄까?</b></p>\n",
        "    <p>👉 미분연산그래프 제작, input부터 output까지 미분 연산되어야 한다는것을 torch에게 알림 </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDDd5PjECVoR"
      },
      "source": [
        "# 3. DATASET과 DATALOADER\n",
        "\n",
        "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\n",
        "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
        "\n",
        "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\n",
        "\n",
        "여기에서 데이터셋들을 찾아볼 수 있습니다:\n",
        "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \n",
        "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\n",
        "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bLX-NfjCVoR"
      },
      "source": [
        "### A. 데이터셋 불러오기\n",
        "\n",
        "`TorchVision` 에서 [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist) 데이터셋을\n",
        "불러오는 예제를 살펴보겠습니다. Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다. 각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성됩니다.\n",
        "\n",
        "다음 매개변수들을 사용하여 [FashionMNIST 데이터셋](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)을 불러옵니다:\n",
        " - ``root`` 는 학습/테스트 데이터가 저장되는 경로입니다.\n",
        " - ``train`` 은 학습용 또는 테스트용 데이터셋 여부를 지정합니다.\n",
        " - ``download=True`` 는 ``root`` 에 데이터가 없는 경우 인터넷에서 다운로드합니다.\n",
        " - ``transform`` 과 ``target_transform`` 은 특징(feature)과 정답(label) 변형(transform)을 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nctpsiN9CVoR"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNZacYNny2Nx"
      },
      "source": [
        "### B. 데이터셋을 순회하고 시각화하기\n",
        "\n",
        "Dataset 에 리스트(list)처럼 직접 접근(index)할 수 있습니다: training_data[index]. matplotlib 을 사용하여 학습 데이터의 일부를 시각화해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZjJC6HlCVoS"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()  # .item(): python 숫자값으로 바꿔주기 \n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4alUO5l9CVoS"
      },
      "source": [
        "### C. 파일에서 사용자 정의 데이터셋 만들기\n",
        "\n",
        "사용자 정의 Dataset 클래스는 반드시 3개 함수를 구현해야 합니다: `__init__`, `__len__`, and `__getitem__`. 아래 구현을 살펴보면 FashionMNIST 이미지들은 img_dir 디렉토리에 저장되고, 정답은 `annotations_file csv` 파일에 별도로 저장됩니다.\n",
        "\n",
        "다음 장에서 각 함수들에서 일어나는 일들을 자세히 살펴보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40PqOXr_CVoS"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]) # 0: 파일명\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1] # 1: 라벨 \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me-lqBfUCVoS"
      },
      "source": [
        "#### a. \\_\\_init\\_\\_\n",
        "\n",
        "`__init__` 함수는 Dataset 객체가 생성(instantiate)될 때 한 번만 실행됩니다. 여기서는 이미지와 주석 파일(annotation_file)이 포함된 디렉토리와 (다음 장에서 자세히 살펴볼) 두가지 변형(transform)을 초기화합니다. \n",
        "\n",
        "labels.csv 파일은 다음과 같습니다: \n",
        "```\n",
        "tshirt1.jpg, 0\n",
        "tshirt2.jpg, 0\n",
        "......\n",
        "ankleboot999.jpg, 9\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbFVmU4hCVoT"
      },
      "source": [
        "#### b. \\_\\_len\\_\\_\n",
        "\n",
        "`__len__` 함수는 데이터셋의 샘플 개수를 반환합니다.\n",
        "\n",
        "예:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeeKTx2KCVoT"
      },
      "source": [
        "#### c. \\_\\_getitem\\_\\_\n",
        "\n",
        "`__getitem__` 함수는 주어진 인덱스 ``idx`` 에 해당하는 샘플을 데이터셋에서 불러오고 반환합니다.<br>\n",
        "인덱스를 기반으로, 디스크에서 이미지의 위치를 식별하고, ``read_image`` 를 사용하여 이미지를 텐서로 변환하고, ``self.img_labels`` 의 csv 데이터로부터 해당하는 정답(label)을 가져오고, (해당하는 경우) 변형(transform) 함수들을 호출한 뒤, 텐서 이미지와 라벨을 Python 사전(dict)형으로 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k1nuduNCVoT"
      },
      "source": [
        "def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform: # .transform : to dict\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "    # sample = {\"image\": image, \"label\": label}\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egxe1WZhCVoT"
      },
      "source": [
        "### D. DataLoader로 학습용 데이터 준비하기\n",
        "\n",
        "`Dataset`은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다. 모델을 학습할 때, 일반적으로 샘플들을 “미니배치(minibatch)”로 전달하고, 매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고, Python의 multiprocessing 을 사용하여 데이터 검색 속도를 높이려고 합니다.\n",
        "\n",
        "`DataLoader`는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iteratable)입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnlYal0uCVoT"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TINHRC15CVoU"
      },
      "source": [
        "### E. DataLoader를 통해 순회하기(iterate)\n",
        "\n",
        "``DataLoader`` 에 데이터셋을 불러온 뒤에는 필요에 따라 데이터셋을 순회(iterate)할 수 있습니다.\n",
        "아래의 각 순회(iteration)는 (각각 ``batch_size=64`` 의 특징(feature)과 정답(label)을 포함하는) ``train_features`` 와\n",
        "``train_labels`` 의 묶음(batch)을 반환합니다. ``shuffle=True`` 로 지정했으므로, 모든 배치를 순회한 뒤 데이터가 섞입니다.\n",
        "(데이터 불러오기 순서를 보다 세밀하게(finer-grained) 제어하려면 [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)\n",
        "를 살펴보세요.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Q82Z-QJnJX"
      },
      "source": [
        "next(iter(train_dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn-Ssjn4CVoU"
      },
      "source": [
        "# 이미지와 정답(label)을 표시합니다.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}