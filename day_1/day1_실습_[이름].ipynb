{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "텐서(Tensor).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyR/FppqH3gkf6meWYCI0Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/PEBpung/TotochTeam1/blob/main/day1_%ED%85%90%EC%84%9C(Tensor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이웃집 토토치 파이토치 : Day 1"
      ],
      "metadata": {
        "id": "C_FyQ99czaAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📢 해당 게시물은 파이토치 공식 튜토리얼 중 파이토치(PyTorch) 시작하기를 읽고 직접 작성해보는 실습 노트북입니다."
      ],
      "metadata": {
        "id": "GIEtaQ_Czdkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 목차\r\n",
        "1. 탠서(TENSOR)\r\n",
        "    1. 텐서(tensor) 초기화\r\n",
        "    2. 텐서의 속성(Attribute)\r\n",
        "    3. 텐서 연산(Operation)\r\n",
        "    4. NumPy 변환(Bridge)\r\n",
        "2. Autograd\r\n",
        "    1. 간단한 이미지 분류 학습\r\n",
        "    2. [실습] 연산 그래프 직접 구현하기\r\n",
        "3. DATASET과 DATALOADER\r\n",
        "    1. 데이터셋 불러오기\r\n",
        "    2. 데이터셋을 순회하고 시각화하기\r\n",
        "    3. 파일에서 사용자 정의 데이터셋 만들기\r\n",
        "    4. DataLoader로 학습용 데이터 준비하기\r\n",
        "    5. DataLoader를 통해 순회하기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 텐서 (Tensor)"
      ],
      "metadata": {
        "id": "w5CTkc4nirPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "id": "mxpKzLnXimaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서(tensor) 초기화"
      ],
      "metadata": {
        "id": "Ul7rdwiRi5zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터로부터 직접(directly) 생성하기**"
      ],
      "metadata": {
        "id": "ZVcsUDhcjCrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = [[1, 2],[3, 4]]\r\n",
        "x_data = torch.tensor(data)\r\n",
        "x_data"
      ],
      "outputs": [],
      "metadata": {
        "id": "10y9YFqZiopn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy 배열로부터 생성하기**"
      ],
      "metadata": {
        "id": "BhK77YQwi6L1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np_array = np.array(data)\r\n",
        "x_np = torch.from_numpy(np_array)\r\n",
        "x_np"
      ],
      "outputs": [],
      "metadata": {
        "id": "KvgWwsTUipiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**다른 텐서로부터 생성하기**"
      ],
      "metadata": {
        "id": "CF0gt5U6jR8V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# x_data의 속성을 유지합니다.\r\n",
        "x_ones = torch.ones_like(x_data) \r\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\r\n",
        "\r\n",
        "# x_data의 속성을 덮어씁니다.\r\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) \r\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "wikxshb9iqQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**무작위(random) 또는 상수(constant) 값을 사용하기:**"
      ],
      "metadata": {
        "id": "Sepex-_YjYkG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "shape = (2,3,)\r\n",
        "rand_tensor = torch.rand(shape)\r\n",
        "ones_tensor = torch.ones(shape)\r\n",
        "zeros_tensor = torch.zeros(shape)\r\n",
        "\r\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\r\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\r\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "jmVb1QuTiqZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rand_tensor.add(ones_tensor)\r\n",
        "print(rand_tensor)\r\n",
        "rand_tensor.add_(ones_tensor)\r\n",
        "print(rand_tensor)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서의 속성(Attribute)"
      ],
      "metadata": {
        "id": "p2blbrRdjgI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tensor = torch.rand(3,4)\r\n",
        "\r\n",
        "############################\r\n",
        "# 밑줄 친 곳을 채워주세요! #\r\n",
        "############################\r\n",
        "\r\n",
        "print(f\"Shape of tensor: {___}\")\r\n",
        "print(f\"Datatype of tensor: {___}\")\r\n",
        "print(f\"Device tensor is stored on: {___}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "6HbUDrVljf_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서 연산(Operation)"
      ],
      "metadata": {
        "id": "QdTMCC1KmPD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. 텐서를 사용하면 어떤 점이 좋을까요??</b></p>\r\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# GPU가 존재하면 텐서를 이동합니다\r\n",
        "if torch.cuda.is_available():\r\n",
        "  tensor = tensor.to('cuda')"
      ],
      "outputs": [],
      "metadata": {
        "id": "nyM7zxmnjf3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy식의 표준 인덱싱과 슬라이싱:"
      ],
      "metadata": {
        "id": "LV3e7QrZmdF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = [[1, 2, 3],\r\n",
        "         [4, 5, 6],\r\n",
        "         [7, 8, 9]]\r\n",
        "t_data = torch.tensor(data)\r\n",
        "\r\n",
        "############################\r\n",
        "# 밑줄 친 곳을 채워주세요! #\r\n",
        "############################\r\n",
        "\r\n",
        "print('2번째 행 출력: ',___)\r\n",
        "print('t_data에서 5를 출력: ', ___)\r\n",
        "print('마지막 column 출력:', ___)\r\n",
        "t_data[___] = 0\r\n",
        "print('3번째 column을 0으로 만들기:')\r\n",
        "print(t_data)"
      ],
      "outputs": [],
      "metadata": {
        "id": "522O3OXJjfuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**텐서 합치기**"
      ],
      "metadata": {
        "id": "4DbwAF-TpeBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\r\n",
        "print(t1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kWGBUa0ljfi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**산술 연산(Arithmetic operations)**"
      ],
      "metadata": {
        "id": "VCf2__l_ppjd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tensor = torch.rand(3,4)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FAMnNAnurkDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\r\n",
        "y1 = tensor @ tensor.T\r\n",
        "y2 = tensor.matmul(tensor.T)\r\n",
        "\r\n",
        "y3 = torch.rand_like(tensor)\r\n",
        "torch.matmul(tensor, tensor.T, out=y3)\r\n",
        "print(y1)\r\n",
        "print(y2)\r\n",
        "print(y3)\r\n",
        "\r\n",
        "print('-- '*15)\r\n",
        "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\r\n",
        "z1 = tensor * tensor\r\n",
        "z2 = tensor.mul(tensor)\r\n",
        "\r\n",
        "z3 = torch.rand_like(tensor)\r\n",
        "torch.mul(tensor, tensor, out=z3)\r\n",
        "print(z1)\r\n",
        "print(z2)\r\n",
        "print(z3)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8rl2lXktjfEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. 행렬 곱(matrix multiplication)과 요소별 곱(element-wise product)의 차이점이 뭘까요??</b></p>\r\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단일-요소(single-element)**"
      ],
      "metadata": {
        "id": "tS823HhDsI6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "agg = tensor.sum()\r\n",
        "agg_item = agg.item()\r\n",
        "print(agg_item, type(agg_item))"
      ],
      "outputs": [],
      "metadata": {
        "id": "C9_IWxvHsIqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**텐서차원 축소/확장(Squeeze/Unsqueeze) 연산**"
      ],
      "metadata": {
        "id": "F6VGHAC4wWCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Squeeze/Unsqueeze\r\n",
        "x = torch.rand((1,1,3,4))\r\n",
        "y = x.squeeze()\r\n",
        "print(y.size())\r\n",
        "print(y.unsqueeze(1).size())"
      ],
      "outputs": [],
      "metadata": {
        "id": "DYhTcpCor2wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. Squeeze와 Unsqueeze는 어떤 경우에 사용 될까요? 자유롭게 생각해보죠!</b></p>\r\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**스태킹(Stacking)**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = torch.FloatTensor([1, 4])\r\n",
        "y = torch.FloatTensor([2, 5])\r\n",
        "z = torch.FloatTensor([3, 6])\r\n",
        "\r\n",
        "print(torch.stack([x, y, z]))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 넘파이(Numpy)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**텐서를 NumPy 배열로 변환하기**"
      ],
      "metadata": {
        "id": "17IUYsqNxUxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "t = torch.ones(5)\r\n",
        "print(f\"t: {t}\")\r\n",
        "n = t.numpy()\r\n",
        "print(f\"n: {n}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "5EuvEtoIxUl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서의 변경 사항이 NumPy 배열에 반영됩니다."
      ],
      "metadata": {
        "id": "IDV_kHfJxYvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "t.add_(1)\r\n",
        "print(f\"t: {t}\")\r\n",
        "print(f\"n: {n}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "FcKNnWvFxUhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy 배열을 텐서로 변환하기**"
      ],
      "metadata": {
        "id": "4D5LXTwDxcap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "n = np.ones(5)\r\n",
        "t = torch.from_numpy(n)"
      ],
      "outputs": [],
      "metadata": {
        "id": "0GLooKX3xUfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy 배열의 변경 사항이 텐서에 반영됩니다."
      ],
      "metadata": {
        "id": "Y0VP8MyOxfq_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.add(n, 1, out=n)\r\n",
        "print(f\"t: {t}\")\r\n",
        "print(f\"n: {n}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "9XJL53PRxUZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Autograd"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 간단 이미지 분류 모델 학습"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "random_seed = 99\r\n",
        "torch.manual_seed(random_seed)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "동일한 출력을 얻기 위해서 random seed 값 설정"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 데이터 준비하기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = torch.nn.Sequential(\r\n",
        "    torch.nn.Linear(6, 1),\r\n",
        "    torch.nn.Flatten()\r\n",
        ")\r\n",
        "data = torch.rand(2, 6)\r\n",
        "labels = torch.ones(2, 1)\r\n",
        "labels"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤으로 설정된 label 값은 ([1.], [1.])입니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. 각자 그림을 그리면서 이해하시는 것을 추천드립니다!</b></p>\r\n",
        "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 순전파 (Forward Propagation)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "prediction = model(data) # 순전파 단계(forward pass)\r\n",
        "prediction"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "순전파 단계에서는 입력(input) 데이터를 모델의 각 층(layer)에 통과시켜 예측값(prediction)을 생성합니다.   \r\n",
        "모델의 output으로 나온 pred 값은 ([0.3425], [0.2512])입니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "layer = model[0]\r\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 초기 weight와 bias를 확인 해보시길 바랍니다.  \r\n",
        "손실함수와 옵티마이저를 사용해서 이 값들을 변경할 것입니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) 손실함수 (loss) 계산하기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss = (prediction - labels).sum() \r\n",
        "print(loss)\r\n",
        "loss.backward() # 역전파 단계(backward pass)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델의 예측값(prediction)과 그에 해당하는 정답(label)의 차이를 합하여 오차(error, 손실(loss) )를 계산하였습니다. 손실함수를 구하는 방법은 다양하지만 이번글에서는 간단하게 차이값으로만 구하도록 하겠습니다.\r\n",
        "\r\n",
        "-  오차 텐서(error tensor)에 .backward() 를 호출하면 역전파가 시작되며, 그 다음 Autograd가 매개변수(parameter)의 .grad 속성(attribute)에, 모델의 각 매개변수에 대한 변화도(gradient)를 계산하고 저장합니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. loss의 결과는 -1.4063이 나왔습니다, 직접 labels 값과 pred 값을 비교해서 계산해봅시다!</b></p>\r\n",
        "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) 옵티마이저 설정"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습율(learning rate) 0.01과 모멘텀(momentum) 0.9를 갖는 SGD로 옵티마이즈를 설정하였으며, 옵티마이저(optimizer)에 모델의 모든 매개변수(models.parameters())를 등록합니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) 경사하강법"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optim.step() # 경사하강법(gradient descent)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- step 을 호출하여 경사하강법(gradient descent)을 시작합니다. 옵티마이저는 .grad 에 저장된 기울기(gradient)에 따라 각 매개변수를 조정(adjust)합니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "layer = model[0]\r\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "prediction = model(data) # 순전파 단계(forward pass)\r\n",
        "prediction"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 문제\r\n",
        "다음과 같은 연산 그래프를 직접 구현하면서 Autograd를 이해해보는 시간을 갖겠습니다.   \r\n",
        "이번 실습에서는 backpop의 미분 값이 어떻게 계산되는 지 살펴볼 것입니다.  \r\n",
        "x는 초기 값으로 2x2의 1로 채워진 행렬을 사용할 것입니다.  \r\n",
        "\r\n",
        "<img src=\"./img/ex1.jpg\" width='600'>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = torch.ones(2, 2)\r\n",
        "print(x)\r\n",
        "print(x.requires_grad)\r\n",
        "print('-'*10)\r\n",
        "\r\n",
        "x = torch.ones(2, 2, requires_grad=True)\r\n",
        "print(x)\r\n",
        "print(x.requires_grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. requires_grad는 어떤 역할을 하는 파라미터일까요?</b></p>\r\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############################\r\n",
        "# 밑줄 친 곳을 채워주세요! #\r\n",
        "############################\r\n",
        "\r\n",
        "y = ___\r\n",
        "print(y)\r\n",
        "print(y.requires_grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(y.grad_fn)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############################\r\n",
        "# 밑줄 친 곳을 채워주세요! #\r\n",
        "############################\r\n",
        "\r\n",
        "z = ___\r\n",
        "out = z.mean()\r\n",
        "print(z)\r\n",
        "print(out)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = torch.ones(5)  # input tensor\r\n",
        "w = torch.randn(5, 3, requires_grad=True)\r\n",
        "b = torch.randn(3, requires_grad=True)\r\n",
        "\r\n",
        "z = torch.matmul(x, w)+b\r\n",
        "print(z.requires_grad)\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    z = torch.matmul(x, w)+b\r\n",
        "print(z.requires_grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient, 경사/기울기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "역전파를 해보겠습니다. out.backward()과 out.backward(torch.Tensor([1.0]))은 동일하게 동작합니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "out.backward()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(x.grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. requires_grad = True를 하면 무슨 일이 일어나길래, grad()를 호출하면 바로 미분값을 합산해줄까?</b></p>\r\n",
        "    <p>👉 (여기에 답을 입력해 주세요)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. DATASET과 DATALOADER\r\n",
        "\r\n",
        "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\r\n",
        "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\r\n",
        "\r\n",
        "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\r\n",
        "\r\n",
        "여기에서 데이터셋들을 찾아볼 수 있습니다:\r\n",
        "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \r\n",
        "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\r\n",
        "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. 데이터셋 불러오기\r\n",
        "\r\n",
        "`TorchVision` 에서 [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist) 데이터셋을\r\n",
        "불러오는 예제를 살펴보겠습니다. Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다. 각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성됩니다.\r\n",
        "\r\n",
        "다음 매개변수들을 사용하여 [FashionMNIST 데이터셋](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)을 불러옵니다:\r\n",
        " - ``root`` 는 학습/테스트 데이터가 저장되는 경로입니다.\r\n",
        " - ``train`` 은 학습용 또는 테스트용 데이터셋 여부를 지정합니다.\r\n",
        " - ``download=True`` 는 ``root`` 에 데이터가 없는 경우 인터넷에서 다운로드합니다.\r\n",
        " - ``transform`` 과 ``target_transform`` 은 특징(feature)과 정답(label) 변형(transform)을 지정합니다.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torchvision import datasets\r\n",
        "from torchvision.transforms import ToTensor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "training_data = datasets.FashionMNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=True,\r\n",
        "    download=True,\r\n",
        "    transform=ToTensor()\r\n",
        ")\r\n",
        "\r\n",
        "test_data = datasets.FashionMNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=False,\r\n",
        "    download=True,\r\n",
        "    transform=ToTensor()\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. 데이터셋을 순회하고 시각화하기\r\n",
        "\r\n",
        "Dataset 에 리스트(list)처럼 직접 접근(index)할 수 있습니다: training_data[index]. matplotlib 을 사용하여 학습 데이터의 일부를 시각화해보겠습니다."
      ],
      "metadata": {
        "id": "DNZacYNny2Nx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "labels_map = {\r\n",
        "    0: \"T-Shirt\",\r\n",
        "    1: \"Trouser\",\r\n",
        "    2: \"Pullover\",\r\n",
        "    3: \"Dress\",\r\n",
        "    4: \"Coat\",\r\n",
        "    5: \"Sandal\",\r\n",
        "    6: \"Shirt\",\r\n",
        "    7: \"Sneaker\",\r\n",
        "    8: \"Bag\",\r\n",
        "    9: \"Ankle Boot\",\r\n",
        "}\r\n",
        "figure = plt.figure(figsize=(8, 8))\r\n",
        "cols, rows = 3, 3\r\n",
        "for i in range(1, cols * rows + 1):\r\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\r\n",
        "    img, label = training_data[sample_idx]\r\n",
        "    figure.add_subplot(rows, cols, i)\r\n",
        "    plt.title(labels_map[label])\r\n",
        "    plt.axis(\"off\")\r\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\r\n",
        "plt.show()\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. 파일에서 사용자 정의 데이터셋 만들기\r\n",
        "\r\n",
        "사용자 정의 Dataset 클래스는 반드시 3개 함수를 구현해야 합니다: `__init__`, `__len__`, and `__getitem__`. 아래 구현을 살펴보면 FashionMNIST 이미지들은 img_dir 디렉토리에 저장되고, 정답은 `annotations_file csv` 파일에 별도로 저장됩니다.\r\n",
        "\r\n",
        "다음 장에서 각 함수들에서 일어나는 일들을 자세히 살펴보겠습니다"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "from torchvision.io import read_image\r\n",
        "\r\n",
        "class CustomImageDataset(Dataset):\r\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\r\n",
        "        self.img_labels = pd.read_csv(annotations_file)\r\n",
        "        self.img_dir = img_dir\r\n",
        "        self.transform = transform\r\n",
        "        self.target_transform = target_transform\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.img_labels)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\r\n",
        "        image = read_image(img_path)\r\n",
        "        label = self.img_labels.iloc[idx, 1]\r\n",
        "        if self.transform:\r\n",
        "            image = self.transform(image)\r\n",
        "        if self.target_transform:\r\n",
        "            label = self.target_transform(label)\r\n",
        "        return image, label"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. \\_\\_init\\_\\_\r\n",
        "\r\n",
        "`__init__` 함수는 Dataset 객체가 생성(instantiate)될 때 한 번만 실행됩니다. 여기서는 이미지와 주석 파일(annotation_file)이 포함된 디렉토리와 (다음 장에서 자세히 살펴볼) 두가지 변형(transform)을 초기화합니다. \r\n",
        "\r\n",
        "labels.csv 파일은 다음과 같습니다: \r\n",
        "```\r\n",
        "tshirt1.jpg, 0\r\n",
        "tshirt2.jpg, 0\r\n",
        "......\r\n",
        "ankleboot999.jpg, 9\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. \\_\\_len\\_\\_\r\n",
        "\r\n",
        "`__len__` 함수는 데이터셋의 샘플 개수를 반환합니다.\r\n",
        "\r\n",
        "예:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. \\_\\_getitem\\_\\_\r\n",
        "\r\n",
        "`__getitem__` 함수는 주어진 인덱스 ``idx`` 에 해당하는 샘플을 데이터셋에서 불러오고 반환합니다.<br>\r\n",
        "인덱스를 기반으로, 디스크에서 이미지의 위치를 식별하고, ``read_image`` 를 사용하여 이미지를 텐서로 변환하고, ``self.img_labels`` 의 csv 데이터로부터 해당하는 정답(label)을 가져오고, (해당하는 경우) 변형(transform) 함수들을 호출한 뒤, 텐서 이미지와 라벨을 Python 사전(dict)형으로 반환합니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def __getitem__(self, idx):\r\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\r\n",
        "    image = read_image(img_path)\r\n",
        "    label = self.img_labels.iloc[idx, 1]\r\n",
        "    if self.transform:\r\n",
        "        image = self.transform(image)\r\n",
        "    if self.target_transform:\r\n",
        "        label = self.target_transform(label)\r\n",
        "    sample = {\"image\": image, \"label\": label}\r\n",
        "    return sample"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D. DataLoader로 학습용 데이터 준비하기\r\n",
        "\r\n",
        "`Dataset`은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다. 모델을 학습할 때, 일반적으로 샘플들을 “미니배치(minibatch)”로 전달하고, 매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고, Python의 multiprocessing 을 사용하여 데이터 검색 속도를 높이려고 합니다.\r\n",
        "\r\n",
        "`DataLoader`는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iteratable)입니다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\r\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\r\n",
        "\r\n",
        "train_dataloader, test_dataloader"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E. DataLoader를 통해 순회하기(iterate)\r\n",
        "\r\n",
        "``DataLoader`` 에 데이터셋을 불러온 뒤에는 필요에 따라 데이터셋을 순회(iterate)할 수 있습니다.\r\n",
        "아래의 각 순회(iteration)는 (각각 ``batch_size=64`` 의 특징(feature)과 정답(label)을 포함하는) ``train_features`` 와\r\n",
        "``train_labels`` 의 묶음(batch)을 반환합니다. ``shuffle=True`` 로 지정했으므로, 모든 배치를 순회한 뒤 데이터가 섞입니다.\r\n",
        "(데이터 불러오기 순서를 보다 세밀하게(finer-grained) 제어하려면 [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)\r\n",
        "를 살펴보세요.)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 이미지와 정답(label)을 표시합니다.\r\n",
        "train_features, train_labels = next(iter(train_dataloader))\r\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\r\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\r\n",
        "img = train_features[0].squeeze()\r\n",
        "label = train_labels[0]\r\n",
        "plt.imshow(img, cmap=\"gray\")\r\n",
        "plt.show()\r\n",
        "print(f\"Label: {label}\")"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}