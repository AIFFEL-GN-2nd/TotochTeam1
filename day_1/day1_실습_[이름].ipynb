{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "í…ì„œ(Tensor).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyR/FppqH3gkf6meWYCI0Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('torch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/PEBpung/TotochTeam1/blob/main/day1_%ED%85%90%EC%84%9C(Tensor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì´ì›ƒì§‘ í† í† ì¹˜ íŒŒì´í† ì¹˜ : Day 1"
      ],
      "metadata": {
        "id": "C_FyQ99czaAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“¢ í•´ë‹¹ ê²Œì‹œë¬¼ì€ íŒŒì´í† ì¹˜ ê³µì‹ íŠœí† ë¦¬ì–¼ ì¤‘ íŒŒì´í† ì¹˜(PyTorch) ì‹œì‘í•˜ê¸°ë¥¼ ì½ê³  ì§ì ‘ ì‘ì„±í•´ë³´ëŠ” ì‹¤ìŠµ ë…¸íŠ¸ë¶ì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "GIEtaQ_Czdkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ëª©ì°¨\r\n",
        "1. íƒ ì„œ(TENSOR)\r\n",
        "    1. í…ì„œ(tensor) ì´ˆê¸°í™”\r\n",
        "    2. í…ì„œì˜ ì†ì„±(Attribute)\r\n",
        "    3. í…ì„œ ì—°ì‚°(Operation)\r\n",
        "    4. NumPy ë³€í™˜(Bridge)\r\n",
        "2. Autograd\r\n",
        "    1. ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ í•™ìŠµ\r\n",
        "    2. [ì‹¤ìŠµ] ì—°ì‚° ê·¸ë˜í”„ ì§ì ‘ êµ¬í˜„í•˜ê¸°\r\n",
        "3. DATASETê³¼ DATALOADER\r\n",
        "    1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\r\n",
        "    2. ë°ì´í„°ì…‹ì„ ìˆœíšŒí•˜ê³  ì‹œê°í™”í•˜ê¸°\r\n",
        "    3. íŒŒì¼ì—ì„œ ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°\r\n",
        "    4. DataLoaderë¡œ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„í•˜ê¸°\r\n",
        "    5. DataLoaderë¥¼ í†µí•´ ìˆœíšŒí•˜ê¸°"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. í…ì„œ (Tensor)"
      ],
      "metadata": {
        "id": "w5CTkc4nirPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "id": "mxpKzLnXimaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### í…ì„œ(tensor) ì´ˆê¸°í™”"
      ],
      "metadata": {
        "id": "Ul7rdwiRi5zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë°ì´í„°ë¡œë¶€í„° ì§ì ‘(directly) ìƒì„±í•˜ê¸°**"
      ],
      "metadata": {
        "id": "ZVcsUDhcjCrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = [[1, 2],[3, 4]]\r\n",
        "x_data = torch.tensor(data)\r\n",
        "x_data"
      ],
      "outputs": [],
      "metadata": {
        "id": "10y9YFqZiopn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy ë°°ì—´ë¡œë¶€í„° ìƒì„±í•˜ê¸°**"
      ],
      "metadata": {
        "id": "BhK77YQwi6L1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np_array = np.array(data)\r\n",
        "x_np = torch.from_numpy(np_array)\r\n",
        "x_np"
      ],
      "outputs": [],
      "metadata": {
        "id": "KvgWwsTUipiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë‹¤ë¥¸ í…ì„œë¡œë¶€í„° ìƒì„±í•˜ê¸°**"
      ],
      "metadata": {
        "id": "CF0gt5U6jR8V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# x_dataì˜ ì†ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.\r\n",
        "x_ones = torch.ones_like(x_data) \r\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\r\n",
        "\r\n",
        "# x_dataì˜ ì†ì„±ì„ ë®ì–´ì”ë‹ˆë‹¤.\r\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) \r\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "wikxshb9iqQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë¬´ì‘ìœ„(random) ë˜ëŠ” ìƒìˆ˜(constant) ê°’ì„ ì‚¬ìš©í•˜ê¸°:**"
      ],
      "metadata": {
        "id": "Sepex-_YjYkG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "shape = (2,3,)\r\n",
        "rand_tensor = torch.rand(shape)\r\n",
        "ones_tensor = torch.ones(shape)\r\n",
        "zeros_tensor = torch.zeros(shape)\r\n",
        "\r\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\r\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\r\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "jmVb1QuTiqZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rand_tensor.add(ones_tensor)\r\n",
        "print(rand_tensor)\r\n",
        "rand_tensor.add_(ones_tensor)\r\n",
        "print(rand_tensor)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### í…ì„œì˜ ì†ì„±(Attribute)"
      ],
      "metadata": {
        "id": "p2blbrRdjgI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tensor = torch.rand(3,4)\r\n",
        "\r\n",
        "############################\r\n",
        "# ë°‘ì¤„ ì¹œ ê³³ì„ ì±„ì›Œì£¼ì„¸ìš”! #\r\n",
        "############################\r\n",
        "\r\n",
        "print(f\"Shape of tensor: {___}\")\r\n",
        "print(f\"Datatype of tensor: {___}\")\r\n",
        "print(f\"Device tensor is stored on: {___}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "6HbUDrVljf_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### í…ì„œ ì—°ì‚°(Operation)"
      ],
      "metadata": {
        "id": "QdTMCC1KmPD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. í…ì„œë¥¼ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ ì ì´ ì¢‹ì„ê¹Œìš”??</b></p>\r\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# GPUê°€ ì¡´ì¬í•˜ë©´ í…ì„œë¥¼ ì´ë™í•©ë‹ˆë‹¤\r\n",
        "if torch.cuda.is_available():\r\n",
        "  tensor = tensor.to('cuda')"
      ],
      "outputs": [],
      "metadata": {
        "id": "nyM7zxmnjf3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPyì‹ì˜ í‘œì¤€ ì¸ë±ì‹±ê³¼ ìŠ¬ë¼ì´ì‹±:"
      ],
      "metadata": {
        "id": "LV3e7QrZmdF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = [[1, 2, 3],\r\n",
        "         [4, 5, 6],\r\n",
        "         [7, 8, 9]]\r\n",
        "t_data = torch.tensor(data)\r\n",
        "\r\n",
        "############################\r\n",
        "# ë°‘ì¤„ ì¹œ ê³³ì„ ì±„ì›Œì£¼ì„¸ìš”! #\r\n",
        "############################\r\n",
        "\r\n",
        "print('2ë²ˆì§¸ í–‰ ì¶œë ¥: ',___)\r\n",
        "print('t_dataì—ì„œ 5ë¥¼ ì¶œë ¥: ', ___)\r\n",
        "print('ë§ˆì§€ë§‰ column ì¶œë ¥:', ___)\r\n",
        "t_data[___] = 0\r\n",
        "print('3ë²ˆì§¸ columnì„ 0ìœ¼ë¡œ ë§Œë“¤ê¸°:')\r\n",
        "print(t_data)"
      ],
      "outputs": [],
      "metadata": {
        "id": "522O3OXJjfuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í…ì„œ í•©ì¹˜ê¸°**"
      ],
      "metadata": {
        "id": "4DbwAF-TpeBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\r\n",
        "print(t1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kWGBUa0ljfi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ì‚°ìˆ  ì—°ì‚°(Arithmetic operations)**"
      ],
      "metadata": {
        "id": "VCf2__l_ppjd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tensor = torch.rand(3,4)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FAMnNAnurkDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ë‘ í…ì„œ ê°„ì˜ í–‰ë ¬ ê³±(matrix multiplication)ì„ ê³„ì‚°í•©ë‹ˆë‹¤. y1, y2, y3ì€ ëª¨ë‘ ê°™ì€ ê°’ì„ ê°–ìŠµë‹ˆë‹¤.\r\n",
        "y1 = tensor @ tensor.T\r\n",
        "y2 = tensor.matmul(tensor.T)\r\n",
        "\r\n",
        "y3 = torch.rand_like(tensor)\r\n",
        "torch.matmul(tensor, tensor.T, out=y3)\r\n",
        "print(y1)\r\n",
        "print(y2)\r\n",
        "print(y3)\r\n",
        "\r\n",
        "print('-- '*15)\r\n",
        "# ìš”ì†Œë³„ ê³±(element-wise product)ì„ ê³„ì‚°í•©ë‹ˆë‹¤. z1, z2, z3ëŠ” ëª¨ë‘ ê°™ì€ ê°’ì„ ê°–ìŠµë‹ˆë‹¤.\r\n",
        "z1 = tensor * tensor\r\n",
        "z2 = tensor.mul(tensor)\r\n",
        "\r\n",
        "z3 = torch.rand_like(tensor)\r\n",
        "torch.mul(tensor, tensor, out=z3)\r\n",
        "print(z1)\r\n",
        "print(z2)\r\n",
        "print(z3)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8rl2lXktjfEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. í–‰ë ¬ ê³±(matrix multiplication)ê³¼ ìš”ì†Œë³„ ê³±(element-wise product)ì˜ ì°¨ì´ì ì´ ë­˜ê¹Œìš”??</b></p>\r\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë‹¨ì¼-ìš”ì†Œ(single-element)**"
      ],
      "metadata": {
        "id": "tS823HhDsI6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "agg = tensor.sum()\r\n",
        "agg_item = agg.item()\r\n",
        "print(agg_item, type(agg_item))"
      ],
      "outputs": [],
      "metadata": {
        "id": "C9_IWxvHsIqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í…ì„œì°¨ì› ì¶•ì†Œ/í™•ì¥(Squeeze/Unsqueeze) ì—°ì‚°**"
      ],
      "metadata": {
        "id": "F6VGHAC4wWCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Squeeze/Unsqueeze\r\n",
        "x = torch.rand((1,1,3,4))\r\n",
        "y = x.squeeze()\r\n",
        "print(y.size())\r\n",
        "print(y.unsqueeze(1).size())"
      ],
      "outputs": [],
      "metadata": {
        "id": "DYhTcpCor2wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. Squeezeì™€ UnsqueezeëŠ” ì–´ë–¤ ê²½ìš°ì— ì‚¬ìš© ë ê¹Œìš”? ììœ ë¡­ê²Œ ìƒê°í•´ë³´ì£ !</b></p>\r\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ìŠ¤íƒœí‚¹(Stacking)**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = torch.FloatTensor([1, 4])\r\n",
        "y = torch.FloatTensor([2, 5])\r\n",
        "z = torch.FloatTensor([3, 6])\r\n",
        "\r\n",
        "print(torch.stack([x, y, z]))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ë„˜íŒŒì´(Numpy)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ê¸°**"
      ],
      "metadata": {
        "id": "17IUYsqNxUxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "t = torch.ones(5)\r\n",
        "print(f\"t: {t}\")\r\n",
        "n = t.numpy()\r\n",
        "print(f\"n: {n}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "5EuvEtoIxUl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "í…ì„œì˜ ë³€ê²½ ì‚¬í•­ì´ NumPy ë°°ì—´ì— ë°˜ì˜ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "IDV_kHfJxYvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "t.add_(1)\r\n",
        "print(f\"t: {t}\")\r\n",
        "print(f\"n: {n}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "FcKNnWvFxUhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy ë°°ì—´ì„ í…ì„œë¡œ ë³€í™˜í•˜ê¸°**"
      ],
      "metadata": {
        "id": "4D5LXTwDxcap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "n = np.ones(5)\r\n",
        "t = torch.from_numpy(n)"
      ],
      "outputs": [],
      "metadata": {
        "id": "0GLooKX3xUfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy ë°°ì—´ì˜ ë³€ê²½ ì‚¬í•­ì´ í…ì„œì— ë°˜ì˜ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "Y0VP8MyOxfq_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.add(n, 1, out=n)\r\n",
        "print(f\"t: {t}\")\r\n",
        "print(f\"n: {n}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "9XJL53PRxUZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Autograd"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ê°„ë‹¨ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "random_seed = 99\r\n",
        "torch.manual_seed(random_seed)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë™ì¼í•œ ì¶œë ¥ì„ ì–»ê¸° ìœ„í•´ì„œ random seed ê°’ ì„¤ì •"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) ë°ì´í„° ì¤€ë¹„í•˜ê¸°"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = torch.nn.Sequential(\r\n",
        "    torch.nn.Linear(6, 1),\r\n",
        "    torch.nn.Flatten()\r\n",
        ")\r\n",
        "data = torch.rand(2, 6)\r\n",
        "labels = torch.ones(2, 1)\r\n",
        "labels"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "ëœë¤ìœ¼ë¡œ ì„¤ì •ëœ label ê°’ì€ ([1.], [1.])ì…ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. ê°ì ê·¸ë¦¼ì„ ê·¸ë¦¬ë©´ì„œ ì´í•´í•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!</b></p>\r\n",
        "    <p>ğŸ‘‰ (í•´ë‹µì€ í† ë¡  ì‹œê°„ì— ê³µìœ í•´ë³¼ê²Œìš”))</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) ìˆœì „íŒŒ (Forward Propagation)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "prediction = model(data) # ìˆœì „íŒŒ ë‹¨ê³„(forward pass)\r\n",
        "prediction"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìˆœì „íŒŒ ë‹¨ê³„ì—ì„œëŠ” ì…ë ¥(input) ë°ì´í„°ë¥¼ ëª¨ë¸ì˜ ê° ì¸µ(layer)ì— í†µê³¼ì‹œì¼œ ì˜ˆì¸¡ê°’(prediction)ì„ ìƒì„±í•©ë‹ˆë‹¤.   \r\n",
        "ëª¨ë¸ì˜ outputìœ¼ë¡œ ë‚˜ì˜¨ pred ê°’ì€ ([0.3425], [0.2512])ì…ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "layer = model[0]\r\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "ëª¨ë¸ì˜ ì´ˆê¸° weightì™€ biasë¥¼ í™•ì¸ í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤.  \r\n",
        "ì†ì‹¤í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•´ì„œ ì´ ê°’ë“¤ì„ ë³€ê²½í•  ê²ƒì…ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) ì†ì‹¤í•¨ìˆ˜ (loss) ê³„ì‚°í•˜ê¸°"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss = (prediction - labels).sum() \r\n",
        "print(loss)\r\n",
        "loss.backward() # ì—­ì „íŒŒ ë‹¨ê³„(backward pass)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’(prediction)ê³¼ ê·¸ì— í•´ë‹¹í•˜ëŠ” ì •ë‹µ(label)ì˜ ì°¨ì´ë¥¼ í•©í•˜ì—¬ ì˜¤ì°¨(error, ì†ì‹¤(loss) )ë¥¼ ê³„ì‚°í•˜ì˜€ìŠµë‹ˆë‹¤. ì†ì‹¤í•¨ìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•˜ì§€ë§Œ ì´ë²ˆê¸€ì—ì„œëŠ” ê°„ë‹¨í•˜ê²Œ ì°¨ì´ê°’ìœ¼ë¡œë§Œ êµ¬í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\r\n",
        "\r\n",
        "-  ì˜¤ì°¨ í…ì„œ(error tensor)ì— .backward() ë¥¼ í˜¸ì¶œí•˜ë©´ ì—­ì „íŒŒê°€ ì‹œì‘ë˜ë©°, ê·¸ ë‹¤ìŒ Autogradê°€ ë§¤ê°œë³€ìˆ˜(parameter)ì˜ .grad ì†ì„±(attribute)ì—, ëª¨ë¸ì˜ ê° ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•œ ë³€í™”ë„(gradient)ë¥¼ ê³„ì‚°í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. lossì˜ ê²°ê³¼ëŠ” -1.4063ì´ ë‚˜ì™”ìŠµë‹ˆë‹¤, ì§ì ‘ labels ê°’ê³¼ pred ê°’ì„ ë¹„êµí•´ì„œ ê³„ì‚°í•´ë´…ì‹œë‹¤!</b></p>\r\n",
        "    <p>ğŸ‘‰ (í•´ë‹µì€ í† ë¡  ì‹œê°„ì— ê³µìœ í•´ë³¼ê²Œìš”))</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) ì˜µí‹°ë§ˆì´ì € ì„¤ì •"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- í•™ìŠµìœ¨(learning rate) 0.01ê³¼ ëª¨ë©˜í…€(momentum) 0.9ë¥¼ ê°–ëŠ” SGDë¡œ ì˜µí‹°ë§ˆì´ì¦ˆë¥¼ ì„¤ì •í•˜ì˜€ìœ¼ë©°, ì˜µí‹°ë§ˆì´ì €(optimizer)ì— ëª¨ë¸ì˜ ëª¨ë“  ë§¤ê°œë³€ìˆ˜(models.parameters())ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) ê²½ì‚¬í•˜ê°•ë²•"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optim.step() # ê²½ì‚¬í•˜ê°•ë²•(gradient descent)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- step ì„ í˜¸ì¶œí•˜ì—¬ ê²½ì‚¬í•˜ê°•ë²•(gradient descent)ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì˜µí‹°ë§ˆì´ì €ëŠ” .grad ì— ì €ì¥ëœ ê¸°ìš¸ê¸°(gradient)ì— ë”°ë¼ ê° ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •(adjust)í•©ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "layer = model[0]\r\n",
        "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "prediction = model(data) # ìˆœì „íŒŒ ë‹¨ê³„(forward pass)\r\n",
        "prediction"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‹¤ìŠµ ë¬¸ì œ\r\n",
        "ë‹¤ìŒê³¼ ê°™ì€ ì—°ì‚° ê·¸ë˜í”„ë¥¼ ì§ì ‘ êµ¬í˜„í•˜ë©´ì„œ Autogradë¥¼ ì´í•´í•´ë³´ëŠ” ì‹œê°„ì„ ê°–ê² ìŠµë‹ˆë‹¤.   \r\n",
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” backpopì˜ ë¯¸ë¶„ ê°’ì´ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ” ì§€ ì‚´í´ë³¼ ê²ƒì…ë‹ˆë‹¤.  \r\n",
        "xëŠ” ì´ˆê¸° ê°’ìœ¼ë¡œ 2x2ì˜ 1ë¡œ ì±„ì›Œì§„ í–‰ë ¬ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.  \r\n",
        "\r\n",
        "<img src=\"./img/ex1.jpg\" width='600'>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = torch.ones(2, 2)\r\n",
        "print(x)\r\n",
        "print(x.requires_grad)\r\n",
        "print('-'*10)\r\n",
        "\r\n",
        "x = torch.ones(2, 2, requires_grad=True)\r\n",
        "print(x)\r\n",
        "print(x.requires_grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. requires_gradëŠ” ì–´ë–¤ ì—­í• ì„ í•˜ëŠ” íŒŒë¼ë¯¸í„°ì¼ê¹Œìš”?</b></p>\r\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############################\r\n",
        "# ë°‘ì¤„ ì¹œ ê³³ì„ ì±„ì›Œì£¼ì„¸ìš”! #\r\n",
        "############################\r\n",
        "\r\n",
        "y = ___\r\n",
        "print(y)\r\n",
        "print(y.requires_grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(y.grad_fn)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############################\r\n",
        "# ë°‘ì¤„ ì¹œ ê³³ì„ ì±„ì›Œì£¼ì„¸ìš”! #\r\n",
        "############################\r\n",
        "\r\n",
        "z = ___\r\n",
        "out = z.mean()\r\n",
        "print(z)\r\n",
        "print(out)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = torch.ones(5)  # input tensor\r\n",
        "w = torch.randn(5, 3, requires_grad=True)\r\n",
        "b = torch.randn(3, requires_grad=True)\r\n",
        "\r\n",
        "z = torch.matmul(x, w)+b\r\n",
        "print(z.requires_grad)\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    z = torch.matmul(x, w)+b\r\n",
        "print(z.requires_grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient, ê²½ì‚¬/ê¸°ìš¸ê¸°"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì—­ì „íŒŒë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤. out.backward()ê³¼ out.backward(torch.Tensor([1.0]))ì€ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "out.backward()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(x.grad)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-warning\">\r\n",
        "    <p><b>Q. requires_grad = Trueë¥¼ í•˜ë©´ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê¸¸ë˜, grad()ë¥¼ í˜¸ì¶œí•˜ë©´ ë°”ë¡œ ë¯¸ë¶„ê°’ì„ í•©ì‚°í•´ì¤„ê¹Œ?</b></p>\r\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\r\n",
        "</div>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. DATASETê³¼ DATALOADER\r\n",
        "\r\n",
        "ë°ì´í„° ìƒ˜í”Œì„ ì²˜ë¦¬í•˜ëŠ” ì½”ë“œëŠ” ì§€ì €ë¶„(messy)í•˜ê³  ìœ ì§€ë³´ìˆ˜ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ê°€ë…ì„±(readability)ê³¼ ëª¨ë“ˆì„±(modularity)ì„ ìœ„í•´ ë°ì´í„°ì…‹ ì½”ë“œë¥¼ ëª¨ë¸ í•™ìŠµ ì½”ë“œë¡œë¶€í„° ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì´ìƒì ì…ë‹ˆë‹¤. PyTorchëŠ” ``torch.utils.data.DataLoader``ì™€ ``torch.utils.data.Dataset`` ì˜ ë‘ ê°€ì§€ ë°ì´í„° ê¸°ë³¸ ìš”ì†Œë¥¼ ì œê³µí•˜ì—¬ ë¯¸ë¦¬ ì¤€ë¹„í•´ëœ(pre-loaded) ë°ì´í„°ì…‹ ë¿ë§Œ ì•„ë‹ˆë¼ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\r\n",
        "``Dataset`` ì€ ìƒ˜í”Œê³¼ ì •ë‹µ(label)ì„ ì €ì¥í•˜ê³ , ``DataLoader`` ëŠ” ``Dataset`` ì„ ìƒ˜í”Œì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ìˆœíšŒ ê°€ëŠ¥í•œ ê°ì²´(iterable)ë¡œ ê°ìŒ‰ë‹ˆë‹¤.\r\n",
        "\r\n",
        "PyTorchì˜ ë„ë©”ì¸ íŠ¹í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ (FashionMNISTì™€ ê°™ì€) ë‹¤ì–‘í•œ ë¯¸ë¦¬ ì¤€ë¹„í•´ë‘”(pre-loaded) ë°ì´í„°ì…‹ì„ ì œê³µí•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ ``torch.utils.data.Dataset`` ì˜ í•˜ìœ„ í´ë˜ìŠ¤ë¡œ ê°œë³„ ë°ì´í„°ë¥¼ íŠ¹ì •í•˜ëŠ” í•¨ìˆ˜ê°€ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°ì´í„°ì…‹ì€ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ê³ (prototype) ì„±ëŠ¥ì„ ì¸¡ì •(benchmark)í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\r\n",
        "\r\n",
        "ì—¬ê¸°ì—ì„œ ë°ì´í„°ì…‹ë“¤ì„ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\r\n",
        "[ì´ë¯¸ì§€ ë°ì´í„°ì…‹](https://pytorch.org/vision/stable/datasets.html), \r\n",
        "[í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹](https://pytorch.org/text/stable/datasets.html) ë°\r\n",
        "[ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹](https://pytorch.org/audio/stable/datasets.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\r\n",
        "\r\n",
        "`TorchVision` ì—ì„œ [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist) ë°ì´í„°ì…‹ì„\r\n",
        "ë¶ˆëŸ¬ì˜¤ëŠ” ì˜ˆì œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. Fashion-MNISTëŠ” Zalandoì˜ ê¸°ì‚¬ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ìœ¼ë¡œ 60,000ê°œì˜ í•™ìŠµ ì˜ˆì œì™€ 10,000ê°œì˜ í…ŒìŠ¤íŠ¸ ì˜ˆì œë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ê° ì˜ˆì œëŠ” í‘ë°±(grayscale)ì˜ 28x28 ì´ë¯¸ì§€ì™€ 10ê°œ ë¶„ë¥˜(class) ì¤‘ í•˜ë‚˜ì¸ ì •ë‹µ(label)ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\r\n",
        "\r\n",
        "ë‹¤ìŒ ë§¤ê°œë³€ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ì—¬ [FashionMNIST ë°ì´í„°ì…‹](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤:\r\n",
        " - ``root`` ëŠ” í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì €ì¥ë˜ëŠ” ê²½ë¡œì…ë‹ˆë‹¤.\r\n",
        " - ``train`` ì€ í•™ìŠµìš© ë˜ëŠ” í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ ì—¬ë¶€ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\r\n",
        " - ``download=True`` ëŠ” ``root`` ì— ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\r\n",
        " - ``transform`` ê³¼ ``target_transform`` ì€ íŠ¹ì§•(feature)ê³¼ ì •ë‹µ(label) ë³€í˜•(transform)ì„ ì§€ì •í•©ë‹ˆë‹¤.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torchvision import datasets\r\n",
        "from torchvision.transforms import ToTensor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "training_data = datasets.FashionMNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=True,\r\n",
        "    download=True,\r\n",
        "    transform=ToTensor()\r\n",
        ")\r\n",
        "\r\n",
        "test_data = datasets.FashionMNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=False,\r\n",
        "    download=True,\r\n",
        "    transform=ToTensor()\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. ë°ì´í„°ì…‹ì„ ìˆœíšŒí•˜ê³  ì‹œê°í™”í•˜ê¸°\r\n",
        "\r\n",
        "Dataset ì— ë¦¬ìŠ¤íŠ¸(list)ì²˜ëŸ¼ ì§ì ‘ ì ‘ê·¼(index)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: training_data[index]. matplotlib ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë°ì´í„°ì˜ ì¼ë¶€ë¥¼ ì‹œê°í™”í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "DNZacYNny2Nx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "labels_map = {\r\n",
        "    0: \"T-Shirt\",\r\n",
        "    1: \"Trouser\",\r\n",
        "    2: \"Pullover\",\r\n",
        "    3: \"Dress\",\r\n",
        "    4: \"Coat\",\r\n",
        "    5: \"Sandal\",\r\n",
        "    6: \"Shirt\",\r\n",
        "    7: \"Sneaker\",\r\n",
        "    8: \"Bag\",\r\n",
        "    9: \"Ankle Boot\",\r\n",
        "}\r\n",
        "figure = plt.figure(figsize=(8, 8))\r\n",
        "cols, rows = 3, 3\r\n",
        "for i in range(1, cols * rows + 1):\r\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\r\n",
        "    img, label = training_data[sample_idx]\r\n",
        "    figure.add_subplot(rows, cols, i)\r\n",
        "    plt.title(labels_map[label])\r\n",
        "    plt.axis(\"off\")\r\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\r\n",
        "plt.show()\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. íŒŒì¼ì—ì„œ ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°\r\n",
        "\r\n",
        "ì‚¬ìš©ì ì •ì˜ Dataset í´ë˜ìŠ¤ëŠ” ë°˜ë“œì‹œ 3ê°œ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤: `__init__`, `__len__`, and `__getitem__`. ì•„ë˜ êµ¬í˜„ì„ ì‚´í´ë³´ë©´ FashionMNIST ì´ë¯¸ì§€ë“¤ì€ img_dir ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ê³ , ì •ë‹µì€ `annotations_file csv` íŒŒì¼ì— ë³„ë„ë¡œ ì €ì¥ë©ë‹ˆë‹¤.\r\n",
        "\r\n",
        "ë‹¤ìŒ ì¥ì—ì„œ ê° í•¨ìˆ˜ë“¤ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì¼ë“¤ì„ ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "from torchvision.io import read_image\r\n",
        "\r\n",
        "class CustomImageDataset(Dataset):\r\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\r\n",
        "        self.img_labels = pd.read_csv(annotations_file)\r\n",
        "        self.img_dir = img_dir\r\n",
        "        self.transform = transform\r\n",
        "        self.target_transform = target_transform\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.img_labels)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\r\n",
        "        image = read_image(img_path)\r\n",
        "        label = self.img_labels.iloc[idx, 1]\r\n",
        "        if self.transform:\r\n",
        "            image = self.transform(image)\r\n",
        "        if self.target_transform:\r\n",
        "            label = self.target_transform(label)\r\n",
        "        return image, label"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. \\_\\_init\\_\\_\r\n",
        "\r\n",
        "`__init__` í•¨ìˆ˜ëŠ” Dataset ê°ì²´ê°€ ìƒì„±(instantiate)ë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ì™€ ì£¼ì„ íŒŒì¼(annotation_file)ì´ í¬í•¨ëœ ë””ë ‰í† ë¦¬ì™€ (ë‹¤ìŒ ì¥ì—ì„œ ìì„¸íˆ ì‚´í´ë³¼) ë‘ê°€ì§€ ë³€í˜•(transform)ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. \r\n",
        "\r\n",
        "labels.csv íŒŒì¼ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: \r\n",
        "```\r\n",
        "tshirt1.jpg, 0\r\n",
        "tshirt2.jpg, 0\r\n",
        "......\r\n",
        "ankleboot999.jpg, 9\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. \\_\\_len\\_\\_\r\n",
        "\r\n",
        "`__len__` í•¨ìˆ˜ëŠ” ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\r\n",
        "\r\n",
        "ì˜ˆ:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. \\_\\_getitem\\_\\_\r\n",
        "\r\n",
        "`__getitem__` í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì¸ë±ìŠ¤ ``idx`` ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë°ì´í„°ì…‹ì—ì„œ ë¶ˆëŸ¬ì˜¤ê³  ë°˜í™˜í•©ë‹ˆë‹¤.<br>\r\n",
        "ì¸ë±ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë””ìŠ¤í¬ì—ì„œ ì´ë¯¸ì§€ì˜ ìœ„ì¹˜ë¥¼ ì‹ë³„í•˜ê³ , ``read_image`` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³ , ``self.img_labels`` ì˜ csv ë°ì´í„°ë¡œë¶€í„° í•´ë‹¹í•˜ëŠ” ì •ë‹µ(label)ì„ ê°€ì ¸ì˜¤ê³ , (í•´ë‹¹í•˜ëŠ” ê²½ìš°) ë³€í˜•(transform) í•¨ìˆ˜ë“¤ì„ í˜¸ì¶œí•œ ë’¤, í…ì„œ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ Python ì‚¬ì „(dict)í˜•ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def __getitem__(self, idx):\r\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\r\n",
        "    image = read_image(img_path)\r\n",
        "    label = self.img_labels.iloc[idx, 1]\r\n",
        "    if self.transform:\r\n",
        "        image = self.transform(image)\r\n",
        "    if self.target_transform:\r\n",
        "        label = self.target_transform(label)\r\n",
        "    sample = {\"image\": image, \"label\": label}\r\n",
        "    return sample"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D. DataLoaderë¡œ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„í•˜ê¸°\r\n",
        "\r\n",
        "`Dataset`ì€ ë°ì´í„°ì…‹ì˜ íŠ¹ì§•(feature)ì„ ê°€ì ¸ì˜¤ê³  í•˜ë‚˜ì˜ ìƒ˜í”Œì— ì •ë‹µ(label)ì„ ì§€ì •í•˜ëŠ” ì¼ì„ í•œ ë²ˆì— í•©ë‹ˆë‹¤. ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ, ì¼ë°˜ì ìœ¼ë¡œ ìƒ˜í”Œë“¤ì„ â€œë¯¸ë‹ˆë°°ì¹˜(minibatch)â€ë¡œ ì „ë‹¬í•˜ê³ , ë§¤ ì—í­(epoch)ë§ˆë‹¤ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì„ì–´ì„œ ê³¼ì í•©(overfit)ì„ ë§‰ê³ , Pythonì˜ multiprocessing ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ê²€ìƒ‰ ì†ë„ë¥¼ ë†’ì´ë ¤ê³  í•©ë‹ˆë‹¤.\r\n",
        "\r\n",
        "`DataLoader`ëŠ” ê°„ë‹¨í•œ APIë¡œ ì´ëŸ¬í•œ ë³µì¡í•œ ê³¼ì •ë“¤ì„ ì¶”ìƒí™”í•œ ìˆœíšŒ ê°€ëŠ¥í•œ ê°ì²´(iteratable)ì…ë‹ˆë‹¤."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\r\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\r\n",
        "\r\n",
        "train_dataloader, test_dataloader"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E. DataLoaderë¥¼ í†µí•´ ìˆœíšŒí•˜ê¸°(iterate)\r\n",
        "\r\n",
        "``DataLoader`` ì— ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¨ ë’¤ì—ëŠ” í•„ìš”ì— ë”°ë¼ ë°ì´í„°ì…‹ì„ ìˆœíšŒ(iterate)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\r\n",
        "ì•„ë˜ì˜ ê° ìˆœíšŒ(iteration)ëŠ” (ê°ê° ``batch_size=64`` ì˜ íŠ¹ì§•(feature)ê³¼ ì •ë‹µ(label)ì„ í¬í•¨í•˜ëŠ”) ``train_features`` ì™€\r\n",
        "``train_labels`` ì˜ ë¬¶ìŒ(batch)ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ``shuffle=True`` ë¡œ ì§€ì •í–ˆìœ¼ë¯€ë¡œ, ëª¨ë“  ë°°ì¹˜ë¥¼ ìˆœíšŒí•œ ë’¤ ë°ì´í„°ê°€ ì„ì…ë‹ˆë‹¤.\r\n",
        "(ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ìˆœì„œë¥¼ ë³´ë‹¤ ì„¸ë°€í•˜ê²Œ(finer-grained) ì œì–´í•˜ë ¤ë©´ [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)\r\n",
        "ë¥¼ ì‚´í´ë³´ì„¸ìš”.)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ì´ë¯¸ì§€ì™€ ì •ë‹µ(label)ì„ í‘œì‹œí•©ë‹ˆë‹¤.\r\n",
        "train_features, train_labels = next(iter(train_dataloader))\r\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\r\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\r\n",
        "img = train_features[0].squeeze()\r\n",
        "label = train_labels[0]\r\n",
        "plt.imshow(img, cmap=\"gray\")\r\n",
        "plt.show()\r\n",
        "print(f\"Label: {label}\")"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}