{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/PEBpung/TotochTeam1/blob/main/day1_%ED%85%90%EC%84%9C(Tensor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 이웃집 토토치 파이토치 : Day 1"
   ],
   "metadata": {
    "id": "C_FyQ99czaAS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "📢 해당 게시물은 파이토치 공식 튜토리얼 중 파이토치(PyTorch) 시작하기를 읽고 직접 작성해보는 실습 노트북입니다."
   ],
   "metadata": {
    "id": "GIEtaQ_Czdkp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 목차\n",
    "1. 탠서(TENSOR)\n",
    "    1. 텐서(tensor) 초기화\n",
    "    2. 텐서의 속성(Attribute)\n",
    "    3. 텐서 연산(Operation)\n",
    "    4. NumPy 변환(Bridge)\n",
    "2. Autograd\n",
    "    1. 간단한 이미지 분류 학습\n",
    "    2. [실습] 연산 그래프 직접 구현하기\n",
    "3. DATASET과 DATALOADER\n",
    "    1. 데이터셋 불러오기\n",
    "    2. 데이터셋을 순회하고 시각화하기\n",
    "    3. 파일에서 사용자 정의 데이터셋 만들기\n",
    "    4. DataLoader로 학습용 데이터 준비하기\n",
    "    5. DataLoader를 통해 순회하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 텐서 (Tensor)"
   ],
   "metadata": {
    "id": "w5CTkc4nirPn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {
    "id": "mxpKzLnXimaU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텐서(tensor) 초기화"
   ],
   "metadata": {
    "id": "Ul7rdwiRi5zl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**데이터로부터 직접(directly) 생성하기**"
   ],
   "metadata": {
    "id": "ZVcsUDhcjCrD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {
    "id": "10y9YFqZiopn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NumPy 배열로부터 생성하기**"
   ],
   "metadata": {
    "id": "BhK77YQwi6L1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "id": "KvgWwsTUipiu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**다른 텐서로부터 생성하기**"
   ],
   "metadata": {
    "id": "CF0gt5U6jR8V"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# x_data의 속성을 유지합니다.\n",
    "x_ones = torch.ones_like(x_data) \n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# x_data의 속성을 덮어씁니다.\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) \n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.1890, 0.7951],\n",
      "        [0.4690, 0.8950]]) \n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "id": "wikxshb9iqQ8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**무작위(random) 또는 상수(constant) 값을 사용하기:**"
   ],
   "metadata": {
    "id": "Sepex-_YjYkG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5651, 0.6437, 0.2517],\n",
      "        [0.3035, 0.0041, 0.2015]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "metadata": {
    "id": "jmVb1QuTiqZb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "rand_tensor.add(ones_tensor)\n",
    "print(rand_tensor)\n",
    "rand_tensor.add_(ones_tensor)\n",
    "print(rand_tensor)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.5651, 0.6437, 0.2517],\n",
      "        [0.3035, 0.0041, 0.2015]])\n",
      "tensor([[1.5651, 1.6437, 1.2517],\n",
      "        [1.3035, 1.0041, 1.2015]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텐서의 속성(Attribute)"
   ],
   "metadata": {
    "id": "p2blbrRdjgI2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "############################\n",
    "# 밑줄 친 곳을 채워주세요! #\n",
    "############################\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "metadata": {
    "id": "6HbUDrVljf_H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텐서 연산(Operation)"
   ],
   "metadata": {
    "id": "QdTMCC1KmPD-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Q. 텐서를 사용하면 어떤 점이 좋을까요??</b></p>\n",
    "    <p>👉 식을 간단하게 표현 가능하고, 병렬적인 계산이 용이하다.</p>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# GPU가 존재하면 텐서를 이동합니다\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')"
   ],
   "outputs": [],
   "metadata": {
    "id": "nyM7zxmnjf3y"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "tensor"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7187, 0.0767, 0.1262, 0.2619],\n",
       "        [0.2235, 0.0248, 0.4043, 0.9561],\n",
       "        [0.6496, 0.7799, 0.4934, 0.8995]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "NumPy식의 표준 인덱싱과 슬라이싱:"
   ],
   "metadata": {
    "id": "LV3e7QrZmdF8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data = [[1, 2, 3],\n",
    "         [4, 5, 6],\n",
    "         [7, 8, 9]]\n",
    "t_data = torch.tensor(data)\n",
    "\n",
    "############################\n",
    "# 밑줄 친 곳을 채워주세요! #\n",
    "############################\n",
    "\n",
    "print('2번째 행 출력: ', t_data[1])\n",
    "print('t_data에서 5를 출력: ', t_data[1, 1])\n",
    "print('마지막 column 출력:', t_data[:, -1])\n",
    "t_data[:, 2] = 0\n",
    "print('3번째 column을 0으로 만들기:')\n",
    "print(t_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2번째 행 출력:  tensor([4, 5, 6])\n",
      "t_data에서 5를 출력:  tensor(5)\n",
      "마지막 column 출력: tensor([3, 6, 9])\n",
      "3번째 column을 0으로 만들기:\n",
      "tensor([[1, 2, 0],\n",
      "        [4, 5, 0],\n",
      "        [7, 8, 0]])\n"
     ]
    }
   ],
   "metadata": {
    "id": "522O3OXJjfuB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**텐서 합치기**"
   ],
   "metadata": {
    "id": "4DbwAF-TpeBg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.7187, 0.0767, 0.1262, 0.2619, 0.7187, 0.0767, 0.1262, 0.2619, 0.7187,\n",
      "         0.0767, 0.1262, 0.2619],\n",
      "        [0.2235, 0.0248, 0.4043, 0.9561, 0.2235, 0.0248, 0.4043, 0.9561, 0.2235,\n",
      "         0.0248, 0.4043, 0.9561],\n",
      "        [0.6496, 0.7799, 0.4934, 0.8995, 0.6496, 0.7799, 0.4934, 0.8995, 0.6496,\n",
      "         0.7799, 0.4934, 0.8995]], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {
    "id": "kWGBUa0ljfi6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**산술 연산(Arithmetic operations)**"
   ],
   "metadata": {
    "id": "VCf2__l_ppjd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "tensor = torch.rand(3,4)\n",
    "tensor"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.1687, 0.5590, 0.2217, 0.8564],\n",
       "        [0.6471, 0.2191, 0.7411, 0.4531],\n",
       "        [0.7980, 0.6109, 0.3404, 0.3654]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {
    "id": "FAMnNAnurkDb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "\n",
    "print('-- '*15)\n",
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.1236, 0.7841, 0.8646],\n",
      "        [0.7841, 1.2212, 1.0680],\n",
      "        [0.8646, 1.0680, 1.2593]])\n",
      "tensor([[1.1236, 0.7841, 0.8646],\n",
      "        [0.7841, 1.2212, 1.0680],\n",
      "        [0.8646, 1.0680, 1.2593]])\n",
      "tensor([[1.1236, 0.7841, 0.8646],\n",
      "        [0.7841, 1.2212, 1.0680],\n",
      "        [0.8646, 1.0680, 1.2593]])\n",
      "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
      "tensor([[0.0285, 0.3125, 0.0492, 0.7335],\n",
      "        [0.4187, 0.0480, 0.5492, 0.2053],\n",
      "        [0.6367, 0.3732, 0.1159, 0.1335]])\n",
      "tensor([[0.0285, 0.3125, 0.0492, 0.7335],\n",
      "        [0.4187, 0.0480, 0.5492, 0.2053],\n",
      "        [0.6367, 0.3732, 0.1159, 0.1335]])\n",
      "tensor([[0.0285, 0.3125, 0.0492, 0.7335],\n",
      "        [0.4187, 0.0480, 0.5492, 0.2053],\n",
      "        [0.6367, 0.3732, 0.1159, 0.1335]])\n"
     ]
    }
   ],
   "metadata": {
    "id": "8rl2lXktjfEx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Q. 행렬 곱(matrix multiplication)과 요소별 곱(element-wise product)의 차이점이 뭘까요??</b></p>\n",
    "    <p>👉 행렬 곱은 선형변환이나 내적등의 해석이 가능하고, 요소곱은 말그대로 그냥 요소별 곱이다.</p>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**단일-요소(single-element)**"
   ],
   "metadata": {
    "id": "tS823HhDsI6Z"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.980961322784424 <class 'float'>\n"
     ]
    }
   ],
   "metadata": {
    "id": "C9_IWxvHsIqV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**텐서차원 축소/확장(Squeeze/Unsqueeze) 연산**"
   ],
   "metadata": {
    "id": "F6VGHAC4wWCi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Squeeze/Unsqueeze\n",
    "x = torch.rand((1,1,3,4))\n",
    "y = x.squeeze()\n",
    "print(y.size())\n",
    "print(y.unsqueeze(1).size())\n",
    "print(y.unsqueeze(0).size())\n",
    "print(y.unsqueeze(-1).size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "metadata": {
    "id": "DYhTcpCor2wC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Q. Squeeze와 Unsqueeze는 어떤 경우에 사용 될까요? 자유롭게 생각해보죠!</b></p>\n",
    "    <p>👉 텐서를 연산할 경우, 차원을 맞추려고 사용한다.</p>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**스태킹(Stacking)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "x = torch.FloatTensor([1, 4])\n",
    "y = torch.FloatTensor([2, 5])\n",
    "z = torch.FloatTensor([3, 6])\n",
    "\n",
    "print(torch.stack([x, y, z]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(torch.cat([x, y, z], dim=0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 4., 2., 5., 3., 6.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 넘파이(Numpy)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**텐서를 NumPy 배열로 변환하기**"
   ],
   "metadata": {
    "id": "17IUYsqNxUxp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "metadata": {
    "id": "5EuvEtoIxUl-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "텐서의 변경 사항이 NumPy 배열에 반영됩니다."
   ],
   "metadata": {
    "id": "IDV_kHfJxYvM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "metadata": {
    "id": "FcKNnWvFxUhd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NumPy 배열을 텐서로 변환하기**"
   ],
   "metadata": {
    "id": "4D5LXTwDxcap"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ],
   "outputs": [],
   "metadata": {
    "id": "0GLooKX3xUfd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NumPy 배열의 변경 사항이 텐서에 반영됩니다."
   ],
   "metadata": {
    "id": "Y0VP8MyOxfq_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "metadata": {
    "id": "9XJL53PRxUZc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Autograd"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 간단 이미지 분류 모델 학습"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_seed = 99\n",
    "torch.manual_seed(random_seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "동일한 출력을 얻기 위해서 random seed 값 설정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) 데이터 준비하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(6, 1),\n",
    "    torch.nn.Flatten()\n",
    ")\n",
    "data = torch.rand(2, 6)\n",
    "labels = torch.ones(2, 1)\n",
    "labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "랜덤으로 설정된 label 값은 ([1.], [1.])입니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Q. 각자 그림을 그리면서 이해하시는 것을 추천드립니다!</b></p>\n",
    "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) 순전파 (Forward Propagation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction = model(data) # 순전파 단계(forward pass)\n",
    "prediction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "순전파 단계에서는 입력(input) 데이터를 모델의 각 층(layer)에 통과시켜 예측값(prediction)을 생성합니다.   \n",
    "모델의 output으로 나온 pred 값은 ([0.3425], [0.2512])입니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "layer = model[0]\n",
    "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델의 초기 weight와 bias를 확인 해보시길 바랍니다.  \n",
    "손실함수와 옵티마이저를 사용해서 이 값들을 변경할 것입니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) 손실함수 (loss) 계산하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss = (prediction - labels).sum() \n",
    "print(loss)\n",
    "loss.backward() # 역전파 단계(backward pass)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 모델의 예측값(prediction)과 그에 해당하는 정답(label)의 차이를 합하여 오차(error, 손실(loss) )를 계산하였습니다. 손실함수를 구하는 방법은 다양하지만 이번글에서는 간단하게 차이값으로만 구하도록 하겠습니다.\n",
    "\n",
    "-  오차 텐서(error tensor)에 .backward() 를 호출하면 역전파가 시작되며, 그 다음 Autograd가 매개변수(parameter)의 .grad 속성(attribute)에, 모델의 각 매개변수에 대한 변화도(gradient)를 계산하고 저장합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Q. loss의 결과는 -1.4063이 나왔습니다, 직접 labels 값과 pred 값을 비교해서 계산해봅시다!</b></p>\n",
    "    <p>👉 (해답은 토론 시간에 공유해볼게요))</p>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4) 옵티마이저 설정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 학습율(learning rate) 0.01과 모멘텀(momentum) 0.9를 갖는 SGD로 옵티마이즈를 설정하였으며, 옵티마이저(optimizer)에 모델의 모든 매개변수(models.parameters())를 등록합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5) 경사하강법"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optim.step() # 경사하강법(gradient descent)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- step 을 호출하여 경사하강법(gradient descent)을 시작합니다. 옵티마이저는 .grad 에 저장된 기울기(gradient)에 따라 각 매개변수를 조정(adjust)합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "layer = model[0]\n",
    "print(f'Result: y = {layer.bias.item()} + {layer.weight[:, 0].item()} x + {layer.weight[:, 1].item()} x^2 + {layer.weight[:, 2].item()} x^3')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction = model(data) # 순전파 단계(forward pass)\n",
    "prediction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 실습 문제\n",
    "다음과 같은 연산 그래프를 직접 구현하면서 Autograd를 이해해보는 시간을 갖겠습니다.   \n",
    "이번 실습에서는 backpop의 미분 값이 어떻게 계산되는 지 살펴볼 것입니다.  \n",
    "x는 초기 값으로 2x2의 1로 채워진 행렬을 사용할 것입니다.  \n",
    "\n",
    "<img src=\"./img/ex1.jpg\" width='600'>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = torch.ones(2, 2)\n",
    "print(x)\n",
    "print(x.requires_grad)\n",
    "print('-'*10)\n",
    "\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Q. requires_grad는 어떤 역할을 하는 파라미터일까요?</b></p>\n",
    "    <p>👉 (여기에 답을 입력해 주세요)</p>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "############################\n",
    "# 밑줄 친 곳을 채워주세요! #\n",
    "############################\n",
    "\n",
    "y = ___\n",
    "print(y)\n",
    "print(y.requires_grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(y.grad_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "############################\n",
    "# 밑줄 친 곳을 채워주세요! #\n",
    "############################\n",
    "\n",
    "z = ___\n",
    "out = z.mean()\n",
    "print(z)\n",
    "print(out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient, 경사/기울기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "역전파를 해보겠습니다. out.backward()과 out.backward(torch.Tensor([1.0]))은 동일하게 동작합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "out.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(x.grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Q. requires_grad = True를 하면 무슨 일이 일어나길래, grad()를 호출하면 바로 미분값을 합산해줄까?</b></p>\n",
    "    <p>👉 (여기에 답을 입력해 주세요)</p>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. DATASET과 DATALOADER\n",
    "\n",
    "데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다. 더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다. PyTorch는 ``torch.utils.data.DataLoader``와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해된(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\n",
    "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
    "\n",
    "PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 다양한 미리 준비해둔(pre-loaded) 데이터셋을 제공합니다. 데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다. 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\n",
    "\n",
    "여기에서 데이터셋들을 찾아볼 수 있습니다:\n",
    "[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html), \n",
    "[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\n",
    "[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A. 데이터셋 불러오기\n",
    "\n",
    "`TorchVision` 에서 [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist) 데이터셋을\n",
    "불러오는 예제를 살펴보겠습니다. Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다. 각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성됩니다.\n",
    "\n",
    "다음 매개변수들을 사용하여 [FashionMNIST 데이터셋](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)을 불러옵니다:\n",
    " - ``root`` 는 학습/테스트 데이터가 저장되는 경로입니다.\n",
    " - ``train`` 은 학습용 또는 테스트용 데이터셋 여부를 지정합니다.\n",
    " - ``download=True`` 는 ``root`` 에 데이터가 없는 경우 인터넷에서 다운로드합니다.\n",
    " - ``transform`` 과 ``target_transform`` 은 특징(feature)과 정답(label) 변형(transform)을 지정합니다.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B. 데이터셋을 순회하고 시각화하기\n",
    "\n",
    "Dataset 에 리스트(list)처럼 직접 접근(index)할 수 있습니다: training_data[index]. matplotlib 을 사용하여 학습 데이터의 일부를 시각화해보겠습니다."
   ],
   "metadata": {
    "id": "DNZacYNny2Nx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### C. 파일에서 사용자 정의 데이터셋 만들기\n",
    "\n",
    "사용자 정의 Dataset 클래스는 반드시 3개 함수를 구현해야 합니다: `__init__`, `__len__`, and `__getitem__`. 아래 구현을 살펴보면 FashionMNIST 이미지들은 img_dir 디렉토리에 저장되고, 정답은 `annotations_file csv` 파일에 별도로 저장됩니다.\n",
    "\n",
    "다음 장에서 각 함수들에서 일어나는 일들을 자세히 살펴보겠습니다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### a. \\_\\_init\\_\\_\n",
    "\n",
    "`__init__` 함수는 Dataset 객체가 생성(instantiate)될 때 한 번만 실행됩니다. 여기서는 이미지와 주석 파일(annotation_file)이 포함된 디렉토리와 (다음 장에서 자세히 살펴볼) 두가지 변형(transform)을 초기화합니다. \n",
    "\n",
    "labels.csv 파일은 다음과 같습니다: \n",
    "```\n",
    "tshirt1.jpg, 0\n",
    "tshirt2.jpg, 0\n",
    "......\n",
    "ankleboot999.jpg, 9\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### b. \\_\\_len\\_\\_\n",
    "\n",
    "`__len__` 함수는 데이터셋의 샘플 개수를 반환합니다.\n",
    "\n",
    "예:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### c. \\_\\_getitem\\_\\_\n",
    "\n",
    "`__getitem__` 함수는 주어진 인덱스 ``idx`` 에 해당하는 샘플을 데이터셋에서 불러오고 반환합니다.<br>\n",
    "인덱스를 기반으로, 디스크에서 이미지의 위치를 식별하고, ``read_image`` 를 사용하여 이미지를 텐서로 변환하고, ``self.img_labels`` 의 csv 데이터로부터 해당하는 정답(label)을 가져오고, (해당하는 경우) 변형(transform) 함수들을 호출한 뒤, 텐서 이미지와 라벨을 Python 사전(dict)형으로 반환합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def __getitem__(self, idx):\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "    image = read_image(img_path)\n",
    "    label = self.img_labels.iloc[idx, 1]\n",
    "    if self.transform:\n",
    "        image = self.transform(image)\n",
    "    if self.target_transform:\n",
    "        label = self.target_transform(label)\n",
    "    sample = {\"image\": image, \"label\": label}\n",
    "    return sample"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### D. DataLoader로 학습용 데이터 준비하기\n",
    "\n",
    "`Dataset`은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다. 모델을 학습할 때, 일반적으로 샘플들을 “미니배치(minibatch)”로 전달하고, 매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고, Python의 multiprocessing 을 사용하여 데이터 검색 속도를 높이려고 합니다.\n",
    "\n",
    "`DataLoader`는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iteratable)입니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### E. DataLoader를 통해 순회하기(iterate)\n",
    "\n",
    "``DataLoader`` 에 데이터셋을 불러온 뒤에는 필요에 따라 데이터셋을 순회(iterate)할 수 있습니다.\n",
    "아래의 각 순회(iteration)는 (각각 ``batch_size=64`` 의 특징(feature)과 정답(label)을 포함하는) ``train_features`` 와\n",
    "``train_labels`` 의 묶음(batch)을 반환합니다. ``shuffle=True`` 로 지정했으므로, 모든 배치를 순회한 뒤 데이터가 섞입니다.\n",
    "(데이터 불러오기 순서를 보다 세밀하게(finer-grained) 제어하려면 [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)\n",
    "를 살펴보세요.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 이미지와 정답(label)을 표시합니다.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPyR/FppqH3gkf6meWYCI0Y",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "텐서(Tensor).ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "interpreter": {
   "hash": "93f0d9e47ee3596f3a4c40963a5f80a2a8195902cfa23a0f0d123dcd43c69f1e"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}